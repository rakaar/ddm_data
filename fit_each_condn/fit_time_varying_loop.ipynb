{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import os\n",
    "\n",
    "from joblib import Parallel, delayed, parallel_backend\n",
    "# from psiam_tied_dv_map_utils_for_noise import psiam_tied_data_gen_wrapper_noise_change_no_L_T0_change\n",
    "from psiam_tied_dv_map_utils_with_PDFs import all_RTs_fit_OPTIM_V_A_change_added_noise_fn, up_RTs_fit_OPTIM_V_A_change_added_noise_fn, down_RTs_fit_OPTIM_V_A_change_added_noise_fn, PA_with_LEDON_2\n",
    "from psiam_tied_dv_map_utils_with_PDFs import up_RTs_fit_OPTIM_V_A_change_gamma_omega_fn, down_RTs_fit_OPTIM_V_A_change_gamma_omega_fn\n",
    "import pandas as pd\n",
    "import random\n",
    "from tqdm.notebook import tqdm\n",
    "from joblib import Parallel, delayed\n",
    "from scipy.integrate import trapezoid as trapz\n",
    "from pyvbmc import VBMC\n",
    "import corner\n",
    "from diagnostics_class import Diagnostics\n",
    "from psiam_tied_dv_map_utils_with_PDFs import all_RTs_fit_OPTIM_fn, CDF_RT_fn\n",
    "from scipy.integrate import cumulative_trapezoid as cumtrapz\n",
    "import pickle\n",
    "from single_cond_utils import PA_with_LEDON_2_VEC\n",
    "from psiam_tied_dv_map_utils_with_PDFs import up_RTs_fit_OPTIM_V_A_change_gamma_omega_P_A_C_A_wrt_stim_fn\n",
    "from psiam_tied_dv_map_utils_with_PDFs import down_RTs_fit_OPTIM_V_A_change_gamma_omega_P_A_C_A_wrt_stim_fn\n",
    "from psiam_tied_dv_map_utils_with_PDFs import all_RTs_fit_OPTIM_omega_gamma_PA_CA_wrt_stim_fn\n",
    "\n",
    "import io\n",
    "import matplotlib.gridspec as gridspec\n",
    "import corner\n",
    "\n",
    "from single_cond_utils import PA_with_LEDON_2_VEC\n",
    "from psiam_tied_dv_map_utils_with_PDFs import up_or_down_RTs_fit_OPTIM_V_A_change_gamma_omega_P_A_C_A_wrt_stim_time_varying_fn\n",
    "from types import SimpleNamespace\n",
    "from psiam_tied_dv_map_utils_with_PDFs import up_or_down_RTs_fit_OPTIM_V_A_change_gamma_omega_w_time_varying_led_off_fn\n",
    "\n",
    "import io\n",
    "import matplotlib.gridspec as gridspec\n",
    "import corner\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "len of LED off: 66226\n",
      "len of led off valid trials = 53472\n",
      "len of valid trials < 1s : 52799\n"
     ]
    }
   ],
   "source": [
    "# repeat_trial, T16, S7\n",
    "og_df = pd.read_csv('../out_LED.csv')\n",
    "df = og_df[ og_df['repeat_trial'].isin([0,2]) | og_df['repeat_trial'].isna() ]\n",
    "session_type = 7    \n",
    "df = df[ df['session_type'].isin([session_type]) ]\n",
    "training_level = 16\n",
    "df = df[ df['training_level'].isin([training_level]) ]\n",
    "\n",
    "\n",
    "# t_stim, t_LED, ABL, ILD\n",
    "t_stim_and_led_tuple = [(row['intended_fix'], row['intended_fix'] - row['LED_onset_time']) for _, row in df.iterrows()]\n",
    "ABL_arr = df['ABL'].unique(); ABL_arr.sort()\n",
    "ILD_arr = df['ILD'].unique(); ILD_arr.sort()\n",
    "\n",
    "\n",
    "# 1 is right , -1 is left\n",
    "df['choice'] = df['response_poke'].apply(lambda x: 1 if x == 3 else (-1 if x == 2 else random.choice([1, -1])))\n",
    "# 1 or 0 if the choice was correct or not\n",
    "df['correct'] = (df['ILD'] * df['choice']).apply(lambda x: 1 if x > 0 else 0)\n",
    "\n",
    "# LED OFF\n",
    "df_led_off = df[df['LED_trial'] == 0]\n",
    "print(f'len of LED off: {len(df_led_off)}')\n",
    "\n",
    "\n",
    "\n",
    "# valid trials\n",
    "df_led_off_valid_trials = df_led_off[df_led_off['success'].isin([1,-1])]\n",
    "print(f'len of led off valid trials = {len(df_led_off_valid_trials)}')\n",
    "\n",
    "# remove trials with RT > 1s\n",
    "df_led_off_valid_trials = df_led_off_valid_trials[df_led_off_valid_trials['timed_fix'] - df_led_off_valid_trials['intended_fix'] < 1]\n",
    "print(f'len of valid trials < 1s : {len(df_led_off_valid_trials)}')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "## VBMC params\n",
    "# Proactive params\n",
    "V_A = 1.6\n",
    "theta_A = 2.53\n",
    "V_A_post_LED = V_A # LED OFF\n",
    "\n",
    "# delays\n",
    "t_A_aff = -0.187\n",
    "del_go = 0.13 \n",
    "\n",
    "# other params\n",
    "K_max = 10\n",
    "\n",
    "# LED Off - no noise\n",
    "noise = 0\n",
    "\n",
    "# \n",
    "bump_offset = 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "def compute_loglike_trial(row, gamma, omega, t_E_aff, w, bump_width, bump_height, dip_width, dip_height):\n",
    "    phi_params =  {\n",
    "    'h1': bump_width,\n",
    "    'a1': bump_height,\n",
    "    'b1': bump_offset,\n",
    "    'h2': dip_width,\n",
    "    'a2': dip_height\n",
    "    }\n",
    "    phi_params_obj = SimpleNamespace(**phi_params)\n",
    "\n",
    "    # data\n",
    "    rt = row['timed_fix']\n",
    "    t_stim = row['intended_fix']\n",
    "    t_LED = row['intended_fix'] - row['LED_onset_time']\n",
    "\n",
    "    response_poke = row['response_poke']\n",
    "    \n",
    "\n",
    "    t_pts = np.arange(t_stim, t_stim + 1, 0.001)\n",
    "    P_A_LED_change = np.array([PA_with_LEDON_2(i, V_A, V_A_post_LED, theta_A, 0, t_LED, t_A_aff) for i in t_pts])\n",
    "    area_btn_stim_and_1s = trapz(P_A_LED_change, t_pts)\n",
    "    trunc_factor_p_joint = area_btn_stim_and_1s\n",
    "    \n",
    "    bound_val = 2*response_poke - 5\n",
    "    P_joint_rt_choice = up_or_down_RTs_fit_OPTIM_V_A_change_gamma_omega_w_time_varying_led_off_fn(rt, V_A, theta_A, gamma, omega, t_stim, \\\n",
    "                                            t_A_aff, t_E_aff, del_go, phi_params_obj, w, bound_val, K_max)\n",
    "    \n",
    "    P_joint_rt_choice_trunc = max(P_joint_rt_choice / (trunc_factor_p_joint + 1e-10), 1e-10)\n",
    "    \n",
    "    wt_log_like = np.log(P_joint_rt_choice_trunc)\n",
    "\n",
    "\n",
    "    return wt_log_like"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "omega_bounds = [0.05, 50]\n",
    "omega_plausible_bounds = [0.5, 10]\n",
    "\n",
    "t_E_aff_bounds = [0, 1]\n",
    "t_E_aff_plausible_bounds = [0.01, 0.2]\n",
    "\n",
    "w_bounds = [0.01, 0.99]\n",
    "w_plausible_bounds = [0.3, 0.7]\n",
    "\n",
    "bump_width_bounds = [0.01, 1]\n",
    "bump_width_plausible_bounds = [0.1, 0.4]\n",
    "\n",
    "bump_height_bounds = [0.01, 1]\n",
    "bump_height_plausible_bounds = [0.1, 0.5]\n",
    "\n",
    "dip_width_bounds = [0.005, 0.5]\n",
    "dip_width_plausible_bounds = [0.01, 0.1]\n",
    "\n",
    "dip_height_bounds = [0.01, 1]\n",
    "dip_height_plausible_bounds = [0.3, 0.7]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "def trapezoidal_logpdf(x, a, b, c, d):\n",
    "    if x < a or x > d:\n",
    "        return -np.inf  # Logarithm of zero\n",
    "    area = ((b - a) + (d - c)) / 2 + (c - b)\n",
    "    h_max = 1.0 / area  # Height of the trapezoid to normalize the area to 1\n",
    "    \n",
    "    if a <= x <= b:\n",
    "        pdf_value = ((x - a) / (b - a)) * h_max\n",
    "    elif b < x < c:\n",
    "        pdf_value = h_max\n",
    "    elif c <= x <= d:\n",
    "        pdf_value = ((d - x) / (d - c)) * h_max\n",
    "    else:\n",
    "        pdf_value = 0.0  # This case is redundant due to the initial check\n",
    "\n",
    "    if pdf_value <= 0.0:\n",
    "        return -np.inf\n",
    "    else:\n",
    "        return np.log(pdf_value)\n",
    "    \n",
    "\n",
    "def vbmc_prior_fn(params):\n",
    "    gamma, omega, t_E_aff, w, bump_width, bump_height, dip_width, dip_height = params\n",
    "\n",
    "    gamma_logpdf = trapezoidal_logpdf(gamma, gamma_bounds[0], gamma_plausible_bounds[0], gamma_plausible_bounds[1], gamma_bounds[1])\n",
    "    omega_logpdf = trapezoidal_logpdf(omega, omega_bounds[0], omega_plausible_bounds[0], omega_plausible_bounds[1], omega_bounds[1])\n",
    "    t_E_aff_logpdf = trapezoidal_logpdf(t_E_aff, t_E_aff_bounds[0], t_E_aff_plausible_bounds[0], t_E_aff_plausible_bounds[1], t_E_aff_bounds[1])\n",
    "    w_logpdf = trapezoidal_logpdf(w, w_bounds[0], w_plausible_bounds[0], w_plausible_bounds[1], w_bounds[1])\n",
    "\n",
    "    bump_width_logpdf = trapezoidal_logpdf(bump_width, bump_width_bounds[0], bump_width_plausible_bounds[0], bump_width_plausible_bounds[1], bump_width_bounds[1])\n",
    "    bump_height_logpdf = trapezoidal_logpdf(bump_height, bump_height_bounds[0], bump_height_plausible_bounds[0], bump_height_plausible_bounds[1], bump_height_bounds[1])\n",
    "    dip_width_logpdf = trapezoidal_logpdf(dip_width, dip_width_bounds[0], dip_width_plausible_bounds[0], dip_width_plausible_bounds[1], dip_width_bounds[1])\n",
    "    dip_height_logpdf = trapezoidal_logpdf(dip_height, dip_height_bounds[0], dip_height_plausible_bounds[0], dip_height_plausible_bounds[1], dip_height_bounds[1])\n",
    "\n",
    "    return (\n",
    "        gamma_logpdf +\n",
    "        omega_logpdf +\n",
    "        t_E_aff_logpdf +\n",
    "        w_logpdf +\n",
    "        bump_width_logpdf +\n",
    "        bump_height_logpdf +\n",
    "        dip_width_logpdf +\n",
    "        dip_height_logpdf\n",
    "    )\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "all_ABLs_cond = [20]\n",
    "all_ILDs_cond = [2, -2, 4, -4, 8, -8, 16, -16]\n",
    "for cond_ABL in all_ABLs_cond:\n",
    "    for cond_ILD in all_ILDs_cond:\n",
    "        conditions = {'ABL': [cond_ABL], 'ILD': [cond_ILD]}\n",
    "\n",
    "        # Applying the filter\n",
    "        df_led_off_valid_trials_cond_filtered = df_led_off_valid_trials[\n",
    "            (df_led_off_valid_trials['ABL'].isin(conditions['ABL'])) & \n",
    "            (df_led_off_valid_trials['ILD'].isin(conditions['ILD']))\n",
    "        ]\n",
    "\n",
    "        def vbmc_loglike_fn(params):\n",
    "            gamma, omega, t_E_aff, w, bump_width, bump_height, dip_width, dip_height = params\n",
    "\n",
    "            all_loglike = Parallel(n_jobs=30)(delayed(compute_loglike_trial)(row, gamma, omega, t_E_aff, w, \\\n",
    "                                                                            bump_width, bump_height, dip_width, dip_height) \\\n",
    "                                            for _, row in df_led_off_valid_trials_cond_filtered.iterrows())\n",
    "            \n",
    "            return np.sum(all_loglike)\n",
    "        \n",
    "        def vbmc_joint_fn(params):\n",
    "            priors = vbmc_prior_fn(params)\n",
    "            loglike = vbmc_loglike_fn(params)\n",
    "\n",
    "            return priors + loglike\n",
    "\n",
    "        print(f'++++++++++ ABL = {cond_ABL}, ILD = {cond_ILD} +++++++++++++++++++++')\n",
    "        if cond_ILD > 0:\n",
    "            gamma_bounds = [0.001, 5]\n",
    "            gamma_plausible_bounds = [0.09, 0.9]\n",
    "        elif cond_ILD < 0:\n",
    "            gamma_bounds = [-5, -0.001]\n",
    "            gamma_plausible_bounds = [-0.9, -0.09]\n",
    "\n",
    "        \n",
    "        # Add bounds for all parameters\n",
    "        lb = np.array([\n",
    "            gamma_bounds[0], omega_bounds[0], t_E_aff_bounds[0], w_bounds[0],\n",
    "            bump_width_bounds[0], bump_height_bounds[0], dip_width_bounds[0], dip_height_bounds[0]\n",
    "        ])\n",
    "        ub = np.array([\n",
    "            gamma_bounds[1], omega_bounds[1], t_E_aff_bounds[1], w_bounds[1],\n",
    "            bump_width_bounds[1], bump_height_bounds[1], dip_width_bounds[1], dip_height_bounds[1]\n",
    "        ])\n",
    "\n",
    "        plb = np.array([\n",
    "            gamma_plausible_bounds[0], omega_plausible_bounds[0], t_E_aff_plausible_bounds[0], w_plausible_bounds[0],\n",
    "            bump_width_plausible_bounds[0], bump_height_plausible_bounds[0], dip_width_plausible_bounds[0], dip_height_plausible_bounds[0]\n",
    "        ])\n",
    "        pub = np.array([\n",
    "            gamma_plausible_bounds[1], omega_plausible_bounds[1], t_E_aff_plausible_bounds[1], w_plausible_bounds[1],\n",
    "            bump_width_plausible_bounds[1], bump_height_plausible_bounds[1], dip_width_plausible_bounds[1], dip_height_plausible_bounds[1]\n",
    "        ])\n",
    "\n",
    "        # Initialize with random values within plausible bounds\n",
    "        np.random.seed(42)\n",
    "        gamma_0 = np.random.uniform(gamma_plausible_bounds[0], gamma_plausible_bounds[1])\n",
    "        omega_0 = np.random.uniform(omega_plausible_bounds[0], omega_plausible_bounds[1])\n",
    "        t_E_aff_0 = np.random.uniform(t_E_aff_plausible_bounds[0], t_E_aff_plausible_bounds[1])\n",
    "        w_0 = np.random.uniform(w_plausible_bounds[0], w_plausible_bounds[1])\n",
    "        bump_width_0 = np.random.uniform(bump_width_plausible_bounds[0], bump_width_plausible_bounds[1])\n",
    "        bump_height_0 = np.random.uniform(bump_height_plausible_bounds[0], bump_height_plausible_bounds[1])\n",
    "        dip_width_0 = np.random.uniform(dip_width_plausible_bounds[0], dip_width_plausible_bounds[1])\n",
    "        dip_height_0 = np.random.uniform(dip_height_plausible_bounds[0], dip_height_plausible_bounds[1])\n",
    "\n",
    "        x_0 = np.array([\n",
    "            gamma_0, omega_0, t_E_aff_0, w_0,\n",
    "            bump_width_0, bump_height_0, dip_width_0, dip_height_0\n",
    "        ])\n",
    "\n",
    "        # Run VBMC\n",
    "        vbmc = VBMC(vbmc_joint_fn, x_0, lb, ub, plb, pub, options={'display': 'on'})\n",
    "        vp, results = vbmc.optimize()\n",
    "\n",
    "        vbmc.save(f'each_cond_data/vbmc_T_vary_w_single_condn_ABL_{cond_ABL}_ILD_{cond_ILD}.pkl', overwrite=True)\n",
    "\n",
    "        vp_samples = vp.sample(int(1e5))[0]\n",
    "\n",
    "        # Extract samples for each parameter\n",
    "        gamma_samples = vp_samples[:, 0]\n",
    "        omega_samples = vp_samples[:, 1]\n",
    "        t_E_aff_samples = vp_samples[:, 2]\n",
    "        w_samples = vp_samples[:, 3]\n",
    "        bump_width_samples = vp_samples[:, 4]\n",
    "        bump_height_samples = vp_samples[:, 5]\n",
    "        dip_width_samples = vp_samples[:, 6]\n",
    "        dip_height_samples = vp_samples[:, 7]\n",
    "\n",
    "        # Compute mean estimates\n",
    "        gamma = gamma_samples.mean()\n",
    "        omega = omega_samples.mean()\n",
    "        t_E_aff = t_E_aff_samples.mean()\n",
    "        w = w_samples.mean()\n",
    "        bump_width = bump_width_samples.mean()\n",
    "        bump_height = bump_height_samples.mean()\n",
    "        dip_width = dip_width_samples.mean()\n",
    "        dip_height = dip_height_samples.mean()\n",
    "\n",
    "        # Create array for corner plot\n",
    "        corner_samples = np.vstack([\n",
    "            gamma_samples, omega_samples, t_E_aff_samples, w_samples,\n",
    "            bump_width_samples, bump_height_samples, dip_width_samples, dip_height_samples\n",
    "        ]).T\n",
    "\n",
    "        # Compute ranges for plot\n",
    "        percentiles = np.percentile(corner_samples, [0, 100], axis=0)\n",
    "        _ranges = [(percentiles[0, i], percentiles[1, i]) for i in range(corner_samples.shape[1])]\n",
    "\n",
    "        # Labels for each parameter\n",
    "        param_labels = [\n",
    "            'gamma', 'omega', 't_E_aff', 'w',\n",
    "            'bump_width', 'bump_height', 'dip_width', 'dip_height'\n",
    "        ]\n",
    "\n",
    "        # Generate corner plot\n",
    "        fig_corner = corner.corner(\n",
    "            corner_samples,\n",
    "            labels=param_labels,\n",
    "            show_titles=True,\n",
    "            quantiles=[0.025, 0.5, 0.975],\n",
    "            range=_ranges,\n",
    "            title_fmt=\".4f\"\n",
    "        );\n",
    "\n",
    "        filename = f\"corner_T_vary_w_each_cond_ABL_{cond_ABL}_ILD_{cond_ILD}.png\"\n",
    "        save_path = os.path.join(\"each_cond_data\", filename)\n",
    "        fig_corner.savefig(save_path, dpi=300, bbox_inches='tight')\n",
    "        plt.close(fig_corner)\n",
    "\n",
    "        # Diagnostics\n",
    "        df_led_off = df[df['LED_trial'] == 0]\n",
    "        # < 1s RTs\n",
    "        df_led_off = df_led_off[df_led_off['timed_fix'] - df_led_off['intended_fix'] < 1]\n",
    "        # remove truncated aborts\n",
    "        data_df_led_off_with_aborts = df_led_off[ ~( (df_led_off['abort_event'] == 3) & (df_led_off['timed_fix'] < 0.3) ) ]\n",
    "        # renaming\n",
    "        data_df_led_off_with_aborts = data_df_led_off_with_aborts.rename(\n",
    "            columns={'timed_fix': 'rt', 'intended_fix': 't_stim'}\n",
    "        )\n",
    "\n",
    "        ### ABORTS + VALID TRIALS + ABL, ILD CONDITION\n",
    "        data_df_led_off_with_aborts_cond_filtered = data_df_led_off_with_aborts[\n",
    "            (data_df_led_off_with_aborts['ABL'].isin(conditions['ABL'])) & \n",
    "            (data_df_led_off_with_aborts['ILD'].isin(conditions['ILD']))\n",
    "        ]\n",
    "\n",
    "        data_df_led_off_valid = data_df_led_off_with_aborts[ data_df_led_off_with_aborts['success'].isin([1,-1]) ]\n",
    "\n",
    "        # VALID TRIALS CONDITION\n",
    "        df_led_off_valid_trials_cond_filtered = data_df_led_off_valid[\n",
    "            (data_df_led_off_valid['ABL'].isin(conditions['ABL'])) & \n",
    "            (data_df_led_off_valid['ILD'].isin(conditions['ILD']))\n",
    "        ]\n",
    "\n",
    "        ## Diag 1\n",
    "        phi_params = {\n",
    "            'h1': bump_width,\n",
    "            'a1': bump_height,\n",
    "            'h2': dip_width,\n",
    "            'a2': dip_height,\n",
    "            'b1': bump_offset\n",
    "        }\n",
    "\n",
    "        phi_params_obj = SimpleNamespace(**phi_params)\n",
    "\n",
    "        N_theory = int(1e3)\n",
    "        random_indices = np.random.randint(0, len(t_stim_and_led_tuple), N_theory)\n",
    "        t_pts = np.arange(0, 1, 0.001)\n",
    "\n",
    "        P_A_samples = np.zeros((N_theory, len(t_pts)))\n",
    "        for idx in range(N_theory):\n",
    "            t_stim, t_LED = t_stim_and_led_tuple[random_indices[idx]]\n",
    "            pdf = PA_with_LEDON_2_VEC(t_pts, V_A, V_A, theta_A, t_stim, t_LED, t_A_aff)\n",
    "            P_A_samples[idx, :] = pdf\n",
    "\n",
    "        P_A_samples_mean = np.mean(P_A_samples, axis=0)\n",
    "        C_A_mean = cumtrapz(P_A_samples_mean, t_pts, initial=0)\n",
    "        \n",
    "        up_wrt_stim = np.zeros_like(t_pts)\n",
    "        down_wrt_stim = np.zeros_like(t_pts)\n",
    "        for idx, t in enumerate(t_pts):\n",
    "            P_A = P_A_samples_mean[idx]\n",
    "            C_A = C_A_mean[idx]\n",
    "            \n",
    "            up_wrt_stim[idx] =  up_or_down_RTs_fit_OPTIM_V_A_change_gamma_omega_P_A_C_A_wrt_stim_time_varying_fn(t, P_A, C_A, gamma, omega, t_E_aff, del_go, phi_params_obj, w, 1, K_max)\n",
    "            down_wrt_stim[idx] = up_or_down_RTs_fit_OPTIM_V_A_change_gamma_omega_P_A_C_A_wrt_stim_time_varying_fn(t, P_A, C_A, gamma, omega, t_E_aff, del_go, phi_params_obj, w, -1, K_max)\n",
    "\n",
    "        bins = np.arange(-1,1,0.02)\n",
    "        bin_centers = (bins[:-1] + bins[1:]) / 2\n",
    "\n",
    "        ## data\n",
    "        data_up = df_led_off_valid_trials_cond_filtered[df_led_off_valid_trials_cond_filtered['choice'] == 1]\n",
    "        data_down = df_led_off_valid_trials_cond_filtered[df_led_off_valid_trials_cond_filtered['choice'] == -1]\n",
    "\n",
    "        data_up_rt = data_up['rt'] - data_up['t_stim']\n",
    "        data_up_rt_hist, _ = np.histogram(data_up_rt, bins=bins, density=True)\n",
    "\n",
    "        data_down_rt = data_down['rt'] - data_down['t_stim']\n",
    "        data_down_rt_hist, _ = np.histogram(data_down_rt, bins=bins, density=True)\n",
    "\n",
    "        frac_up_data = len(data_up) / len(df_led_off_valid_trials_cond_filtered)\n",
    "        frac_down_data = len(data_down) / len(df_led_off_valid_trials_cond_filtered)\n",
    "\n",
    "        \n",
    "        theory_area_up = trapz(up_wrt_stim, t_pts)\n",
    "        theory_area_down = trapz(down_wrt_stim, t_pts)\n",
    "\n",
    "        # accuracy\n",
    "        xlabels = ['data', 'vbmc']\n",
    "        if conditions['ILD'][0] > 0:\n",
    "            accuracy_data_and_theory = [frac_up_data, theory_area_up]\n",
    "        else:\n",
    "            accuracy_data_and_theory = [frac_down_data, theory_area_down]\n",
    "\n",
    "        tacho = np.zeros_like(t_pts)\n",
    "        for idx, t in enumerate(t_pts):\n",
    "            P_A = P_A_samples_mean[idx]\n",
    "            C_A = C_A_mean[idx]\n",
    "            \n",
    "            P_up = up_or_down_RTs_fit_OPTIM_V_A_change_gamma_omega_P_A_C_A_wrt_stim_time_varying_fn(t, P_A, C_A, gamma, omega, t_E_aff, del_go, phi_params_obj, w, 1, K_max)\n",
    "            P_down = up_or_down_RTs_fit_OPTIM_V_A_change_gamma_omega_P_A_C_A_wrt_stim_time_varying_fn(t, P_A, C_A, gamma, omega, t_E_aff, del_go, phi_params_obj, w, -1, K_max)\n",
    "            \n",
    "            if conditions['ILD'][0] > 0:\n",
    "                P_rt_c = P_up\n",
    "            else:\n",
    "                P_rt_c = P_down\n",
    "                \n",
    "            P_rt = P_up + P_down\n",
    "            tacho[idx] = P_rt_c / P_rt\n",
    "\n",
    "        \n",
    "        df_led_off_valid_trials_cond_filtered_copy = df_led_off_valid_trials_cond_filtered.copy()\n",
    "        df_led_off_valid_trials_cond_filtered_copy.loc[:, 'RT_bin'] = pd.cut(df_led_off_valid_trials_cond_filtered_copy['rt'] - df_led_off_valid_trials_cond_filtered_copy['t_stim'],\\\n",
    "                                                                    bins = bins, include_lowest=True)\n",
    "        grouped_by_rt_bin = df_led_off_valid_trials_cond_filtered_copy.groupby('RT_bin', observed=False)['correct'].agg(['mean', 'count'])\n",
    "        grouped_by_rt_bin['bin_mid'] = grouped_by_rt_bin.index.map(lambda x: x.mid)\n",
    "\n",
    "        ### Plot ###\n",
    "        FONT_SIZE_LABEL = 22   # for x/y labels\n",
    "        FONT_SIZE_TICKS = 22   # for x/y tick labels\n",
    "        FONT_SIZE_TITLE = 22   # for subplot titles\n",
    "        FONT_SIZE_INSET_TITLE = 22  # for inset bar plot title\n",
    "\n",
    "        # --------------------------\n",
    "        # Create a figure and a GridSpec with 3 columns,\n",
    "        # giving the third column more space (e.g., 1.4 times the width).\n",
    "        fig = plt.figure(figsize=(30, 8))\n",
    "        gs = gridspec.GridSpec(nrows=1, ncols=3, width_ratios=[1, 1, 1.4])\n",
    "\n",
    "        ax_rtd = fig.add_subplot(gs[0, 0])\n",
    "        ax_tacho = fig.add_subplot(gs[0, 1])\n",
    "        ax_corner = fig.add_subplot(gs[0, 2])\n",
    "\n",
    "        # ------------------------------------------------------------------------------\n",
    "        # 1) RTD Plot in ax_rtd\n",
    "        ax_rtd.plot(t_pts, up_wrt_stim, ls='--', color='r')\n",
    "        ax_rtd.plot(t_pts, -down_wrt_stim, ls='--', color='r')\n",
    "        ax_rtd.plot(bin_centers, data_up_rt_hist * frac_up_data, color='b')\n",
    "        ax_rtd.plot(bin_centers, -data_down_rt_hist * frac_down_data, color='b')\n",
    "\n",
    "        ax_rtd.set_xlim(0, 1)\n",
    "\n",
    "        # Set labels and title with custom font sizes\n",
    "        ax_rtd.set_xlabel('rt wrt stim', fontsize=FONT_SIZE_LABEL)\n",
    "        ax_rtd.set_ylabel('density', fontsize=FONT_SIZE_LABEL)\n",
    "        ax_rtd.set_title(\n",
    "            f\"Areas: +T:{theory_area_up:.3f},+E:{frac_up_data:.3f},\"\n",
    "            f\"-T:{theory_area_down:.3f},-E:{frac_down_data:.3f}\",\n",
    "            fontsize=FONT_SIZE_TITLE\n",
    "        )\n",
    "\n",
    "        # Increase tick label size\n",
    "        ax_rtd.tick_params(axis='both', which='major', labelsize=FONT_SIZE_TICKS)\n",
    "\n",
    "        # Inset bar chart\n",
    "        inset_ax = ax_rtd.inset_axes([0.65, 0.55, 0.3, 0.4])\n",
    "        bar_positions = [0, 1]\n",
    "        inset_ax.bar(bar_positions, accuracy_data_and_theory, color=['C0', 'C1'])\n",
    "        inset_ax.set_xticks(bar_positions)\n",
    "        inset_ax.set_xticklabels(['data', 'vbmc'], fontsize=FONT_SIZE_TICKS)\n",
    "        inset_ax.set_ylim(0, 1)\n",
    "        inset_ax.set_ylabel('accuracy', fontsize=FONT_SIZE_LABEL)\n",
    "        inset_ax.set_title(\n",
    "            f\"AL={conditions['ABL'][0]},ID={conditions['ILD'][0]}\",\n",
    "            fontsize=FONT_SIZE_INSET_TITLE\n",
    "        )\n",
    "        inset_ax.tick_params(axis='y', which='major', labelsize=FONT_SIZE_TICKS)\n",
    "\n",
    "        # ------------------------------------------------------------------------------\n",
    "        # 2) Tacho Plot in ax_tacho\n",
    "        ax_tacho.plot(t_pts, tacho, label='tacho')\n",
    "        ax_tacho.plot(grouped_by_rt_bin['bin_mid'], grouped_by_rt_bin['mean'], label='data')\n",
    "        ax_tacho.set_ylim(0.5, 1)\n",
    "\n",
    "        # Set labels and title with custom font sizes\n",
    "        ax_tacho.set_xlabel('rt - t_stim', fontsize=FONT_SIZE_LABEL)\n",
    "        ax_tacho.set_ylabel('accuracy', fontsize=FONT_SIZE_LABEL)\n",
    "        ax_tacho.set_title('btn stim start and stim + 1s', fontsize=FONT_SIZE_TITLE)\n",
    "\n",
    "        # Increase tick label size\n",
    "        ax_tacho.tick_params(axis='both', which='major', labelsize=FONT_SIZE_TICKS)\n",
    "        ax_tacho.legend(fontsize=FONT_SIZE_TICKS)\n",
    "\n",
    "\n",
    "        ## 3. Corner\n",
    "        fig_corner = corner.corner(\n",
    "            corner_samples,\n",
    "            labels=param_labels,\n",
    "            show_titles=True,\n",
    "            quantiles=[0.025, 0.5, 0.975],\n",
    "            range=_ranges,\n",
    "            title_fmt=\".4f\"\n",
    "        );\n",
    "\n",
    "\n",
    "        # Adjust subplots to reduce margins around the corner plot.\n",
    "        # Tweak left, right, bottom, top until the left whitespace is minimized.\n",
    "        fig_corner.subplots_adjust(left=0, right=0.95, bottom=0.15, top=0.9)\n",
    "\n",
    "        # Save with minimal padding\n",
    "        buf = io.BytesIO()\n",
    "        fig_corner.savefig(buf, format='png', bbox_inches='tight', pad_inches=0)\n",
    "        buf.seek(0)\n",
    "\n",
    "        # Read into an image array and close the figure\n",
    "        corner_img = plt.imread(buf)\n",
    "        plt.close(fig_corner)\n",
    "\n",
    "        # Now display in your third subplot\n",
    "        ax_corner.imshow(corner_img)\n",
    "        ax_corner.axis('off')\n",
    "        ax_corner.set_title('Corner Plot', fontsize=20, pad=0)\n",
    "\n",
    "        fname = f'each_cond_data/diagnostics_T_vary_w_ABL_{cond_ABL}_ILD_{cond_ILD}.png'\n",
    "        plt.savefig(fname, dpi=300, bbox_inches=\"tight\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "DOCX report created: T_vary_ABL_20_report.docx\n"
     ]
    }
   ],
   "source": [
    "from docx import Document\n",
    "from docx.shared import Inches\n",
    "import os\n",
    "\n",
    "def create_docx_report(abl_value, ild_values, image_folder=\".\"):\n",
    "    \"\"\"\n",
    "    Creates a DOCX report with diagnostics and corner plots for each ILD for a given ABL.\n",
    "\n",
    "    Args:\n",
    "        abl_value (int): The ABL value.\n",
    "        ild_values (list): A list of ILD values.\n",
    "        image_folder (str, optional): The folder containing the image files. Defaults to \".\".\n",
    "    \"\"\"\n",
    "\n",
    "    docx_filename = f\"T_vary_ABL_{abl_value}_report.docx\"\n",
    "    document = Document()\n",
    "\n",
    "    # Title page\n",
    "    document.add_heading(f'ABL {abl_value}', level=1)\n",
    "    document.add_page_break()\n",
    "\n",
    "    # Iterate through ILDs\n",
    "    for ild_value in ild_values:\n",
    "        diagnostics_filename = os.path.join(image_folder, f\"diagnostics_T_vary_w_ABL_{abl_value}_ILD_{ild_value}.png\")\n",
    "        corner_filename = os.path.join(image_folder, f\"corner_T_vary_w_each_cond_ABL_{abl_value}_ILD_{ild_value}.png\")\n",
    "\n",
    "        document.add_heading(f'ILD {ild_value}', level=2) # Subheading for ILD\n",
    "\n",
    "        if os.path.exists(diagnostics_filename) and os.path.exists(corner_filename):\n",
    "            document.add_picture(diagnostics_filename, width=Inches(5)) # Adjust width as needed\n",
    "            document.add_picture(corner_filename, width=Inches(5)) # Adjust width as needed\n",
    "        else:\n",
    "            document.add_paragraph(f\"Images not found for ILD {ild_value}\")\n",
    "\n",
    "        document.add_page_break() # New page for each ILD\n",
    "\n",
    "    document.save(docx_filename)\n",
    "    print(f\"DOCX report created: {docx_filename}\")\n",
    "\n",
    "\n",
    "all_ABLs_cond = [20]\n",
    "ild_values = [1, -1, 2, -2, 4, -4, 8, -8, 16, -16]\n",
    "\n",
    "for abl_value in all_ABLs_cond:\n",
    "    image_folder = \"each_cond_data\" # Assuming images are in 'each_cond_data' folder\n",
    "    create_docx_report(abl_value, ild_values, image_folder)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
