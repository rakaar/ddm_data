{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 123,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import pandas as pd\n",
    "import random\n",
    "from joblib import Parallel, delayed\n",
    "from tqdm.notebook import tqdm\n",
    "import numpy as np\n",
    "from scipy.integrate import quad\n",
    "from scipy.special import hyp2f1\n",
    "import math\n",
    "from scipy.integrate import trapezoid"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 126,
   "metadata": {},
   "outputs": [],
   "source": [
    "def erfcx(x):\n",
    "    # Define a vectorized function that forces each element to be a float.\n",
    "    vec_func = np.vectorize(lambda xi: math.exp(float(xi)*float(xi)) * math.erfc(float(xi)))\n",
    "    return vec_func(x)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 125,
   "metadata": {},
   "outputs": [],
   "source": [
    "# def my_erf(x):\n",
    "#     return math.erf(x)\n",
    "\n",
    "\n",
    "def my_erf(x):\n",
    "    \"\"\"Vectorized error function using math.erf.\"\"\"\n",
    "    # np.vectorize will apply math.erf element‐by‐element\n",
    "    return np.vectorize(math.erf)(x)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# decay check"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# simulator - psiam + tied decay"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def decay_amount_tied_fn(t, gamma, mu_d, sigma_d, alpha):\n",
    "    return np.exp(-t/gamma) +  (alpha / (1 + np.exp(-(t - mu_d) / sigma_d )))\n",
    "\n",
    "\n",
    "def simulate_psiam_tied_decay(V_A, theta_A, ABL, ILD, rate_lambda, T_0, theta_E, Z_E, t_stim, t_A_aff, t_E_aff, decay_params, dt):\n",
    "    AI = 0; DV = Z_E; t = 0; dB = dt**0.5\n",
    "    gamma, mu_d, sigma_d, alpha = (decay_params[k] for k in [\"gamma\", \"mu_d\", \"sigma_d\", \"alpha\"])\n",
    "\n",
    "    \n",
    "    chi = 17.37; q_e = 1\n",
    "    theta = theta_E * q_e\n",
    "    common = (2 / T_0) * (10 ** (rate_lambda * ABL / 20))\n",
    "\n",
    "    is_act = 0\n",
    "    while True:\n",
    "        if t > t_stim + t_E_aff:\n",
    "            decay = decay_amount_tied_fn(t - t_stim - t_E_aff, gamma, mu_d, sigma_d, alpha)\n",
    "            mu = common * (rate_lambda * ILD / chi) * decay\n",
    "            sigma = np.sqrt(common * decay)\n",
    "\n",
    "            DV += mu*dt + sigma*np.random.normal(0, dB)\n",
    "        \n",
    "        if t > t_A_aff:\n",
    "            AI += V_A*dt + np.random.normal(0, dB)\n",
    "        \n",
    "        t += dt\n",
    "        \n",
    "        if DV >= theta:\n",
    "            choice = +1; RT = t\n",
    "            break\n",
    "        elif DV <= -theta:\n",
    "            choice = -1; RT = t\n",
    "            break\n",
    "        \n",
    "        if AI >= theta_A:\n",
    "            is_act = 1\n",
    "            AI_hit_time = t\n",
    "            while t <= (AI_hit_time + t_E_aff):#  u can process evidence till stim plays\n",
    "                if t > t_stim + t_E_aff: # Evid accum wil begin only after stim starts and afferent delay\n",
    "                    decay = decay_amount_tied_fn(t - t_stim - t_E_aff, gamma, mu_d, sigma_d, alpha)\n",
    "                    mu = common * (rate_lambda * ILD / chi) * decay\n",
    "                    sigma = np.sqrt(common * decay)\n",
    "\n",
    "                    DV += mu*dt + sigma*np.random.normal(0, dB)\n",
    "                    if DV >= theta:\n",
    "                        DV = theta\n",
    "                        break\n",
    "                    elif DV <= -theta:\n",
    "                        DV = -theta\n",
    "                        break\n",
    "                t += dt\n",
    "            \n",
    "            break\n",
    "        \n",
    "        \n",
    "    if is_act == 1:\n",
    "        RT = AI_hit_time\n",
    "        if DV > 0:\n",
    "            choice = 1\n",
    "        elif DV < 0:\n",
    "            choice = -1\n",
    "        else: # if DV is 0 because stim has not yet been played, then choose right/left randomly\n",
    "            randomly_choose_up = np.random.rand() >= 0.5\n",
    "            if randomly_choose_up:\n",
    "                choice = 1\n",
    "            else:\n",
    "                choice = -1       \n",
    "    \n",
    "    return choice, RT, is_act\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# sim wrapper"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def psiam_tied_decay_data_gen_wrapper(V_A, theta_A, ABL_arr, ILD_arr, rate_lambda, T_0, theta_E, Z_E, t_stim_arr, t_A_aff, t_E_aff, decay_params, dt):\n",
    "    ABL = random.choice(ABL_arr)\n",
    "    ILD = random.choice(ILD_arr)\n",
    "    t_stim = random.choice(t_stim_arr)\n",
    "    \n",
    "    \n",
    "    choice, rt, is_act = simulate_psiam_tied_decay(V_A, theta_A, ABL, ILD, rate_lambda, T_0, theta_E, Z_E, t_stim, t_A_aff, t_E_aff, decay_params, dt)\n",
    "    return {'choice': choice, 'rt': rt, 'is_act': is_act ,'ABL': ABL, 'ILD': ILD, 't_stim': t_stim}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# get ABL ILD and stim"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# read out_LED.csv as dataframe\n",
    "og_df = pd.read_csv('../out_LED.csv')\n",
    "\n",
    "# chose non repeat trials - 0 or 2 or missing\n",
    "df = og_df[ og_df['repeat_trial'].isin([0,2]) | og_df['repeat_trial'].isna() ]\n",
    "\n",
    "# only session type 7\n",
    "session_type = 7    \n",
    "df = df[ df['session_type'].isin([session_type]) ]\n",
    "\n",
    "# training level 16\n",
    "training_level = 16\n",
    "df = df[ df['training_level'].isin([training_level]) ]\n",
    "\n",
    "df = df[  df['LED_trial'] == 0 ]\n",
    "\n",
    "# 1 is right , -1 is left\n",
    "df['choice'] = df['response_poke'].apply(lambda x: 1 if x == 3 else (-1 if x == 2 else random.choice([1, -1])))\n",
    "\n",
    "# 1 or 0 if the choice was correct or not\n",
    "df['correct'] = (df['ILD'] * df['choice']).apply(lambda x: 1 if x > 0 else 0)\n",
    "\n",
    "# find ABL and ILD\n",
    "ABL_arr = df['ABL'].unique()\n",
    "ILD_arr = df['ILD'].unique()\n",
    "\n",
    "\n",
    "# sort ILD arr in ascending order\n",
    "ILD_arr = np.sort(ILD_arr)\n",
    "ABL_arr = np.sort(ABL_arr)\n",
    "# t_stim_arr = np.random.choice(df['intended_fix'], N_sim)\n",
    "\n",
    "\n",
    "print('ABL:', ABL_arr)\n",
    "print('ILD:', ILD_arr)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Sim params"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# V_A, theta_A, ABL_arr, ILD_arr, rate_lambda, T_0, theta_E, Z_E, t_stim_arr, t_A_aff, t_E_aff, decay_params, dt\n",
    "V_A = 1.5\n",
    "theta_A = 2\n",
    "\n",
    "rate_lambda = 0.2\n",
    "T_0 = 1 * 1e-3\n",
    "theta_E = 20\n",
    "Z_E = 0\n",
    "t_A_aff = 70 * (1e-3)\n",
    "t_E_aff = 100 * (1e-3)\n",
    "# t_A_aff = 0\n",
    "# t_E_aff = 0\n",
    "\n",
    "gamma = 0.035\n",
    "mu_d = 0.1\n",
    "sigma_d = 0.05\n",
    "alpha = 0.3\n",
    "\n",
    "decay_params = {'gamma': gamma, 'mu_d': mu_d, 'sigma_d': sigma_d, 'alpha': alpha}\n",
    "# sim params\n",
    "\n",
    "N_sim = int(100e3)\n",
    "t_stim_arr = np.random.choice(df['intended_fix'], N_sim)\n",
    "\n",
    "dt = 1e-4\n",
    "K_max = 10"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sim_results = Parallel(n_jobs=30)(delayed(psiam_tied_decay_data_gen_wrapper)(V_A, theta_A, ABL_arr, ILD_arr, rate_lambda, T_0, theta_E, Z_E, t_stim_arr, t_A_aff, t_E_aff, decay_params, dt) for _ in tqdm(range(N_sim))) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "valid_sim_res = [res for res in sim_results if res['rt'] > res['t_stim']]\n",
    "print(f'frac of valid rt = {len(valid_sim_res)}/{N_sim} = {len(valid_sim_res)/N_sim}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "valid_rt_up = [res['rt'] - res['t_stim'] for res in valid_sim_res if res['choice'] == 1]\n",
    "valid_rt_down = [res['rt'] - res['t_stim'] for res in valid_sim_res if res['choice'] == -1]\n",
    "\n",
    "# hist\n",
    "bins = np.arange(0, 1, 0.01)\n",
    "valid_up_rt_hist, _ = np.histogram(valid_rt_up, bins=bins, density=True)\n",
    "valid_down_rt_hist, _ = np.histogram(valid_rt_down, bins=bins, density=True)\n",
    "\n",
    "\n",
    "plt.plot(bins[:-1], valid_up_rt_hist, label='up')\n",
    "plt.plot(bins[:-1], -valid_down_rt_hist, label='down')\n",
    "plt.legend()\n",
    "plt.title('histogram of valid rt');"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# likelihood theory and sim"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# rho A "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 127,
   "metadata": {},
   "outputs": [],
   "source": [
    "def rho_A_t_fn(t, V_A, theta_A):\n",
    "    \"\"\"\n",
    "    For AI,prob density of t given V_A, theta_A\n",
    "    \"\"\"\n",
    "    if t <= 0:\n",
    "        return 0\n",
    "    return (theta_A*1/np.sqrt(2*np.pi*(t)**3))*np.exp(-0.5 * (V_A**2) * (((t) - (theta_A/V_A))**2)/(t))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# P btn 1 and 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 128,
   "metadata": {},
   "outputs": [],
   "source": [
    "def decay_integral(t, gamma, mu_d, sigma_d, alpha):\n",
    "    part1 = gamma * (1 - np.exp(-t / gamma))\n",
    "\n",
    "    log_term_t = np.log(1 + np.exp((t - mu_d) / sigma_d))\n",
    "    log_term_0 = np.log(1 + np.exp(- mu_d / sigma_d))\n",
    "    part2 = alpha * sigma_d * (log_term_t - log_term_0)\n",
    "\n",
    "    return part1 + part2\n",
    "\n",
    "def Phi(x):\n",
    "    \"\"\"\n",
    "    Define the normal cumulative distribution function Φ(x) using erf\n",
    "    \"\"\"\n",
    "    return 0.5 * (1 + my_erf(x / np.sqrt(2)))\n",
    "\n",
    "def P_small_t_btn_x1_x2_vectorized(x1, x2, t, ABL, ILD, rate_lambda, T_0, theta_E, Z_E, decay_params, K_max):\n",
    "    \"\"\"\n",
    "    Vectorized version of the P_small_t_btn_x1_x2 function.\n",
    "    Computes the integration of P_small(x,t) between x1 and x2.\n",
    "    \"\"\"\n",
    "    gamma, mu_d, sigma_d, alpha = (decay_params[k] for k in [\"gamma\", \"mu_d\", \"sigma_d\", \"alpha\"])\n",
    "\n",
    "    if t <= 0:\n",
    "        return 0\n",
    "    \n",
    "    q_e = 1\n",
    "    theta = theta_E * q_e\n",
    "\n",
    "    chi = 17.37\n",
    "    mu = theta_E * (rate_lambda * ILD / chi)\n",
    "    z = (Z_E / theta) + 1.0\n",
    "\n",
    "    # Compute t_theta and normalize t\n",
    "    omega = (2 / (T_0 * (theta_E**2))) * (10 ** (rate_lambda * ABL / 20))  \n",
    "    t_normalized = omega * decay_integral(t, gamma, mu_d, sigma_d, alpha)\n",
    "\n",
    "    # Compute sqrt(t_normalized)\n",
    "    sqrt_t = np.sqrt(t_normalized)\n",
    "    \n",
    "    # Handle potential division by zero\n",
    "    sqrt_t = np.where(sqrt_t == 0, 1e-10, sqrt_t)\n",
    "\n",
    "    # Create an array of n values from -K_max to K_max inclusive\n",
    "    n = np.arange(-K_max, K_max + 1)\n",
    "\n",
    "    # Compute exponentials for term1 and term2\n",
    "    exp_term1 = np.exp(4 * mu * n)\n",
    "    exp_term2 = np.exp(2 * mu * (2 * (1 - n) - z))\n",
    "\n",
    "    # Compute arguments for Phi functions in term1\n",
    "    phi1_upper = (x2 - (z + 4 * n + mu * t_normalized)) / sqrt_t\n",
    "    phi1_lower = (x1 - (z + 4 * n + mu * t_normalized)) / sqrt_t\n",
    "\n",
    "    # Compute Phi for term1\n",
    "    Phi_term1 = Phi(phi1_upper) - Phi(phi1_lower)\n",
    "\n",
    "    # Compute arguments for Phi functions in term2\n",
    "    phi2_upper = (x2 - (-z + 4 * (1 - n) + mu * t_normalized)) / sqrt_t\n",
    "    phi2_lower = (x1 - (-z + 4 * (1 - n) + mu * t_normalized)) / sqrt_t\n",
    "\n",
    "    # Compute Phi for term2\n",
    "    Phi_term2 = Phi(phi2_upper) - Phi(phi2_lower)\n",
    "\n",
    "    # Compute term1 and term2\n",
    "    term1 = exp_term1 * Phi_term1\n",
    "    term2 = exp_term2 * Phi_term2\n",
    "\n",
    "    # Compute the result by summing over all n\n",
    "    result = np.sum(term1 - term2)\n",
    "\n",
    "    return result\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# CDF E minus"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 129,
   "metadata": {},
   "outputs": [],
   "source": [
    "def M(x):\n",
    "    \"\"\"Mills ratio.\"\"\"\n",
    "    x = np.clip(x, -20, 20)\n",
    "    return np.sqrt(np.pi / 2) * erfcx(x / np.sqrt(2))\n",
    "\n",
    "\n",
    "def phi(x):\n",
    "    \"\"\"Standard Gaussian function.\"\"\"\n",
    "    return (1 / np.sqrt(2 * np.pi)) * np.exp(-0.5 * x**2)\n",
    "\n",
    "def CDF_E_minus_small_t_NORM_fn_vectorized(t, ABL, ILD, rate_lambda, T_0, theta_E, Z_E, bound, decay_params, K_max):\n",
    "    \"\"\"\n",
    "    Vectorized version of the CDF of hitting the lower bound in normalized time.\n",
    "    Utilizes custom phi and M functions.\n",
    "\n",
    "    Parameters:\n",
    "    - t (float or np.ndarray): Time variable(s).\n",
    "    - ABL, ILD, rate_lambda, T_0, theta_E, Z_E (float): Model parameters.\n",
    "    - bound (int): Bound flag (0 or 1).\n",
    "    - K_max (int): Maximum k value for summation.\n",
    "\n",
    "    Returns:\n",
    "    - np.ndarray: CDF values corresponding to each t.\n",
    "    \"\"\"\n",
    "    gamma, mu_d, sigma_d, alpha = (decay_params[k] for k in [\"gamma\", \"mu_d\", \"sigma_d\", \"alpha\"])\n",
    "\n",
    "    # Convert t to a NumPy array for vectorized operations\n",
    "    t = np.asarray(t, dtype=np.float64)\n",
    "    \n",
    "    # Initialize the CDF result array with zeros\n",
    "    CDF = np.zeros_like(t, dtype=np.float64)\n",
    "    \n",
    "    # Create a boolean mask where t > 0\n",
    "    mask = t > 0\n",
    "    \n",
    "    if not np.any(mask):\n",
    "        # If all t <= 0, return the initialized CDF (all zeros)\n",
    "        return CDF\n",
    "    \n",
    "    # Extract only the t values where t > 0 for computation\n",
    "    t_valid = t[mask]\n",
    "    \n",
    "    q_e = 1\n",
    "    theta = theta_E * q_e\n",
    "\n",
    "    chi = 17.37\n",
    "    v = theta_E * (rate_lambda * ILD / chi)\n",
    "    w = (Z_E + theta) / (2 * theta)\n",
    "    a = 2\n",
    "    if bound == 1:\n",
    "        v = -v\n",
    "        w = 1 - w\n",
    "\n",
    "    # Compute t_theta and normalize t\n",
    "    omega = (2 / (T_0 * (theta_E**2))) * (10 ** (rate_lambda * ABL / 20))  \n",
    "    t_normalized = omega * decay_integral(t_valid, gamma, mu_d, sigma_d, alpha)\n",
    "\n",
    "    # Compute the exponential component of the CDF\n",
    "    result = np.exp(-v * a * w - ((v ** 2) * t_normalized) / 2)\n",
    "\n",
    "    # Create the k array\n",
    "    k = np.arange(K_max + 1)\n",
    "    \n",
    "    # Determine even indices\n",
    "    is_even = (k % 2 == 0).astype(float)\n",
    "    \n",
    "    # Compute r_k using broadcasting\n",
    "    r_k = k * a + a * np.where(is_even, w, 1 - w)  # Shape: (K_max + 1,)\n",
    "    \n",
    "    # Compute sqrt(t_normalized) and handle zero to avoid division by zero\n",
    "    sqrt_t = np.sqrt(t_normalized)\n",
    "    sqrt_t = np.where(sqrt_t == 0, 1e-10, sqrt_t)  # Shape: (num_valid_t,)\n",
    "    \n",
    "    # Reshape r_k and sqrt_t for broadcasting\n",
    "    # r_k: (K_max +1, 1)\n",
    "    # sqrt_t: (1, num_valid_t)\n",
    "    # This allows broadcasting to compute r_k / sqrt_t for all combinations\n",
    "    r_k = r_k[:, np.newaxis]  # Shape: (K_max +1, 1)\n",
    "    sqrt_t = sqrt_t[np.newaxis, :]  # Shape: (1, num_valid_t)\n",
    "    \n",
    "    phi_args = r_k / sqrt_t  # Shape: (K_max +1, num_valid_t)\n",
    "    \n",
    "    M_args_positive = (r_k - v * t_normalized) / sqrt_t  # Shape: (K_max +1, num_valid_t)\n",
    "    M_args_negative = (r_k + v * t_normalized) / sqrt_t  # Shape: (K_max +1, num_valid_t)\n",
    "    \n",
    "    assert np.all(np.isfinite(phi_args)), \"phi_args contains invalid values\"\n",
    "    assert np.all(np.isfinite(M_args_positive)), \"M_args_positive contains invalid values\"\n",
    "    assert np.all(np.isfinite(M_args_negative)), \"M_args_negative contains invalid values\"\n",
    "\n",
    "       \n",
    "    phi_vals = phi(phi_args)  # Assuming phi is vectorized: Shape: (K_max +1, num_valid_t)\n",
    "    M_vals = M(M_args_positive) + M(M_args_negative)  # Assuming M is vectorized\n",
    "\n",
    "    ### M values are infinitely large for inputs less than -10 ###\n",
    "    invalid_M_vals = ~np.isfinite(M_vals)\n",
    "    if np.any(invalid_M_vals):\n",
    "        print(\"Invalid M_vals detected:\")\n",
    "        invalid_indices = np.argwhere(invalid_M_vals)\n",
    "        num_to_print = min(2, len(invalid_indices))\n",
    "        for i in range(num_to_print):\n",
    "            k_idx, t_idx = invalid_indices[i]\n",
    "            print(f\"M_vals[{k_idx}, {t_idx}] = {M_vals[k_idx, t_idx]}\")\n",
    "            print(f\"M_args_positive[{k_idx}, {t_idx}] = {M_args_positive[k_idx, t_idx]}\")\n",
    "            print(f\"M_args_negative[{k_idx}, {t_idx}] = {M_args_negative[k_idx, t_idx]}\")\n",
    "            print(\"---\")\n",
    "\n",
    "    assert np.all(np.isfinite(M_vals)), \"M_vals contains invalid values\"\n",
    "    \n",
    "    sign = (-1) ** k  # Shape: (K_max +1,)\n",
    "    sign = sign[:, np.newaxis]  # Shape: (K_max +1, 1)\n",
    "    \n",
    "    summation = np.sum(sign * phi_vals * M_vals, axis=0)  # Shape: (num_valid_t,)\n",
    "    \n",
    "    CDF_valid = result * summation  # Shape: (num_valid_t,)\n",
    "    \n",
    "    CDF[mask] = CDF_valid\n",
    "    \n",
    "    return CDF\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# rho E minus"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 130,
   "metadata": {},
   "outputs": [],
   "source": [
    "def rho_E_minus_small_t_NORM_fn(t, ABL, ILD, rate_lambda, T_0, theta_E, Z_E, bound, decay_params, K_max):\n",
    "    \"\"\"\n",
    "    in normalized time, PDF of hitting the lower bound\n",
    "    \"\"\"\n",
    "    gamma, mu_d, sigma_d, alpha = (decay_params[k] for k in [\"gamma\", \"mu_d\", \"sigma_d\", \"alpha\"])\n",
    "\n",
    "    if t <= 0:\n",
    "        return 0\n",
    "    \n",
    "    q_e = 1\n",
    "    theta = theta_E*q_e \n",
    "\n",
    "    chi = 17.37\n",
    "    v = theta_E * (rate_lambda * ILD / chi)\n",
    "    w = (Z_E + theta)/(2*theta)\n",
    "    a = 2\n",
    "    if bound == 1:\n",
    "        v = -v\n",
    "        w = 1 - w\n",
    "\n",
    "    # t_theta = T_0 * (theta_E**2) * (10**(-rate_lambda*ABL/20)) * (1/(2*np.cosh(rate_lambda*ILD/chi)))\n",
    "    # t /= t_theta\n",
    "    # Compute t_theta and normalize t\n",
    "    omega = (2 / (T_0 * (theta_E**2))) * (10 ** (rate_lambda * ABL / 20))  \n",
    "    dtau_by_dt = omega * decay_amount_tied_fn(t, gamma, mu_d, sigma_d, alpha)\n",
    "    \n",
    "    t = omega * decay_integral(t, gamma, mu_d, sigma_d, alpha)\n",
    "\n",
    "    non_sum_term = (1/a**2)*(a**3/np.sqrt(2*np.pi*t**3))*np.exp(-v*a*w - (v**2 * t)/2)\n",
    "    K_max = int(K_max/2)\n",
    "    k_vals = np.linspace(-K_max, K_max, 2*K_max + 1)\n",
    "    sum_w_term = w + 2*k_vals\n",
    "    sum_exp_term = np.exp(-(a**2 * (w + 2*k_vals)**2)/(2*t))\n",
    "    sum_result = np.sum(sum_w_term*sum_exp_term)\n",
    "\n",
    "    \n",
    "    density =  non_sum_term * sum_result\n",
    "    if density <= 0:\n",
    "        density = 1e-16\n",
    "\n",
    "    return density * dtau_by_dt\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# cum A "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 131,
   "metadata": {},
   "outputs": [],
   "source": [
    "def cum_A_t_fn(t, V_A, theta_A):\n",
    "    \"\"\"\n",
    "    For AI, calculate cummulative distrn of a time t given V_A, theta_A\n",
    "    \"\"\"\n",
    "    if t <= 0:\n",
    "        return 0\n",
    "\n",
    "    term1 = Phi(V_A * ((t) - (theta_A/V_A)) / np.sqrt(t))\n",
    "    term2 = np.exp(2 * V_A * theta_A) * Phi(-V_A * ((t) + (theta_A / V_A)) / np.sqrt(t))\n",
    "    return term1 + term2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 132,
   "metadata": {},
   "outputs": [],
   "source": [
    "def up_RTs_fit_fn(t_pts, V_A, theta_A, ABL, ILD, rate_lambda, T_0, theta_E, Z_E, t_stim, t_A_aff, t_E_aff, decay_params ,K_max):\n",
    "    \"\"\"\n",
    "    PDF of up RTs array\n",
    "    \"\"\"\n",
    "    bound = 1\n",
    "\n",
    "    P_A = [rho_A_t_fn(t-t_A_aff, V_A, theta_A) for t in t_pts]\n",
    "    P_EA_btn_1_2 = [P_small_t_btn_x1_x2_vectorized(1, 2, t - t_stim, ABL, ILD, rate_lambda, T_0, theta_E, Z_E, decay_params, K_max) for t in t_pts]\n",
    "    P_E_plus_cum = np.zeros(len(t_pts))\n",
    "    for i,t in enumerate(t_pts):\n",
    "        t1 = t - t_stim - t_E_aff\n",
    "        t2 = t - t_stim\n",
    "        P_E_plus_cum[i] = CDF_E_minus_small_t_NORM_fn_vectorized(t2, ABL, ILD, rate_lambda, T_0, theta_E, Z_E, bound, decay_params, K_max) \\\n",
    "                    - CDF_E_minus_small_t_NORM_fn_vectorized(t1, ABL, ILD, rate_lambda, T_0, theta_E, Z_E, bound, decay_params, K_max)\n",
    "\n",
    "\n",
    "    P_E_plus = [rho_E_minus_small_t_NORM_fn(t-t_E_aff-t_stim, ABL, ILD, rate_lambda, T_0, theta_E, Z_E, bound, decay_params, K_max) for t in t_pts]\n",
    "    C_A = [cum_A_t_fn(t-t_A_aff, V_A, theta_A) for t in t_pts]\n",
    "\n",
    "    P_A = np.array(P_A); P_EA_btn_1_2 = np.array(P_EA_btn_1_2); P_E_plus = np.array(P_E_plus); C_A = np.array(C_A)\n",
    "    P_correct_unnorm = (P_A*(P_EA_btn_1_2 + P_E_plus_cum) + P_E_plus*(1-C_A))\n",
    "    return P_correct_unnorm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 133,
   "metadata": {},
   "outputs": [],
   "source": [
    "def down_RTs_fit_fn(t_pts, V_A, theta_A, ABL, ILD, rate_lambda, T_0, theta_E, Z_E, t_stim, t_A_aff, t_E_aff, decay_params ,K_max):\n",
    "    \"\"\"\n",
    "    PDF of up RTs array\n",
    "    \"\"\"\n",
    "    bound = -1\n",
    "\n",
    "    P_A = [rho_A_t_fn(t-t_A_aff, V_A, theta_A) for t in t_pts]\n",
    "    P_EA_btn_1_2 = [P_small_t_btn_x1_x2_vectorized(0, 1, t - t_stim, ABL, ILD, rate_lambda, T_0, theta_E, Z_E, decay_params, K_max) for t in t_pts]\n",
    "    P_E_plus_cum = np.zeros(len(t_pts))\n",
    "    for i,t in enumerate(t_pts):\n",
    "        t1 = t - t_stim - t_E_aff\n",
    "        t2 = t - t_stim\n",
    "        P_E_plus_cum[i] = CDF_E_minus_small_t_NORM_fn_vectorized(t2, ABL, ILD, rate_lambda, T_0, theta_E, Z_E, bound, decay_params, K_max) \\\n",
    "                    - CDF_E_minus_small_t_NORM_fn_vectorized(t1, ABL, ILD, rate_lambda, T_0, theta_E, Z_E, bound, decay_params, K_max)\n",
    "\n",
    "\n",
    "    P_E_plus = [rho_E_minus_small_t_NORM_fn(t-t_E_aff-t_stim, ABL, ILD, rate_lambda, T_0, theta_E, Z_E, bound, decay_params, K_max) for t in t_pts]\n",
    "    C_A = [cum_A_t_fn(t-t_A_aff, V_A, theta_A) for t in t_pts]\n",
    "\n",
    "    P_A = np.array(P_A); P_EA_btn_1_2 = np.array(P_EA_btn_1_2); P_E_plus = np.array(P_E_plus); C_A = np.array(C_A)\n",
    "    P_correct_unnorm = (P_A*(P_EA_btn_1_2 + P_E_plus_cum) + P_E_plus*(1-C_A))\n",
    "    return P_correct_unnorm"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# testing likelihood fn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 134,
   "metadata": {},
   "outputs": [],
   "source": [
    "# t_pts = np.arange(0, 1, 0.01)\n",
    "# ABL = ABL_arr[0]\n",
    "# ILD = ILD_arr[0]\n",
    "# t_stim = t_stim_arr[0] \n",
    "# theory_up_rt = up_RTs_fit_fn(t_pts, V_A, theta_A, ABL, ILD, rate_lambda, T_0, theta_E, Z_E, t_stim, t_A_aff, t_E_aff, decay_params, 10)\n",
    "# theory_down_rt = down_RTs_fit_fn(t_pts, V_A, theta_A, ABL, ILD, rate_lambda, T_0, theta_E, Z_E, t_stim, t_A_aff, t_E_aff, decay_params, 10)\n",
    "# bins = np.arange(0, 1, 0.01)\n",
    "# plt.plot(t_pts-t_stim, theory_up_rt, color='r', ls='--')\n",
    "# plt.plot(t_pts-t_stim, -theory_down_rt, color='r', ls='--', label='theory')\n",
    "\n",
    "# valid_up_rt_hist, _ = np.histogram(valid_rt_up, bins=bins, density=True)\n",
    "# valid_down_rt_hist, _ = np.histogram(valid_rt_down, bins=bins, density=True)\n",
    "\n",
    "# N_up = len(valid_rt_up)\n",
    "# N_down = len(valid_rt_down)\n",
    "\n",
    "# plt.plot(bins[:-1], valid_up_rt_hist*(N_up/N_sim), label='up')\n",
    "# plt.plot(bins[:-1], -valid_down_rt_hist*(N_down/N_sim), label='down')\n",
    "\n",
    "# plt.legend()\n",
    "# plt.title('histogram of valid rt');\n",
    "\n",
    "# # data\n",
    "# print(f'area under theory = {trapezoid(theory_up_rt, t_pts)}')\n",
    "# print(f'area under sim = {trapezoid(valid_up_rt_hist, bins[:-1]) * (N_up/N_sim)}')\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# VBMC"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## loglike"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 135,
   "metadata": {},
   "outputs": [],
   "source": [
    "def compute_loglike(row, rate_lambda, T_0, theta_E, t_E_aff, Z_E, gamma, mu_d, sigma_d, alpha):\n",
    "    \n",
    "    ILD = row['ILD']\n",
    "    ABL = row['ABL']\n",
    "    choice = row['choice']\n",
    "\n",
    "    rt = row['rt']\n",
    "    t_stim = row['t_stim']\n",
    "    \n",
    "    K_max = 10\n",
    "    decay_params = {'gamma': gamma, 'mu_d': mu_d, 'sigma_d': sigma_d, 'alpha': alpha}\n",
    "    if choice == 1:\n",
    "        likelihood = up_RTs_fit_fn([rt], V_A, theta_A, ABL, ILD, rate_lambda, T_0, theta_E, Z_E, t_stim, t_A_aff, t_E_aff, decay_params ,K_max)[0]\n",
    "    elif choice == -1:\n",
    "        likelihood = down_RTs_fit_fn([rt], V_A, theta_A, ABL, ILD, rate_lambda, T_0, theta_E, Z_E, t_stim, t_A_aff, t_E_aff, decay_params ,K_max)[0]\n",
    "\n",
    "\n",
    "    if likelihood <= 0:\n",
    "        likelihood = 1e-50\n",
    "\n",
    "    \n",
    "    return np.log(likelihood)    \n",
    "\n",
    "\n",
    "def psiam_tied_loglike_fn(params):\n",
    "    rate_lambda, T_0, theta_E, t_E_aff, Z_E, gamma, mu_d, sigma_d, alpha = params\n",
    "\n",
    "\n",
    "    all_loglike = Parallel(n_jobs=-1)(delayed(compute_loglike)(row, rate_lambda, T_0, theta_E, t_E_aff, Z_E, gamma, mu_d, sigma_d, alpha)\\\n",
    "                                       for row in sim_results if row['rt'] > row['t_stim'])\n",
    "\n",
    "    loglike = np.sum(all_loglike)\n",
    "    return loglike"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Bounds"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 136,
   "metadata": {},
   "outputs": [],
   "source": [
    "rate_lambda_bounds = [0.05, 0.3]         # true = 0.2\n",
    "T_0_bounds         = [0.5e-3, 1.5e-3]     # true = 1e-3\n",
    "theta_E_bounds     = [10, 30]             # true = 20\n",
    "t_E_aff_bounds     = [0.05, 0.15]         # true = 0.10 sec\n",
    "Z_E_bounds         = [-10, 10]            # true = 0\n",
    "\n",
    "gamma_bounds       = [0.01, 0.1]          # true = 0.035\n",
    "mu_d_bounds        = [0.05, 0.15]         # true = 0.1\n",
    "sigma_d_bounds     = [0.01, 0.1]          # true = 0.05\n",
    "alpha_bounds       = [0.1, 0.5]           # true = 0.3\n",
    "\n",
    "### \n",
    "rate_lambda_plausible_bounds = [0.15, 0.25]\n",
    "T_0_plausible_bounds         = [0.8e-3, 1.2e-3]\n",
    "theta_E_plausible_bounds     = [15, 25]\n",
    "t_E_aff_plausible_bounds     = [0.08, 0.12]\n",
    "Z_E_plausible_bounds         = [-5, 5]\n",
    "\n",
    "gamma_plausible_bounds       = [0.03, 0.05]\n",
    "mu_d_plausible_bounds        = [0.08, 0.12]\n",
    "sigma_d_plausible_bounds     = [0.03, 0.07]\n",
    "alpha_plausible_bounds       = [0.25, 0.35]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# prior"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 137,
   "metadata": {},
   "outputs": [],
   "source": [
    "def trapezoidal_logpdf(x, a, b, c, d):\n",
    "    if x < a or x > d:\n",
    "        return -np.inf  # Logarithm of zero\n",
    "    area = ((b - a) + (d - c)) / 2 + (c - b)\n",
    "    h_max = 1.0 / area  # Height of the trapezoid to normalize the area to 1\n",
    "    \n",
    "    if a <= x <= b:\n",
    "        pdf_value = ((x - a) / (b - a)) * h_max\n",
    "    elif b < x < c:\n",
    "        pdf_value = h_max\n",
    "    elif c <= x <= d:\n",
    "        pdf_value = ((d - x) / (d - c)) * h_max\n",
    "    else:\n",
    "        pdf_value = 0.0  # This case is redundant due to the initial check\n",
    "\n",
    "    if pdf_value <= 0.0:\n",
    "        return -np.inf\n",
    "    else:\n",
    "        return np.log(pdf_value)\n",
    "    \n",
    "\n",
    "def psiam_tied_prior_fn(params):\n",
    "    rate_lambda, T_0, theta_E, t_E_aff, Z_E, gamma, mu_d, sigma_d, alpha = params\n",
    "\n",
    "    rate_lambda_logpdf = trapezoidal_logpdf(rate_lambda, rate_lambda_bounds[0], rate_lambda_plausible_bounds[0], rate_lambda_plausible_bounds[1], rate_lambda_bounds[1])\n",
    "    T_0_logpdf = trapezoidal_logpdf(T_0, T_0_bounds[0], T_0_plausible_bounds[0], T_0_plausible_bounds[1], T_0_bounds[1])\n",
    "    theta_E_logpdf = trapezoidal_logpdf(theta_E, theta_E_bounds[0], theta_E_plausible_bounds[0], theta_E_plausible_bounds[1], theta_E_bounds[1])\n",
    "    \n",
    "    t_E_aff_logpdf = trapezoidal_logpdf(t_E_aff, t_E_aff_bounds[0], t_E_aff_plausible_bounds[0], t_E_aff_plausible_bounds[1], t_E_aff_bounds[1])\n",
    "    Z_E_logpdf = trapezoidal_logpdf(Z_E, Z_E_bounds[0], Z_E_plausible_bounds[0], Z_E_plausible_bounds[1], Z_E_bounds[1])\n",
    "    gamma_logpdf = trapezoidal_logpdf(gamma, gamma_bounds[0], gamma_plausible_bounds[0], gamma_plausible_bounds[1], gamma_bounds[1])\n",
    "    mu_d_logpdf = trapezoidal_logpdf(mu_d, mu_d_bounds[0], mu_d_plausible_bounds[0], mu_d_plausible_bounds[1], mu_d_bounds[1])\n",
    "    sigma_d_logpdf = trapezoidal_logpdf(sigma_d, sigma_d_bounds[0], sigma_d_plausible_bounds[0], sigma_d_plausible_bounds[1], sigma_d_bounds[1])\n",
    "    alpha_logpdf = trapezoidal_logpdf(alpha, alpha_bounds[0], alpha_plausible_bounds[0], alpha_plausible_bounds[1], alpha_bounds[1])\n",
    "\n",
    "    return rate_lambda_logpdf + T_0_logpdf + theta_E_logpdf + t_E_aff_logpdf + Z_E_logpdf + gamma_logpdf + mu_d_logpdf + sigma_d_logpdf + alpha_logpdf\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# prior + loglike"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 138,
   "metadata": {},
   "outputs": [],
   "source": [
    "def psiam_tied_joint_fn(params):\n",
    "    priors = psiam_tied_prior_fn(params) \n",
    "    loglike = psiam_tied_loglike_fn(params)\n",
    "\n",
    "    joint = priors + loglike\n",
    "    return joint"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# run vbmc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 139,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Lower bounds (lb)\n",
    "lb = np.array([\n",
    "    rate_lambda_bounds[0],    # rate_lambda lower bound\n",
    "    T_0_bounds[0],            # T_0 lower bound\n",
    "    theta_E_bounds[0],        # theta_E lower bound\n",
    "    t_E_aff_bounds[0],        # t_E_aff lower bound\n",
    "    Z_E_bounds[0],            # Z_E lower bound\n",
    "    gamma_bounds[0],          # gamma lower bound\n",
    "    mu_d_bounds[0],           # mu_d lower bound\n",
    "    sigma_d_bounds[0],        # sigma_d lower bound\n",
    "    alpha_bounds[0]           # alpha lower bound\n",
    "])\n",
    "\n",
    "# Upper bounds (ub)\n",
    "ub = np.array([\n",
    "    rate_lambda_bounds[1],    # rate_lambda upper bound\n",
    "    T_0_bounds[1],            # T_0 upper bound\n",
    "    theta_E_bounds[1],        # theta_E upper bound\n",
    "    t_E_aff_bounds[1],        # t_E_aff upper bound\n",
    "    Z_E_bounds[1],            # Z_E upper bound\n",
    "    gamma_bounds[1],          # gamma upper bound\n",
    "    mu_d_bounds[1],           # mu_d upper bound\n",
    "    sigma_d_bounds[1],        # sigma_d upper bound\n",
    "    alpha_bounds[1]           # alpha upper bound\n",
    "])\n",
    "\n",
    "# Plausible lower bounds (plb)\n",
    "plb = np.array([\n",
    "    rate_lambda_plausible_bounds[0],\n",
    "    T_0_plausible_bounds[0],\n",
    "    theta_E_plausible_bounds[0],\n",
    "    t_E_aff_plausible_bounds[0],\n",
    "    Z_E_plausible_bounds[0],\n",
    "    gamma_plausible_bounds[0],\n",
    "    mu_d_plausible_bounds[0],\n",
    "    sigma_d_plausible_bounds[0],\n",
    "    alpha_plausible_bounds[0]\n",
    "])\n",
    "\n",
    "# Plausible upper bounds (pub)\n",
    "pub = np.array([\n",
    "    rate_lambda_plausible_bounds[1],\n",
    "    T_0_plausible_bounds[1],\n",
    "    theta_E_plausible_bounds[1],\n",
    "    t_E_aff_plausible_bounds[1],\n",
    "    Z_E_plausible_bounds[1],\n",
    "    gamma_plausible_bounds[1],\n",
    "    mu_d_plausible_bounds[1],\n",
    "    sigma_d_plausible_bounds[1],\n",
    "    alpha_plausible_bounds[1]\n",
    "])\n",
    "\n",
    "# --------------------------------------------------\n",
    "# Next, set an initial guess (x0) for the parameters by drawing\n",
    "# uniformly from the plausible bounds.\n",
    "# --------------------------------------------------\n",
    "np.random.seed(42)  # for reproducibility\n",
    "\n",
    "rate_lambda_0 = np.random.uniform(rate_lambda_plausible_bounds[0], rate_lambda_plausible_bounds[1])\n",
    "T_0_0         = np.random.uniform(T_0_plausible_bounds[0], T_0_plausible_bounds[1])\n",
    "theta_E_0     = np.random.uniform(theta_E_plausible_bounds[0], theta_E_plausible_bounds[1])\n",
    "t_E_aff_0     = np.random.uniform(t_E_aff_plausible_bounds[0], t_E_aff_plausible_bounds[1])\n",
    "Z_E_0         = np.random.uniform(Z_E_plausible_bounds[0], Z_E_plausible_bounds[1])\n",
    "gamma_0       = np.random.uniform(gamma_plausible_bounds[0], gamma_plausible_bounds[1])\n",
    "mu_d_0        = np.random.uniform(mu_d_plausible_bounds[0], mu_d_plausible_bounds[1])\n",
    "sigma_d_0     = np.random.uniform(sigma_d_plausible_bounds[0], sigma_d_plausible_bounds[1])\n",
    "alpha_0       = np.random.uniform(alpha_plausible_bounds[0], alpha_plausible_bounds[1])\n",
    "\n",
    "# Combine the initial parameter values in the correct order:\n",
    "x0 = np.array([\n",
    "    rate_lambda_0,\n",
    "    T_0_0,\n",
    "    theta_E_0,\n",
    "    t_E_aff_0,\n",
    "    Z_E_0,\n",
    "    gamma_0,\n",
    "    mu_d_0,\n",
    "    sigma_d_0,\n",
    "    alpha_0\n",
    "])\n",
    "\n",
    "# --------------------------------------------------\n",
    "# Now you can use these in your VBMC call (or any optimization routine)\n",
    "# --------------------------------------------------\n",
    "# For example:\n",
    "# vbmc = VBMC(psiam_tied_joint_fn, x0, lb, ub, plb, pub, options={'display': 'on'})\n",
    "# vp, results = vbmc.optimize()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyvbmc import VBMC\n",
    "\n",
    "vbmc = VBMC(psiam_tied_joint_fn, x0, lb, ub, plb, pub, options={'display': 'on'})\n",
    "vp, results = vbmc.optimize()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "vbmc.save('psiam_tied_decay_sim_fit_vbmc.pkl')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
