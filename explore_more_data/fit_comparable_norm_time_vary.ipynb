{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Didn't converge, better to fit aborts seperately first"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import pandas as pd\n",
    "from tqdm import tqdm\n",
    "from joblib import Parallel, delayed\n",
    "from pyvbmc import VBMC\n",
    "import corner\n",
    "from tqdm.notebook import tqdm\n",
    "import pickle\n",
    "import random\n",
    "from scipy.integrate import cumulative_trapezoid as cumtrapz\n",
    "\n",
    "from time_vary_norm_utils import (\n",
    "    up_or_down_RTs_fit_fn, cum_pro_and_reactive_time_vary_fn,\n",
    "    rho_A_t_VEC_fn, up_or_down_RTs_fit_wrt_stim_fn, rho_A_t_fn, cum_A_t_fn,\n",
    "    CDF_E_minus_small_t_NORM_rate_norm_l_time_varying_fn, rho_E_minus_small_t_NORM_rate_norm_time_varying_fn)\n",
    "from types import SimpleNamespace\n",
    "from time_vary_and_norm_simulators import psiam_tied_data_gen_wrapper_rate_norm_fn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "######## TEMP ########\n",
    "def up_or_down_RTs_fit_PA_C_A_given_wrt_t_stim_fn(\n",
    "        t, bound,\n",
    "        P_A, C_A,\n",
    "        ABL, ILD, rate_lambda, T0, theta_E, Z_E, t_E_aff, del_go,\n",
    "        phi_params, rate_norm_l, \n",
    "        is_norm, is_time_vary, K_max):\n",
    "    \n",
    "    # t1, t2 - if proactive wins, time range in which EA can hit bound and confirm a choice\n",
    "    t1 = max(t - t_E_aff, 1e-6)\n",
    "    t2 = max(t - t_E_aff + del_go, 1e-6)\n",
    "\n",
    "    # phi(t) and its integral for different times\n",
    "    if is_time_vary:\n",
    "        int_phi_t_E_g = int_phi_fn(max(t - t_E_aff + del_go, 1e-6), phi_params.h1, phi_params.a1, phi_params.b1, phi_params.h2, phi_params.a2)\n",
    "\n",
    "        phi_t_e = phi_t_fn(max(t - t_E_aff, 1e-6), phi_params.h1, phi_params.a1, phi_params.b1, phi_params.h2, phi_params.a2)\n",
    "        int_phi_t_e = int_phi_fn(max(t - t_E_aff, 1e-6), phi_params.h1, phi_params.a1, phi_params.b1, phi_params.h2, phi_params.a2)\n",
    "\n",
    "        int_phi_t2 = int_phi_fn(t2, phi_params.h1, phi_params.a1, phi_params.b1, phi_params.h2, phi_params.a2)\n",
    "        int_phi_t1 = int_phi_fn(t1, phi_params.h1, phi_params.a1, phi_params.b1, phi_params.h2, phi_params.a2)\n",
    "\n",
    "        if int_phi_t_E_g * int_phi_t_e * int_phi_t2 * int_phi_t1 == 0:\n",
    "            raise ValueError(\n",
    "                f'''\n",
    "                t = {t}, t_E_aff = {t_E_aff}\n",
    "                t1 = {t1}\n",
    "                one of them is zero\n",
    "                int_phi_t_E_g = {int_phi_t_E_g}\n",
    "                int_phi_t_e = {int_phi_t_e}\n",
    "                int_phi_t2 = {int_phi_t2}\n",
    "                int_phi_t1 = {int_phi_t1}\n",
    "\n",
    "                params  = {phi_params.h1, phi_params.a1, phi_params.b1, phi_params.h2, phi_params.a2}\n",
    "                '''\n",
    "                    \n",
    "                )\n",
    "    else:\n",
    "        int_phi_t_E_g = np.nan\n",
    "        \n",
    "        phi_t_e = np.nan\n",
    "        int_phi_t_e = np.nan\n",
    "\n",
    "        int_phi_t2 = np.nan\n",
    "        int_phi_t1 = np.nan\n",
    "\n",
    "    # PA wins and random choice due to EA survival\n",
    "    P_EA_hits_either_bound = CDF_E_minus_small_t_NORM_rate_norm_l_time_varying_fn(\n",
    "                                t - t_E_aff + del_go, 1, \n",
    "                                ABL, ILD, rate_lambda, T0, theta_E, Z_E, int_phi_t_E_g, rate_norm_l, \n",
    "                                is_norm, is_time_vary, K_max)  \\\n",
    "                                + \\\n",
    "                                CDF_E_minus_small_t_NORM_rate_norm_l_time_varying_fn(\n",
    "                                t - t_E_aff + del_go, -1, \n",
    "                                ABL, ILD, rate_lambda, T0, theta_E, Z_E, int_phi_t_E_g, rate_norm_l,\n",
    "                                is_norm, is_time_vary, K_max)\n",
    "    \n",
    "    P_EA_survives = 1 - P_EA_hits_either_bound\n",
    "    random_readout_if_EA_survives = 0.5 * P_EA_survives\n",
    "    \n",
    "    # PA wins and EA hits later\n",
    "    P_E_plus_cum = CDF_E_minus_small_t_NORM_rate_norm_l_time_varying_fn(\n",
    "                            t2, bound, \n",
    "                            ABL, ILD, rate_lambda, T0, theta_E, Z_E, int_phi_t2, rate_norm_l, \n",
    "                            is_norm, is_time_vary, K_max)  \\\n",
    "                            - \\\n",
    "                            CDF_E_minus_small_t_NORM_rate_norm_l_time_varying_fn(\n",
    "                            t1, bound, \n",
    "                            ABL, ILD, rate_lambda, T0, theta_E, Z_E, int_phi_t1, rate_norm_l,\n",
    "                            is_norm, is_time_vary, K_max)\n",
    "    \n",
    "\n",
    "    # EA wins\n",
    "    P_E_plus = rho_E_minus_small_t_NORM_rate_norm_time_varying_fn(\n",
    "        t - t_E_aff, bound, ABL, ILD, rate_lambda, T0, theta_E, Z_E, phi_t_e, int_phi_t_e, \n",
    "        rate_norm_l, is_norm, is_time_vary, K_max)\n",
    "    \n",
    "\n",
    "    \n",
    "\n",
    "    return (P_A*(random_readout_if_EA_survives + P_E_plus_cum) + P_E_plus*(1-C_A))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "exp_df = pd.read_csv('../outExp.csv')\n",
    "\n",
    "# remove wrong rows \n",
    "count = ((exp_df['RTwrtStim'].isna()) & (exp_df['abort_event'] == 3)).sum()\n",
    "print(\"Number of rows where RTwrtStim is NaN and abort_event == 3:\", count)\n",
    "exp_df = exp_df[~((exp_df['RTwrtStim'].isna()) & (exp_df['abort_event'] == 3))].copy()\n",
    "\n",
    "# comparable batch\n",
    "exp_df_batch = exp_df[\n",
    "    (exp_df['batch_name'] == 'Comparable') &\n",
    "    (exp_df['LED_trial'].isin([np.nan, 0]))\n",
    "]\n",
    "\n",
    "# aborts and valid\n",
    "df_valid_and_aborts = exp_df_batch[\n",
    "    (exp_df_batch['success'].isin([1,-1])) |\n",
    "    (exp_df_batch['abort_event'] == 3)\n",
    "].copy()\n",
    "\n",
    "## choice and acc columns\n",
    "# 1 is right , -1 is left\n",
    "df_valid_and_aborts['choice'] = df_valid_and_aborts['response_poke'].apply(lambda x: 1 if x == 3 else (-1 if x == 2 else random.choice([1, -1])))\n",
    "# 1 or 0 if the choice was correct or not\n",
    "df_valid_and_aborts['accuracy'] = (df_valid_and_aborts['ILD'] * df_valid_and_aborts['choice']).apply(lambda x: 1 if x > 0 else 0)\n",
    "\n",
    "## df used for fitting - valid trials < 1s + stim\n",
    "df_valid_less_than_1 = df_valid_and_aborts[\n",
    "    (df_valid_and_aborts['success'].isin([1,-1])) & \n",
    "    (df_valid_and_aborts['RTwrtStim'] < 1) &\n",
    "    (df_valid_and_aborts['RTwrtStim'] > 0)\n",
    "]\n",
    "\n",
    "# find ABL and ILD\n",
    "ABL_arr = df_valid_and_aborts['ABL'].unique()\n",
    "ILD_arr = df_valid_and_aborts['ILD'].unique()\n",
    "\n",
    "\n",
    "# sort ILD arr in ascending order\n",
    "ILD_arr = np.sort(ILD_arr)\n",
    "ABL_arr = np.sort(ABL_arr)\n",
    "\n",
    "print('ABL:', ABL_arr)\n",
    "print('ILD:', ILD_arr)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# vbmc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "is_norm = True\n",
    "is_time_vary = True\n",
    "# phi_params_obj = np.nan"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "proactive_trunc_time = 0.3\n",
    "K_max = 10"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "V_A = 3.282\n",
    "theta_A = 3.779\n",
    "t_A_aff = -0.266\n",
    "bump_offset = 0"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## loglike fn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def compute_loglike(row, rate_lambda, T_0, theta_E, Z_E, t_E_aff, del_go, rate_norm_l, bump_height, bump_width, dip_height, dip_width):\n",
    "    \n",
    "    rt = row['TotalFixTime']\n",
    "    t_stim = row['intended_fix']\n",
    "    \n",
    "    \n",
    "    ILD = row['ILD']\n",
    "    ABL = row['ABL']\n",
    "    choice = row['choice']\n",
    "\n",
    "    phi_params = {\n",
    "        'h1': bump_width,\n",
    "        'a1': bump_height,\n",
    "        'h2': dip_width,\n",
    "        'a2': dip_height,\n",
    "        'b1': bump_offset\n",
    "    }\n",
    "\n",
    "    phi_params_obj = SimpleNamespace(**phi_params)\n",
    "\n",
    "    pdf = up_or_down_RTs_fit_fn(\n",
    "            rt, choice,\n",
    "            V_A, theta_A, t_A_aff,\n",
    "            t_stim, ABL, ILD, rate_lambda, T_0, theta_E, Z_E, t_E_aff, del_go,\n",
    "            phi_params_obj, rate_norm_l, \n",
    "            is_norm, is_time_vary, K_max)\n",
    "\n",
    "    trunc_factor_p_joint = cum_pro_and_reactive_time_vary_fn(\n",
    "                            t_stim + 1, proactive_trunc_time,\n",
    "                            V_A, theta_A, t_A_aff,\n",
    "                            t_stim, ABL, ILD, rate_lambda, T_0, theta_E, Z_E, t_E_aff,\n",
    "                            phi_params_obj, rate_norm_l, \n",
    "                            is_norm, is_time_vary, K_max) \\\n",
    "                            - \\\n",
    "                            cum_pro_and_reactive_time_vary_fn(\n",
    "                            t_stim, proactive_trunc_time,\n",
    "                            V_A, theta_A, t_A_aff,\n",
    "                            t_stim, ABL, ILD, rate_lambda, T_0, theta_E, Z_E, t_E_aff,\n",
    "                            phi_params_obj, rate_norm_l, \n",
    "                            is_norm, is_time_vary, K_max)\n",
    "                           \n",
    "\n",
    "    pdf /= (trunc_factor_p_joint + 1e-20)\n",
    "    pdf = max(pdf, 1e-50)\n",
    "    if np.isnan(pdf):\n",
    "        print(f'row[\"abort_event\"] = {row[\"abort_event\"]}')\n",
    "        print(f'row[\"RTwrtStim\"] = {row[\"RTwrtStim\"]}')\n",
    "        raise ValueError(f'nan pdf rt = {rt}, t_stim = {t_stim}')\n",
    "    return np.log(pdf)\n",
    "    \n",
    "    \n",
    "\n",
    "\n",
    "def vbmc_loglike_fn(params):\n",
    "    rate_lambda, T_0, theta_E, w, t_E_aff, del_go, rate_norm_l, bump_height, bump_width, dip_height, dip_width = params\n",
    "    Z_E = (w - 0.5) * 2 * theta_E\n",
    "    all_loglike = Parallel(n_jobs=30)(delayed(compute_loglike)(row, rate_lambda, T_0, theta_E, Z_E, t_E_aff, del_go, rate_norm_l, bump_height, bump_width, dip_height, dip_width)\\\n",
    "                                       for _, row in df_valid_less_than_1.iterrows() )\n",
    "    return np.sum(all_loglike)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## priors"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "rate_lambda_bounds = [0.5, 5]\n",
    "T_0_bounds = [50e-3, 800e-3]\n",
    "theta_E_bounds = [1, 15]\n",
    "w_bounds = [0.3, 0.7]\n",
    "t_E_aff_bounds = [0.01, 0.2]\n",
    "del_go_bounds = [0, 0.2]\n",
    "rate_norm_bounds = [0, 2]\n",
    "bump_height_bounds = [0.02, 1]\n",
    "bump_width_bounds = [0.1, 1]\n",
    "dip_width_bounds = [0.01, 1]\n",
    "dip_height_bounds = [0.001, 1]\n",
    "\n",
    "rate_lambda_plausible_bounds = [1, 3]\n",
    "T_0_plausible_bounds = [150e-3, 400e-3]\n",
    "theta_E_plausible_bounds = [1.5, 10]\n",
    "w_plausible_bounds = [0.4, 0.6]\n",
    "t_E_aff_plausible_bounds = [0.03, 0.09]\n",
    "del_go_plausible_bounds = [0.05, 0.15]\n",
    "rate_norm_plausible_bounds = [0.8, 0.99]\n",
    "bump_height_plausible_bounds = [0.1, 0.5]\n",
    "bump_width_plausible_bounds = [0.2, 0.3]\n",
    "dip_width_plausible_bounds = [0.025, 0.05]\n",
    "dip_height_plausible_bounds = [0.2, 0.5]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def trapezoidal_logpdf(x, a, b, c, d):\n",
    "    if x < a or x > d:\n",
    "        return -np.inf  # Logarithm of zero\n",
    "    area = ((b - a) + (d - c)) / 2 + (c - b)\n",
    "    h_max = 1.0 / area  # Height of the trapezoid to normalize the area to 1\n",
    "    \n",
    "    if a <= x <= b:\n",
    "        pdf_value = ((x - a) / (b - a)) * h_max\n",
    "    elif b < x < c:\n",
    "        pdf_value = h_max\n",
    "    elif c <= x <= d:\n",
    "        pdf_value = ((d - x) / (d - c)) * h_max\n",
    "    else:\n",
    "        pdf_value = 0.0  # This case is redundant due to the initial check\n",
    "\n",
    "    if pdf_value <= 0.0:\n",
    "        return -np.inf\n",
    "    else:\n",
    "        return np.log(pdf_value)\n",
    "    \n",
    "\n",
    "def vbmc_prior_fn(params):\n",
    "    rate_lambda, T_0, theta_E, w, t_E_aff, del_go, rate_norm_l, bump_height, bump_width, dip_height, dip_width = params\n",
    "\n",
    "    rate_lambda_logpdf = trapezoidal_logpdf(\n",
    "        rate_lambda,\n",
    "        rate_lambda_bounds[0],\n",
    "        rate_lambda_plausible_bounds[0],\n",
    "        rate_lambda_plausible_bounds[1],\n",
    "        rate_lambda_bounds[1]\n",
    "    )\n",
    "    \n",
    "    T_0_logpdf = trapezoidal_logpdf(\n",
    "        T_0,\n",
    "        T_0_bounds[0],\n",
    "        T_0_plausible_bounds[0],\n",
    "        T_0_plausible_bounds[1],\n",
    "        T_0_bounds[1]\n",
    "    )\n",
    "    \n",
    "    theta_E_logpdf = trapezoidal_logpdf(\n",
    "        theta_E,\n",
    "        theta_E_bounds[0],\n",
    "        theta_E_plausible_bounds[0],\n",
    "        theta_E_plausible_bounds[1],\n",
    "        theta_E_bounds[1]\n",
    "    )\n",
    "    \n",
    "    w_logpdf = trapezoidal_logpdf(\n",
    "        w,\n",
    "        w_bounds[0],\n",
    "        w_plausible_bounds[0],\n",
    "        w_plausible_bounds[1],\n",
    "        w_bounds[1]\n",
    "    )\n",
    "    \n",
    "    t_E_aff_logpdf = trapezoidal_logpdf(\n",
    "        t_E_aff,\n",
    "        t_E_aff_bounds[0],\n",
    "        t_E_aff_plausible_bounds[0],\n",
    "        t_E_aff_plausible_bounds[1],\n",
    "        t_E_aff_bounds[1]\n",
    "    )\n",
    "    \n",
    "    del_go_logpdf = trapezoidal_logpdf(\n",
    "        del_go,\n",
    "        del_go_bounds[0],\n",
    "        del_go_plausible_bounds[0],\n",
    "        del_go_plausible_bounds[1],\n",
    "        del_go_bounds[1]\n",
    "    )\n",
    "    rate_norm_l_logpdf = trapezoidal_logpdf(\n",
    "        rate_norm_l,\n",
    "        rate_norm_bounds[0],\n",
    "        rate_norm_plausible_bounds[0],\n",
    "        rate_norm_plausible_bounds[1],\n",
    "        rate_norm_bounds[1]\n",
    "    )\n",
    "    \n",
    "    bump_height_logpdf = trapezoidal_logpdf(\n",
    "        bump_height,\n",
    "        bump_height_bounds[0],\n",
    "        bump_height_plausible_bounds[0],\n",
    "        bump_height_plausible_bounds[1],\n",
    "        bump_height_bounds[1]\n",
    "    )\n",
    "\n",
    "    bump_width_logpdf = trapezoidal_logpdf(\n",
    "        bump_width,\n",
    "        bump_width_bounds[0],\n",
    "        bump_width_plausible_bounds[0],\n",
    "        bump_width_plausible_bounds[1],\n",
    "        bump_width_bounds[1]\n",
    "    )\n",
    "\n",
    "    dip_height_logpdf = trapezoidal_logpdf(\n",
    "        dip_height,\n",
    "        dip_height_bounds[0],\n",
    "        dip_height_plausible_bounds[0],\n",
    "        dip_height_plausible_bounds[1],\n",
    "        dip_height_bounds[1]\n",
    "    )\n",
    "\n",
    "    dip_width_logpdf = trapezoidal_logpdf(\n",
    "        dip_width,\n",
    "        dip_width_bounds[0],\n",
    "        dip_width_plausible_bounds[0],\n",
    "        dip_width_plausible_bounds[1],\n",
    "        dip_width_bounds[1]\n",
    "    )\n",
    "\n",
    "    return (\n",
    "        rate_lambda_logpdf +\n",
    "        T_0_logpdf +\n",
    "        theta_E_logpdf +\n",
    "        w_logpdf +\n",
    "        t_E_aff_logpdf +\n",
    "        del_go_logpdf + \n",
    "        rate_norm_l_logpdf + \n",
    "        bump_height_logpdf +\n",
    "        bump_width_logpdf +\n",
    "        dip_height_logpdf +\n",
    "        dip_width_logpdf\n",
    "    )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## prior + loglike"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def vbmc_joint_fn(params):\n",
    "    priors = vbmc_prior_fn(params)\n",
    "    loglike = vbmc_loglike_fn(params)\n",
    "\n",
    "    return priors + loglike"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# run vbmc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Add bounds for all parameters (order: V_A, theta_A, t_A_aff, rate_lambda, T_0, theta_E, w, t_E_aff, del_go)\n",
    "lb = np.array([\n",
    "    rate_lambda_bounds[0],\n",
    "    T_0_bounds[0],\n",
    "    theta_E_bounds[0],\n",
    "    w_bounds[0],\n",
    "    t_E_aff_bounds[0],\n",
    "    del_go_bounds[0],\n",
    "    rate_norm_bounds[0],\n",
    "    bump_height_bounds[0],\n",
    "    bump_width_bounds[0],\n",
    "    dip_height_bounds[0],\n",
    "    dip_width_bounds[0]\n",
    "])\n",
    "\n",
    "ub = np.array([\n",
    "    rate_lambda_bounds[1],\n",
    "    T_0_bounds[1],\n",
    "    theta_E_bounds[1],\n",
    "    w_bounds[1],\n",
    "    t_E_aff_bounds[1],\n",
    "    del_go_bounds[1],\n",
    "    rate_norm_bounds[1],\n",
    "    bump_height_bounds[1],\n",
    "    bump_width_bounds[1],\n",
    "    dip_height_bounds[1],\n",
    "    dip_width_bounds[1]\n",
    "])\n",
    "\n",
    "plb = np.array([\n",
    "    rate_lambda_plausible_bounds[0],\n",
    "    T_0_plausible_bounds[0],\n",
    "    theta_E_plausible_bounds[0],\n",
    "    w_plausible_bounds[0],\n",
    "    t_E_aff_plausible_bounds[0],\n",
    "    del_go_plausible_bounds[0],\n",
    "    rate_norm_plausible_bounds[0],\n",
    "    bump_height_plausible_bounds[0],\n",
    "    bump_width_plausible_bounds[0],\n",
    "    dip_height_plausible_bounds[0],\n",
    "    dip_width_plausible_bounds[0]\n",
    "])\n",
    "\n",
    "pub = np.array([\n",
    "    rate_lambda_plausible_bounds[1],\n",
    "    T_0_plausible_bounds[1],\n",
    "    theta_E_plausible_bounds[1],\n",
    "    w_plausible_bounds[1],\n",
    "    t_E_aff_plausible_bounds[1],\n",
    "    del_go_plausible_bounds[1],\n",
    "    rate_norm_plausible_bounds[1],\n",
    "    bump_height_plausible_bounds[1],\n",
    "    bump_width_plausible_bounds[1],\n",
    "    dip_height_plausible_bounds[1],\n",
    "    dip_width_plausible_bounds[1]\n",
    "])\n",
    "\n",
    "# Initialize with random values within plausible bounds\n",
    "np.random.seed(42)\n",
    "# rate_lambda_0 = np.random.uniform(*rate_lambda_plausible_bounds)\n",
    "# T_0_0 = np.random.uniform(*T_0_plausible_bounds)\n",
    "# theta_E_0 = np.random.uniform(*theta_E_plausible_bounds)\n",
    "# w_0 = np.random.uniform(*w_plausible_bounds)\n",
    "# t_E_aff_0 = np.random.uniform(*t_E_aff_plausible_bounds)\n",
    "# del_go_0 = np.random.uniform(*del_go_plausible_bounds)\n",
    "\n",
    "rate_lambda_0 = 2.3\n",
    "T_0_0 = 100 * 1e-3\n",
    "theta_E_0 = 3\n",
    "w_0 = 0.51\n",
    "t_E_aff_0 = 0.071\n",
    "del_go_0 = 0.19\n",
    "rate_norm_l_0 = 0.95\n",
    "bump_height_0 = 0.35846\n",
    "bump_width_0 = 0.28043\n",
    "dip_height_0 = 0.29911\n",
    "dip_width_0 = 0.01818\n",
    "\n",
    "x_0 = np.array([\n",
    "    rate_lambda_0,\n",
    "    T_0_0,\n",
    "    theta_E_0,\n",
    "    w_0,\n",
    "    t_E_aff_0,\n",
    "    del_go_0,\n",
    "    rate_norm_l_0,\n",
    "    bump_height_0,\n",
    "    bump_width_0,\n",
    "    dip_height_0,\n",
    "    dip_width_0\n",
    "])\n",
    "\n",
    "# Run VBMC\n",
    "vbmc = VBMC(vbmc_joint_fn, x_0, lb, ub, plb, pub, options={'display': 'on'})\n",
    "vp, results = vbmc.optimize()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# vbmc.save('ONLY_norm_vbmc_fit.pkl')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "vp_samples.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Sample from the VBMC posterior (returns tuple: samples, log weights)\n",
    "vp_samples = vp.sample(int(1e5))[0]\n",
    "\n",
    "# Convert T_0 to ms (T_0 is at index 4)\n",
    "vp_samples[:, 1] *= 1e3\n",
    "\n",
    "# Parameter labels (order matters!)\n",
    "param_labels = [\n",
    "    r'$\\lambda$',       # 3\n",
    "    r'$T_0$ (ms)',      # 4\n",
    "    r'$\\theta_E$',      # 5\n",
    "    r'$w$',             # 6\n",
    "    r'$t_E^{aff}$',     # 7\n",
    "    r'$\\Delta_{go}$',  # 8,\n",
    "    r'rate_norm'        # 9\n",
    "]\n",
    "\n",
    "# Compute 1st and 99th percentiles for each param to restrict range\n",
    "percentiles = np.percentile(vp_samples, [1, 99], axis=0)\n",
    "_ranges = [(percentiles[0, i], percentiles[1, i]) for i in range(vp_samples.shape[1])]\n",
    "\n",
    "# Create the corner plot\n",
    "fig = corner.corner(\n",
    "    vp_samples,\n",
    "    labels=param_labels,\n",
    "    show_titles=True,\n",
    "    quantiles=[0.025, 0.5, 0.975],\n",
    "    range=_ranges,\n",
    "    title_fmt=\".3f\"\n",
    ")\n",
    "\n",
    "# Convert T_0 back to original units if needed\n",
    "vp_samples[:, 1] /= 1e3\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "vbmc.save('comparabale_tied_rate_norm_l_params_fit.pkl')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Simulation diagnostics"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## params"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "rate_lambda = vp_samples[:, 0].mean()\n",
    "T_0 = vp_samples[:, 1].mean()\n",
    "theta_E = vp_samples[:, 2].mean()\n",
    "w = vp_samples[:, 3].mean()\n",
    "Z_E = (w - 0.5) * 2 * theta_E\n",
    "t_E_aff = vp_samples[:, 4].mean()\n",
    "del_go = vp_samples[:, 5].mean()\n",
    "rate_norm_l = vp_samples[:, 6].mean()\n",
    "\n",
    "# Print them out\n",
    "print(\"Posterior Means:\")\n",
    "print(f\"rate_lambda  = {rate_lambda:.5f}\")\n",
    "print(f\"T_0 (ms)      = {1e3*T_0:.5f}\")\n",
    "print(f\"theta_E       = {theta_E:.5f}\")\n",
    "print(f\"Z_E           = {Z_E:.5f}\")\n",
    "print(f\"t_E_aff       = {1e3*t_E_aff:.5f} ms\")\n",
    "print(f\"del_go   = {del_go:.5f}\")\n",
    "print(f\"rate_norm_l   = {rate_norm_l:.5f}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## simulate"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# sample t-stim\n",
    "N_sim = int(1e6)\n",
    "\n",
    "t_stim_samples = df_valid_and_aborts['intended_fix'].sample(N_sim, replace=True).values\n",
    "ABL_samples = df_valid_and_aborts['ABL'].sample(N_sim, replace=True).values\n",
    "ILD_samples = np.random.choice(np.setdiff1d(df_valid_and_aborts['ILD'].unique(), [0]), size=N_sim, replace=True)\n",
    "\n",
    "N_print = int(N_sim / 5)\n",
    "dt  = 1e-4\n",
    "\n",
    "sim_results = Parallel(n_jobs=30)(\n",
    "    delayed(psiam_tied_data_gen_wrapper_rate_norm_fn)(\n",
    "        V_A, theta_A, ABL_samples[iter_num], ILD_samples[iter_num], rate_lambda, T_0, theta_E, Z_E, t_A_aff, t_E_aff, del_go, \n",
    "        t_stim_samples[iter_num], rate_norm_l, iter_num, N_print, dt\n",
    "    ) for iter_num in tqdm(range(N_sim))\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## prepare valid sim df, data df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sim_results_df = pd.DataFrame(sim_results)\n",
    "sim_results_df_valid = sim_results_df[\n",
    "    (sim_results_df['rt'] > sim_results_df['t_stim']) &\n",
    "    (sim_results_df['rt'] - sim_results_df['t_stim'] < 1)\n",
    "].copy()\n",
    "sim_results_df_valid.loc[:, 'correct'] = (sim_results_df_valid['ILD'] * sim_results_df_valid['choice']).apply(lambda x: 1 if x > 0 else 0)\n",
    "\n",
    "\n",
    "# remove correct column from df_valid_and_aborts\n",
    "df_valid_less_than_1 = df_valid_less_than_1.drop(columns=['correct']).copy()\n",
    "df_led_off_valid_renamed = df_valid_less_than_1.rename(columns = {\n",
    "    'TotalFixTime': 'rt',\n",
    "    'intended_fix': 't_stim',\n",
    "    'accuracy': 'correct'\n",
    "}).copy()\n",
    "\n",
    "sim_df_1 = sim_results_df_valid.copy()\n",
    "data_df_1 = df_led_off_valid_renamed.copy()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## plots"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# theory\n",
    "N_theory = int(1e3)\n",
    "t_pts = np.arange(-1, 2, 0.001)\n",
    "t_stim_samples = df_valid_and_aborts['intended_fix'].sample(N_theory, replace=True).values\n",
    "\n",
    "P_A_samples = np.zeros((N_theory, len(t_pts)))\n",
    "for idx, t_stim in enumerate(t_stim_samples):\n",
    "    P_A_samples[idx, :] = [rho_A_t_fn(t + t_stim - t_A_aff, V_A, theta_A) for t in t_pts]\n",
    "\n",
    "P_A_mean = np.mean(P_A_samples, axis=0)\n",
    "C_A_mean = cumtrapz(P_A_mean, t_pts, initial=0)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "bw = 0.02\n",
    "bins = np.arange(0, 1, bw)\n",
    "bin_centers = bins[:-1] + (0.5 * bw)\n",
    "ILD_arr_minus_zero = [x for x in ILD_arr if x != 0]\n",
    "\n",
    "n_rows = len(ILD_arr_minus_zero)\n",
    "n_cols = len(ABL_arr)\n",
    "\n",
    "fig, axs = plt.subplots(n_rows, n_cols, figsize=(4 * n_cols, 3 * n_rows), sharey='row')\n",
    "\n",
    "for i_idx, ILD in enumerate(ILD_arr_minus_zero):\n",
    "    for a_idx, ABL in enumerate(ABL_arr):\n",
    "        ax = axs[i_idx, a_idx] if n_rows > 1 else axs[a_idx]\n",
    "\n",
    "        sim_df_1_ABL_ILD = sim_df_1[(sim_df_1['ABL'] == ABL) & (sim_df_1['ILD'] == ILD)]\n",
    "        data_df_1_ABL_ILD = data_df_1[(data_df_1['ABL'] == ABL) & (data_df_1['ILD'] == ILD)]\n",
    "\n",
    "        sim_up = sim_df_1_ABL_ILD[sim_df_1_ABL_ILD['choice'] == 1]\n",
    "        sim_down = sim_df_1_ABL_ILD[sim_df_1_ABL_ILD['choice'] == -1]\n",
    "        data_up = data_df_1_ABL_ILD[data_df_1_ABL_ILD['choice'] == 1]\n",
    "        data_down = data_df_1_ABL_ILD[data_df_1_ABL_ILD['choice'] == -1]\n",
    "\n",
    "        sim_up_rt = sim_up['rt'] - sim_up['t_stim']\n",
    "        sim_down_rt = sim_down['rt'] - sim_down['t_stim']\n",
    "        data_up_rt = data_up['rt'] - data_up['t_stim']\n",
    "        data_down_rt = data_down['rt'] - data_down['t_stim']\n",
    "\n",
    "        sim_up_hist, _ = np.histogram(sim_up_rt, bins=bins, density=True)\n",
    "        sim_down_hist, _ = np.histogram(sim_down_rt, bins=bins, density=True)\n",
    "        data_up_hist, _ = np.histogram(data_up_rt, bins=bins, density=True)\n",
    "        data_down_hist, _ = np.histogram(data_down_rt, bins=bins, density=True)\n",
    "\n",
    "        # Normalize histograms by proportion of trials\n",
    "        sim_up_hist *= len(sim_up) / len(sim_df_1_ABL_ILD)\n",
    "        sim_down_hist *= len(sim_down) / len(sim_df_1_ABL_ILD)\n",
    "        data_up_hist *= len(data_up) / len(data_df_1_ABL_ILD)\n",
    "        data_down_hist *= len(data_down) / len(data_df_1_ABL_ILD)\n",
    "\n",
    "        # theory\n",
    "        trunc_fac_samples = np.zeros((N_theory))\n",
    "\n",
    "        for idx, t_stim in enumerate(t_stim_samples):\n",
    "            trunc_fac_samples[idx] = cum_pro_and_reactive_time_vary_fn(\n",
    "                                t_stim + 1, proactive_trunc_time,\n",
    "                                V_A, theta_A, t_A_aff,\n",
    "                                t_stim, ABL, ILD, rate_lambda, T_0, theta_E, Z_E, t_E_aff,\n",
    "                                phi_params_obj, rate_norm_l, \n",
    "                                is_norm, is_time_vary, K_max) \\\n",
    "                                - \\\n",
    "                                cum_pro_and_reactive_time_vary_fn(\n",
    "                                t_stim,proactive_trunc_time,\n",
    "                                V_A, theta_A, t_A_aff,\n",
    "                                t_stim, ABL, ILD, rate_lambda, T_0, theta_E, Z_E, t_E_aff,\n",
    "                                phi_params_obj, rate_norm_l, \n",
    "                                is_norm, is_time_vary, K_max) + 1e-10\n",
    "        trunc_factor = np.mean(trunc_fac_samples)\n",
    "        \n",
    "        up_mean = np.array([up_or_down_RTs_fit_PA_C_A_given_wrt_t_stim_fn(\n",
    "                    t, 1,\n",
    "                    P_A_mean[i], C_A_mean[i],\n",
    "                    ABL, ILD, rate_lambda, T_0, theta_E, Z_E, t_E_aff, del_go,\n",
    "                    phi_params_obj, rate_norm_l, \n",
    "                    is_norm, is_time_vary, K_max) for i, t in enumerate(t_pts)])\n",
    "        down_mean = np.array([up_or_down_RTs_fit_PA_C_A_given_wrt_t_stim_fn(\n",
    "                t, -1,\n",
    "                P_A_mean[i], C_A_mean[i],\n",
    "                ABL, ILD, rate_lambda, T_0, theta_E, Z_E, t_E_aff, del_go,\n",
    "                phi_params_obj, rate_norm_l, \n",
    "                is_norm, is_time_vary, K_max) for i, t in enumerate(t_pts)])\n",
    "        \n",
    "        mask_0_1      = (t_pts >= 0) & (t_pts <= 1)   # boolean index\n",
    "        t_pts_0_1     = t_pts[mask_0_1]               # time vector you already made\n",
    "        up_mean_0_1   = up_mean[mask_0_1]\n",
    "        down_mean_0_1 = down_mean[mask_0_1]\n",
    "        \n",
    "        up_theory_mean_norm = up_mean_0_1 / trunc_factor\n",
    "        down_theory_mean_norm = down_mean_0_1 / trunc_factor\n",
    "\n",
    "\n",
    "        # Plot\n",
    "        ax.plot(bin_centers, data_up_hist, color='b', label='Data' if (i_idx == 0 and a_idx == 0) else \"\")\n",
    "        ax.plot(bin_centers, -data_down_hist, color='b')\n",
    "        ax.plot(bin_centers, sim_up_hist, color='r', label='Sim' if (i_idx == 0 and a_idx == 0) else \"\")\n",
    "        ax.plot(bin_centers, -sim_down_hist, color='r')\n",
    "\n",
    "        ax.plot(t_pts_0_1, up_theory_mean_norm, lw=3, alpha=0.2, color='g')\n",
    "        ax.plot(t_pts_0_1, -down_theory_mean_norm, lw=3, alpha=0.2, color='g')\n",
    "\n",
    "        # Compute fractions\n",
    "        data_total = len(data_df_1_ABL_ILD)\n",
    "        sim_total = len(sim_df_1_ABL_ILD)\n",
    "        data_up_frac = len(data_up) / data_total if data_total else 0\n",
    "        data_down_frac = len(data_down) / data_total if data_total else 0\n",
    "        sim_up_frac = len(sim_up) / sim_total if sim_total else 0\n",
    "        sim_down_frac = len(sim_down) / sim_total if sim_total else 0\n",
    "\n",
    "        ax.set_title(\n",
    "            f\"ABL: {ABL}, ILD: {ILD}\\n\"\n",
    "            f\"Data,Sim: (+{data_up_frac:.2f},+{sim_up_frac:.2f}), \"\n",
    "            f\"(-{data_down_frac:.2f},-{sim_down_frac:.2f})\"\n",
    "        )\n",
    "        \n",
    "        ax.axhline(0, color='k', linewidth=0.5)\n",
    "        ax.set_xlim([0, 0.7])\n",
    "        if a_idx == 0:\n",
    "            ax.set_ylabel(\"Density (Up / Down flipped)\")\n",
    "        if i_idx == n_rows - 1:\n",
    "            ax.set_xlabel(\"RT (s)\")\n",
    "\n",
    "fig.tight_layout()\n",
    "fig.legend(loc='upper right')\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "bw = 0.02\n",
    "bins = np.arange(0, 1, bw)\n",
    "bin_centers = bins[:-1] + (0.5 * bw)\n",
    "\n",
    "def plot_tacho(df_1):\n",
    "    df_1 = df_1.copy()\n",
    "    df_1['RT_bin'] = pd.cut(df_1['rt'] - df_1['t_stim'], bins=bins, include_lowest=True)\n",
    "    grouped = df_1.groupby('RT_bin', observed=False)['correct'].agg(['mean', 'count'])\n",
    "    grouped['bin_mid'] = grouped.index.map(lambda x: x.mid)\n",
    "    return grouped['bin_mid'], grouped['mean']\n",
    "ILD_arr_minus_zero = [x for x in ILD_arr if x != 0]\n",
    "\n",
    "n_rows = len(ILD_arr_minus_zero)\n",
    "n_cols = len(ABL_arr)\n",
    "\n",
    "# === Define fig2 ===\n",
    "fig2, axs = plt.subplots(n_rows, n_cols, figsize=(4 * n_cols, 3 * n_rows), sharey='row')\n",
    "\n",
    "for i_idx, ILD in enumerate(ILD_arr_minus_zero):\n",
    "    for a_idx, ABL in enumerate(ABL_arr):\n",
    "        ax = axs[i_idx, a_idx] if n_rows > 1 else axs[a_idx]\n",
    "\n",
    "        sim_df_1_ABL_ILD = sim_df_1[(sim_df_1['ABL'] == ABL) & (sim_df_1['ILD'] == ILD)]\n",
    "        data_df_1_ABL_ILD = data_df_1[(data_df_1['ABL'] == ABL) & (data_df_1['ILD'] == ILD)]\n",
    "\n",
    "        sim_tacho_x, sim_tacho_y = plot_tacho(sim_df_1_ABL_ILD)\n",
    "        data_tacho_x, data_tacho_y = plot_tacho(data_df_1_ABL_ILD)\n",
    "\n",
    "        # Plotting\n",
    "        ax.plot(data_tacho_x, data_tacho_y, color='b', label='Data' if (i_idx == 0 and a_idx == 0) else \"\")\n",
    "        ax.plot(sim_tacho_x, sim_tacho_y, color='r', label='Sim' if (i_idx == 0 and a_idx == 0) else \"\")\n",
    "\n",
    "        ax.set_ylim([0, 1])\n",
    "        ax.set_xlim([0, 0.7])\n",
    "        ax.set_title(f\"ABL: {ABL}, ILD: {ILD}\")\n",
    "        if a_idx == 0:\n",
    "            ax.set_ylabel(\"P(correct)\")\n",
    "        if i_idx == n_rows - 1:\n",
    "            ax.set_xlabel(\"RT (s)\")\n",
    "\n",
    "fig2.tight_layout()\n",
    "fig2.legend(loc='upper right')\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Grand RTDs and tacho"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# remove 0 ILD rows  from data_df_1\n",
    "data_df_1 = data_df_1[data_df_1['ILD'] != 0]\n",
    "\n",
    "np.sort(data_df_1['ILD'].unique())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.sort(sim_df_1['ILD'].unique())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ILD_arr_minus_zero = [x for x in ILD_arr if x != 0]\n",
    "def grand_rtd(df_1):\n",
    "    df_1_rt = df_1['rt'] - df_1['t_stim']\n",
    "    rt_hist, _ = np.histogram(df_1_rt, bins=bins, density=True)\n",
    "    return rt_hist\n",
    "\n",
    "def plot_psycho(df_1):\n",
    "    prob_choice_dict = {}\n",
    "\n",
    "    all_ABL = np.sort(df_1['ABL'].unique())\n",
    "    all_ILD = np.sort(ILD_arr_minus_zero)\n",
    "\n",
    "    for abl in all_ABL:\n",
    "        filtered_df = df_1[df_1['ABL'] == abl]\n",
    "        prob_choice_dict[abl] = [\n",
    "            sum(filtered_df[filtered_df['ILD'] == ild]['choice'] == 1) / len(filtered_df[filtered_df['ILD'] == ild])\n",
    "            for ild in all_ILD\n",
    "        ]\n",
    "\n",
    "    return prob_choice_dict\n",
    "\n",
    "# === Define fig3 ===\n",
    "fig3, axes = plt.subplots(1, 3, figsize=(15, 4))\n",
    "\n",
    "# === Grand RTD ===\n",
    "axes[0].plot(bin_centers, grand_rtd(data_df_1), color='b', label='data')\n",
    "axes[0].plot(bin_centers, grand_rtd(sim_df_1), color='r', label='sim')\n",
    "axes[0].legend()\n",
    "axes[0].set_xlabel('rt wrt stim')\n",
    "axes[0].set_ylabel('density')\n",
    "axes[0].set_title('Grand RTD')\n",
    "\n",
    "# === Grand Psychometric ===\n",
    "data_psycho = plot_psycho(data_df_1)\n",
    "sim_psycho = plot_psycho(sim_df_1)\n",
    "\n",
    "colors = [\n",
    "    '#1f77b4',  # muted blue\n",
    "    '#ff7f0e',  # safety orange\n",
    "    '#2ca02c',  # muted green\n",
    "    '#d62728',  # brick red\n",
    "    '#9467bd',  # muted purple\n",
    "    '#8dd3c7',  # pale teal\n",
    "    '#fdb462',  # burnt orange\n",
    "    '#bcbd22',  # golden yellow\n",
    "    '#17becf',  # bright blue\n",
    "    '#9edae5',  # pale blue-green\n",
    "]  # Define colors for each ABL\n",
    "for i, ABL in enumerate(ABL_arr):\n",
    "    axes[1].plot(ILD_arr_minus_zero, data_psycho[ABL], color=colors[i], label=f'data ABL={ABL}', marker='o', linestyle='None')\n",
    "    axes[1].plot(ILD_arr_minus_zero, sim_psycho[ABL], color=colors[i], linestyle='-')\n",
    "\n",
    "axes[1].legend()\n",
    "axes[1].set_xlabel('ILD')\n",
    "axes[1].set_ylabel('P(right)')\n",
    "axes[1].set_title('Grand Psychometric')\n",
    "\n",
    "# === Grand Tacho ===\n",
    "data_tacho_x, data_tacho_y = plot_tacho(data_df_1)\n",
    "sim_tacho_x, sim_tacho_y = plot_tacho(sim_df_1)\n",
    "\n",
    "axes[2].plot(data_tacho_x, data_tacho_y, color='b', label='data')\n",
    "axes[2].plot(sim_tacho_x, sim_tacho_y, color='r', label='sim')\n",
    "axes[2].legend()\n",
    "axes[2].set_xlabel('rt wrt stim')\n",
    "axes[2].set_ylabel('acc')\n",
    "axes[2].set_title('Grand Tacho')\n",
    "axes[2].set_ylim(0.5, 1)\n",
    "\n",
    "fig3.tight_layout()\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# all in a single PDF?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "from matplotlib.backends.backend_pdf import PdfPages\n",
    "from docx import Document\n",
    "from docx.shared import Inches\n",
    "\n",
    "# Set your filename prefix\n",
    "output_filename = 'no_ILD_16_V4_NON_LINEAR_ONLY_Norm_report'\n",
    "\n",
    "# Ensure output directory\n",
    "os.makedirs('outputs', exist_ok=True)\n",
    "\n",
    "# === Save individual figures as PNGs ===\n",
    "fig1_path = f'outputs/{output_filename}_updown_hist.png'\n",
    "fig2_path = f'outputs/{output_filename}_tacho.png'\n",
    "fig3_path = f'outputs/{output_filename}_grand_summary.png'\n",
    "\n",
    "fig.savefig(fig1_path)\n",
    "fig2.savefig(fig2_path)\n",
    "fig3.savefig(fig3_path)\n",
    "\n",
    "# === Create PDF with all three figures ===\n",
    "pdf_path = f'outputs/{output_filename}.pdf'\n",
    "with PdfPages(pdf_path) as pdf:\n",
    "    for fig_item in [fig, fig2, fig3]:\n",
    "        pdf.savefig(fig_item)\n",
    "\n",
    "# === Create DOCX with all three figures ===\n",
    "doc = Document()\n",
    "doc.add_heading('RTD and Tacho Analysis Results', 0)\n",
    "\n",
    "for img_path in [fig1_path, fig2_path, fig3_path]:\n",
    "    doc.add_page_break()\n",
    "    doc.add_picture(img_path, width=Inches(6.5))\n",
    "\n",
    "docx_path = f'outputs/{output_filename}.docx'\n",
    "doc.save(docx_path)\n",
    "\n",
    "print(f\"✅ Saved PDF to: {pdf_path}\")\n",
    "print(f\"✅ Saved DOCX to: {docx_path}\")\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
