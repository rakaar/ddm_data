{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from joblib import Parallel, delayed\n",
    "from tqdm import tqdm\n",
    "from scipy.integrate import quad\n",
    "import pandas as pd\n",
    "import random\n",
    "from pyvbmc import VBMC\n",
    "from V_A_step_jump_fit_utils import PDF_hit_V_A_change, CDF_hit_V_A_change, rho_A_t_fn, cum_A_t_fn\n",
    "from tqdm import tqdm\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ABL: [20 40 60]\n",
      "ILD: [-16.  -8.  -4.  -2.  -1.   1.   2.   4.   8.  16.]\n"
     ]
    }
   ],
   "source": [
    "# read out_LED.csv as dataframe\n",
    "og_df = pd.read_csv('../out_LED.csv')\n",
    "\n",
    "# chose non repeat trials - 0 or 2 or missing\n",
    "df = og_df[ og_df['repeat_trial'].isin([0,2]) | og_df['repeat_trial'].isna() ]\n",
    "\n",
    "# only session type 7\n",
    "session_type = 7    \n",
    "df = df[ df['session_type'].isin([session_type]) ]\n",
    "\n",
    "# training level 16\n",
    "training_level = 16\n",
    "df = df[ df['training_level'].isin([training_level]) ]\n",
    "\n",
    "# find ABL and ILD\n",
    "ABL_arr = df['ABL'].unique()\n",
    "ILD_arr = df['ILD'].unique()\n",
    "\n",
    "\n",
    "# sort ILD arr in ascending order\n",
    "ILD_arr = np.sort(ILD_arr)\n",
    "ABL_arr = np.sort(ABL_arr)\n",
    "\n",
    "print('ABL:', ABL_arr)\n",
    "print('ILD:', ILD_arr)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_to_fit = df[ df['LED_trial'] == 1 ] "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# VBMC"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "T_trunc = 0.3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "def compute_loglike(row, base_V_A, new_V_A, theta_A, t_A_aff):\n",
    "    rt = row['timed_fix']\n",
    "    t_stim = row['intended_fix']\n",
    "    t_led = row['intended_fix'] - row['LED_onset_time']\n",
    "\n",
    "    \n",
    "    if rt - t_A_aff < T_trunc:\n",
    "        likelihood = 0\n",
    "    else:\n",
    "        if t_led == 0: # only new V_A will be used\n",
    "            pdf_trunc_factor = 1 - cum_A_t_fn(T_trunc - t_A_aff, new_V_A, theta_A)\n",
    "            if rt - t_A_aff < t_stim:\n",
    "                likelihood =  rho_A_t_fn(rt - t_A_aff, new_V_A, theta_A) / pdf_trunc_factor\n",
    "            elif rt - t_A_aff > t_stim:\n",
    "                likelihood = ( 1 - cum_A_t_fn(t_stim - t_A_aff, new_V_A, theta_A) ) / pdf_trunc_factor\n",
    "        else: # V_A change in middle\n",
    "            trunc_factor = 1 - CDF_hit_V_A_change(T_trunc - t_A_aff, base_V_A, new_V_A, theta_A, t_led)\n",
    "            if rt - t_A_aff < t_stim:\n",
    "                likelihood = PDF_hit_V_A_change(rt-t_A_aff, base_V_A, new_V_A, theta_A, t_led) / trunc_factor\n",
    "            elif rt - t_A_aff > t_stim:\n",
    "                if t_stim < T_trunc: # if stim is before truncation, the abort prob = 0\n",
    "                    likelihood = 1\n",
    "                else:\n",
    "                    likelihood = ( 1 - CDF_hit_V_A_change(t_stim - t_A_aff, base_V_A, new_V_A, theta_A, t_led) ) / trunc_factor\n",
    "\n",
    "    if likelihood <= 0:\n",
    "        likelihood = 1e-50\n",
    "\n",
    "    \n",
    "    return np.log(likelihood)    \n",
    "\n",
    "\n",
    "\n",
    "def psiam_tied_loglike_fn(params):\n",
    "    base_V_A, new_V_A, theta_A, t_A_aff = params\n",
    "\n",
    "    all_loglike = Parallel(n_jobs=-1)(delayed(compute_loglike)(row, base_V_A, new_V_A, theta_A, t_A_aff)\\\n",
    "                                      for _, row in df_to_fit.iterrows() \\\n",
    "                                        if (not np.isnan(row['timed_fix'] + row['intended_fix'] + row['LED_onset_time']))) \n",
    "                                   \n",
    "\n",
    "    loglike = np.sum(all_loglike)\n",
    "    return loglike"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# bounds"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "base_V_A_bounds = [0.1, 5]\n",
    "new_V_A_bounds = [0.1, 5]\n",
    "theta_A_bounds = [0.1, 5]\n",
    "t_A_aff_bounds = [-5, 0.1]\n",
    "\n",
    "base_V_A_plausible_bounds = [0.5, 3]\n",
    "new_V_A_plausible_bounds = [0.5, 3]\n",
    "theta_A_plausible_bounds = [0.5, 3]\n",
    "t_A_aff_plausible_bounds = [-2, 0.06]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# prior"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def trapezoidal_logpdf(x, a, b, c, d):\n",
    "    if x < a or x > d:\n",
    "        return -np.inf  # Logarithm of zero\n",
    "    area = ((b - a) + (d - c)) / 2 + (c - b)\n",
    "    h_max = 1.0 / area  # Height of the trapezoid to normalize the area to 1\n",
    "    \n",
    "    if a <= x <= b:\n",
    "        pdf_value = ((x - a) / (b - a)) * h_max\n",
    "    elif b < x < c:\n",
    "        pdf_value = h_max\n",
    "    elif c <= x <= d:\n",
    "        pdf_value = ((d - x) / (d - c)) * h_max\n",
    "    else:\n",
    "        pdf_value = 0.0  # This case is redundant due to the initial check\n",
    "\n",
    "    if pdf_value <= 0.0:\n",
    "        return -np.inf\n",
    "    else:\n",
    "        return np.log(pdf_value)\n",
    "    \n",
    "\n",
    "def vbmc_prior_abort_fn(params):\n",
    "    base_V_A, new_V_A, theta_A, t_A_aff = params\n",
    "\n",
    "    base_V_A_logpdf = trapezoidal_logpdf(base_V_A, base_V_A_bounds[0], base_V_A_plausible_bounds[0], base_V_A_plausible_bounds[1], base_V_A_bounds[1])\n",
    "    new_V_A_logpdf = trapezoidal_logpdf(new_V_A, new_V_A_bounds[0], new_V_A_plausible_bounds[0], new_V_A_plausible_bounds[1], new_V_A_bounds[1])\n",
    "    theta_A_logpdf = trapezoidal_logpdf(theta_A, theta_A_bounds[0], theta_A_plausible_bounds[0], theta_A_plausible_bounds[1], theta_A_bounds[1])\n",
    "    t_A_aff_logpdf = trapezoidal_logpdf(t_A_aff, t_A_aff_bounds[0], t_A_aff_plausible_bounds[0], t_A_aff_plausible_bounds[1], t_A_aff_bounds[1])\n",
    "    return base_V_A_logpdf + new_V_A_logpdf + theta_A_logpdf + t_A_aff_logpdf"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# joint"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def vbmc_joint(params):\n",
    "    return vbmc_prior_abort_fn(params) + psiam_tied_loglike_fn(params)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# run vbmc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "lb = [base_V_A_bounds[0], new_V_A_bounds[0], theta_A_bounds[0], t_A_aff_bounds[0]]\n",
    "ub = [base_V_A_bounds[1], new_V_A_bounds[1], theta_A_bounds[1], t_A_aff_bounds[1]]\n",
    "\n",
    "plb = [base_V_A_plausible_bounds[0], new_V_A_plausible_bounds[0], theta_A_plausible_bounds[0], t_A_aff_plausible_bounds[0]]\n",
    "pub = [base_V_A_plausible_bounds[1], new_V_A_plausible_bounds[1], theta_A_plausible_bounds[1], t_A_aff_plausible_bounds[1]]\n",
    "\n",
    "np.random.seed(42)\n",
    "base_V_A_0 = np.random.uniform(base_V_A_plausible_bounds[0], base_V_A_plausible_bounds[1])\n",
    "new_V_A_0 = np.random.uniform(new_V_A_plausible_bounds[0], new_V_A_plausible_bounds[1])\n",
    "theta_A_0 = np.random.uniform(theta_A_plausible_bounds[0], theta_A_plausible_bounds[1])\n",
    "t_A_aff_0 = np.random.uniform(t_A_aff_plausible_bounds[0], t_A_aff_plausible_bounds[1])\n",
    "\n",
    "x_0 = np.array([base_V_A_0, new_V_A_0, theta_A_0, t_A_aff_0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Reshaping x0 to row vector.\n",
      "Reshaping lower bounds to (1, 4).\n",
      "Reshaping upper bounds to (1, 4).\n",
      "Reshaping plausible lower bounds to (1, 4).\n",
      "Reshaping plausible upper bounds to (1, 4).\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/rlab/raghavendra/ddm_data/.venv/lib/python3.12/site-packages/cma/evolution_strategy.py:3379: RuntimeWarning: invalid value encountered in scalar subtract\n",
      "  current_fitness_range < opts['tolfunrel'] * (es.fit.median0 - es.fit.median_min),\n",
      "/home/rlab/raghavendra/ddm_data/.venv/lib/python3.12/site-packages/cma/evolution_strategy.py:3379: RuntimeWarning: invalid value encountered in scalar multiply\n",
      "  current_fitness_range < opts['tolfunrel'] * (es.fit.median0 - es.fit.median_min),\n"
     ]
    }
   ],
   "source": [
    "vbmc = VBMC(vbmc_joint, x_0, lb, ub, plb, pub, options={'display': 'off'})\n",
    "vp, results = vbmc.optimize()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# save vbmc\n",
    "vp.save('V_A_step_jump_LED_on_vbmc.pkl', overwrite=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import pickle\n",
    "# with open('V_A_step_jump_LED_on_vbmc.pkl', 'rb') as f:\n",
    "#     vp = pickle.load(f)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# corner plot"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import corner\n",
    "vp_samples = vp.sample(int(1e6))[0]\n",
    "base_V_A_samp = vp_samples[:,0]\n",
    "new_V_A_samp = vp_samples[:,1]\n",
    "theta_A_samp = vp_samples[:,2]\n",
    "t_A_aff_samp = vp_samples[:,3]\n",
    "\n",
    "combined_samples = np.transpose(np.vstack((base_V_A_samp, new_V_A_samp, theta_A_samp, t_A_aff_samp)))\n",
    "param_labels = ['base_V_A', 'new_V_A', 'theta_A', 't_A_aff']\n",
    "corner.corner (combined_samples, labels=param_labels, show_titles=True, title_fmt=\".4f\");\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# fit and see - all"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "base_V_A_mean = np.mean(base_V_A_samp)\n",
    "new_V_A_mean = np.mean(new_V_A_samp)\n",
    "theta_A_mean = np.mean(theta_A_samp)\n",
    "t_A_aff_mean = np.mean(t_A_aff_samp)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# data\n",
    "data_abort_rt = df_to_fit[ (df_to_fit['timed_fix'] < df_to_fit['intended_fix']) & \\\n",
    "                            (df_to_fit['timed_fix'] > T_trunc) ]['timed_fix'].values\n",
    "\n",
    "bin_width = 0.03\n",
    "bins = np.arange(0, np.max(data_abort_rt), bin_width)\n",
    "t_pts = bins[:-1] + bin_width / 2\n",
    "\n",
    "frac_of_aborts_data = len(data_abort_rt) / len(df_to_fit)\n",
    "print(f'frac of aborts = {frac_of_aborts_data}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def calc_trunc_pdf(t, base_V_A, new_V_A, theta_A, t_A_aff, t_led, trunc_factor):   \n",
    "    # pdf\n",
    "    if t_led == 0:\n",
    "        if t <= T_trunc:\n",
    "            pdf = 0\n",
    "        else:\n",
    "            trunc_factor = 1 - cum_A_t_fn(T_trunc - t_A_aff, new_V_A, theta_A)\n",
    "            pdf = rho_A_t_fn(t - t_A_aff, new_V_A, theta_A) / trunc_factor\n",
    "    else:\n",
    "        if t <= T_trunc:\n",
    "            pdf = 0\n",
    "        else:\n",
    "            pdf = PDF_hit_V_A_change(t - t_A_aff, base_V_A, new_V_A, theta_A, t_led) / trunc_factor\n",
    "    return pdf\n",
    "\n",
    "def calc_trunc_cdf(base_V_A, new_V_A, theta_A, t_A_aff, t_led, t_stim, trunc_factor):\n",
    "    # cdf\n",
    "    if t_stim <= T_trunc:\n",
    "        return 0\n",
    "    if t_led == 0:\n",
    "        trunc_factor = 1 - cum_A_t_fn(T_trunc - t_A_aff, new_V_A, theta_A)\n",
    "        cdf = cum_A_t_fn(t_stim - t_A_aff, new_V_A, theta_A) / trunc_factor\n",
    "    else:\n",
    "        cdf = (CDF_hit_V_A_change(t_stim - t_A_aff, base_V_A, new_V_A, theta_A, t_led)) / trunc_factor\n",
    "    return cdf\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "N_theory = 5000\n",
    "unique_pairs = list(zip(df_to_fit['intended_fix'], df_to_fit['intended_fix'] - df_to_fit['LED_onset_time']))\n",
    "sampled_pairs = random.sample(unique_pairs, min(N_theory, len(unique_pairs)))\n",
    "\n",
    "pdf_ensemble = np.zeros((N_theory, len(t_pts)))\n",
    "cdf_ensemble = np.zeros((N_theory, ))\n",
    "all_areas_pdf_ensemble = np.zeros((N_theory, ))\n",
    "for i, (t_stim, t_led) in tqdm(enumerate (sampled_pairs), total=N_theory):\n",
    "    if t_stim <= t_led:\n",
    "        print('Issue')\n",
    "        break\n",
    "    \n",
    "    trunc_factor = 1 - CDF_hit_V_A_change(T_trunc - t_A_aff_mean, base_V_A_mean, new_V_A_mean, theta_A_mean, t_led)\n",
    "    pdf_ensemble[i,:] = [calc_trunc_pdf(t, base_V_A_mean, new_V_A_mean, theta_A_mean, t_A_aff_mean, t_led, trunc_factor) for t in t_pts]\n",
    "    all_areas_pdf_ensemble[i] = np.trapz(pdf_ensemble[i,:], t_pts)\n",
    "    # if all_areas_pdf_ensemble[i] < 0.8:\n",
    "    #     print(f'params = {t_stim, t_led}')\n",
    "    \n",
    "    cdf_ensemble[i] = calc_trunc_cdf(base_V_A_mean, new_V_A_mean, theta_A_mean, t_A_aff_mean, t_led, t_stim, trunc_factor)\n",
    "    # if cdf_ensemble[i] > 0.2:\n",
    "    #     print(f'params = {t_stim, t_led}')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(10,5))\n",
    "plt.subplot(1,2,1)\n",
    "plt.hist(all_areas_pdf_ensemble, bins=50, density=True, alpha=0.5, label='theory')\n",
    "plt.title(f'mean area = {np.mean(all_areas_pdf_ensemble):.2f}');\n",
    "\n",
    "plt.subplot(1,2,2)\n",
    "plt.hist(cdf_ensemble, bins=50, density=True, alpha=0.5, label='theory')\n",
    "plt.title(f'mean cdf = {np.mean(cdf_ensemble):.2f}');"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# sanity checks\n",
    "cdf_ensemble_mean = np.mean(cdf_ensemble)\n",
    "pdf_ensemble_mean = np.mean(pdf_ensemble, axis=0)\n",
    "print(f'pdf ensemble mean shape = {pdf_ensemble_mean.shape}')\n",
    "print(f'frac aborts theory = {cdf_ensemble_mean}, frac aborts data = {frac_of_aborts_data}')\n",
    "print(f'area under pdf ensemble mean = {np.trapz(pdf_ensemble_mean, t_pts)}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "abort_rt_hist, _ = np.histogram(data_abort_rt, bins=bins, density=True)\n",
    "abort_rt_hist *= frac_of_aborts_data # to make area frac of aborts\n",
    "\n",
    "\n",
    "pdf_ensemble_mean_norm = pdf_ensemble_mean* cdf_ensemble_mean # so that area is frac of aborts"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.plot(t_pts, pdf_ensemble_mean_norm, label='theory')\n",
    "plt.plot(t_pts, abort_rt_hist, label='data')\n",
    "\n",
    "plt.legend()\n",
    "\n",
    "plt.xlabel('truncated abort RT (s)')\n",
    "plt.ylabel('density')\n",
    "plt.title('Area = frac of aborts, V_A step jump,left-trunc,right-censor, LED on')\n",
    "print(f'area under theory = {np.trapz(pdf_ensemble_mean_norm, t_pts)}, area under data = {np.trapz(abort_rt_hist, t_pts)}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# area = 1\n",
    "\n",
    "plt.hist(data_abort_rt, bins=bins, density=True, label='data', histtype='step')\n",
    "plt.plot(t_pts, pdf_ensemble_mean, label='theory')\n",
    "plt.legend()\n",
    "plt.xlabel('truncated abort RT (s)')\n",
    "plt.ylabel('density')\n",
    "\n",
    "plt.title('Area = 1,V_A step jump,left-trunc,right-censor, LED on')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## how many t_stim < 0.3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(10,5))\n",
    "plt.subplot(1,2,1)\n",
    "plt.hist(df_to_fit['intended_fix'], alpha=0.5);\n",
    "plt.axvline(T_trunc);\n",
    "plt.title('tstim')\n",
    "\n",
    "plt.subplot(1,2,2)\n",
    "plt.hist(df_to_fit[df_to_fit['intended_fix'] < 0.3]['intended_fix'], alpha=0.5);\n",
    "plt.title('tstim < 0.3')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# remove t_led = 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "N_theory = 5000\n",
    "unique_pairs = list(zip(df_to_fit['intended_fix'], df_to_fit['intended_fix'] - df_to_fit['LED_onset_time']))\n",
    "# from unique_pairs remove rows where second column is zero\n",
    "unique_pairs = [pair for pair in unique_pairs if pair[1] != 0]\n",
    "\n",
    "sampled_pairs = random.sample(unique_pairs, min(N_theory, len(unique_pairs)))\n",
    "\n",
    "pdf_ensemble = np.zeros((N_theory, len(t_pts)))\n",
    "cdf_ensemble = np.zeros((N_theory, ))\n",
    "all_areas_pdf_ensemble = np.zeros((N_theory, ))\n",
    "for i, (t_stim, t_led) in tqdm(enumerate (sampled_pairs), total=N_theory):\n",
    "    if t_stim <= t_led:\n",
    "        print('Issue')\n",
    "        break\n",
    "    \n",
    "    trunc_factor = 1 - CDF_hit_V_A_change(T_trunc - t_A_aff_mean, base_V_A_mean, new_V_A_mean, theta_A_mean, t_led)\n",
    "    pdf_ensemble[i,:] = [calc_trunc_pdf(t, base_V_A_mean, new_V_A_mean, theta_A_mean, t_A_aff_mean, t_led, trunc_factor) for t in t_pts]\n",
    "    all_areas_pdf_ensemble[i] = np.trapz(pdf_ensemble[i,:], t_pts)\n",
    "    # if all_areas_pdf_ensemble[i] < 0.8:\n",
    "    #     print(f'params = {t_stim, t_led}')\n",
    "    \n",
    "    cdf_ensemble[i] = calc_trunc_cdf(base_V_A_mean, new_V_A_mean, theta_A_mean, t_A_aff_mean, t_led, t_stim, trunc_factor)\n",
    "    # if cdf_ensemble[i] > 0.2:\n",
    "    #     print(f'params = {t_stim, t_led}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(10,5))\n",
    "plt.subplot(1,2,1)\n",
    "plt.hist(all_areas_pdf_ensemble, bins=50, density=True, alpha=0.5, label='theory')\n",
    "plt.title(f'mean area = {np.mean(all_areas_pdf_ensemble):.2f}.LED = 0 removed');\n",
    "\n",
    "plt.subplot(1,2,2)\n",
    "plt.hist(cdf_ensemble, bins=50, density=True, alpha=0.5, label='theory')\n",
    "plt.title(f'mean cdf = {np.mean(cdf_ensemble):.2f}. LED = 0 removed');"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# led onset distr"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "led_onset = df_to_fit['intended_fix'] - df_to_fit['LED_onset_time']\n",
    "num_led_onset_zero = np.sum(led_onset == 0)\n",
    "print(f'num led onset zero = {num_led_onset_zero}/{len(df_to_fit)}')\n",
    "print(f'% led onset zero = {100*num_led_onset_zero / len(df_to_fit)}')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
