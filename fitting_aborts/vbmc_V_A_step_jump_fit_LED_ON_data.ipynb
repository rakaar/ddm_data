{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from joblib import Parallel, delayed\n",
    "from tqdm import tqdm\n",
    "from scipy.integrate import quad\n",
    "import pandas as pd\n",
    "import random\n",
    "from pyvbmc import VBMC\n",
    "from V_A_step_jump_fit_utils import PDF_hit_V_A_change, CDF_hit_V_A_change, rho_A_t_fn, cum_A_t_fn\n",
    "from tqdm import tqdm\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ABL: [20 40 60]\n",
      "ILD: [-16.  -8.  -4.  -2.  -1.   1.   2.   4.   8.  16.]\n"
     ]
    }
   ],
   "source": [
    "# read out_LED.csv as dataframe\n",
    "og_df = pd.read_csv('../out_LED.csv')\n",
    "\n",
    "# chose non repeat trials - 0 or 2 or missing\n",
    "df = og_df[ og_df['repeat_trial'].isin([0,2]) | og_df['repeat_trial'].isna() ]\n",
    "\n",
    "# only session type 7\n",
    "session_type = 7    \n",
    "df = df[ df['session_type'].isin([session_type]) ]\n",
    "\n",
    "# training level 16\n",
    "training_level = 16\n",
    "df = df[ df['training_level'].isin([training_level]) ]\n",
    "\n",
    "# find ABL and ILD\n",
    "ABL_arr = df['ABL'].unique()\n",
    "ILD_arr = df['ILD'].unique()\n",
    "\n",
    "\n",
    "# sort ILD arr in ascending order\n",
    "ILD_arr = np.sort(ILD_arr)\n",
    "ABL_arr = np.sort(ABL_arr)\n",
    "\n",
    "print('ABL:', ABL_arr)\n",
    "print('ILD:', ILD_arr)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_to_fit = df[ df['LED_trial'] == 1 ] "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# VBMC"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "T_trunc = 0.3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "def compute_loglike(row, base_V_A, new_V_A, theta_A, t_A_aff):\n",
    "    rt = row['timed_fix']\n",
    "    t_stim = row['intended_fix']\n",
    "    t_led = row['intended_fix'] - row['LED_onset_time']\n",
    "\n",
    "    \n",
    "    if rt - t_A_aff < T_trunc:\n",
    "        likelihood = 0\n",
    "    else:\n",
    "        if t_led == 0: # only new V_A will be used\n",
    "            pdf_trunc_factor = 1 - cum_A_t_fn(T_trunc - t_A_aff, new_V_A, theta_A)\n",
    "            if rt - t_A_aff < t_stim:\n",
    "                likelihood =  rho_A_t_fn(rt - t_A_aff, new_V_A, theta_A) / pdf_trunc_factor\n",
    "            elif rt - t_A_aff > t_stim:\n",
    "                if t_stim < T_trunc:\n",
    "                    likelihood = 1\n",
    "                else:\n",
    "                    likelihood = ( 1 - cum_A_t_fn(t_stim - t_A_aff, new_V_A, theta_A) ) / pdf_trunc_factor\n",
    "        else: # V_A change in middle\n",
    "            trunc_factor = 1 - CDF_hit_V_A_change(T_trunc - t_A_aff, base_V_A, new_V_A, theta_A, t_led)\n",
    "            if rt - t_A_aff < t_stim:\n",
    "                likelihood = PDF_hit_V_A_change(rt-t_A_aff, base_V_A, new_V_A, theta_A, t_led) / trunc_factor\n",
    "            elif rt - t_A_aff > t_stim:\n",
    "                if t_stim < T_trunc: # if stim is before truncation, the abort prob = 0\n",
    "                    likelihood = 1\n",
    "                else:\n",
    "                    likelihood = ( 1 - CDF_hit_V_A_change(t_stim - t_A_aff, base_V_A, new_V_A, theta_A, t_led) ) / trunc_factor\n",
    "\n",
    "    if likelihood <= 0:\n",
    "        likelihood = 1e-50\n",
    "\n",
    "    \n",
    "    return np.log(likelihood)    \n",
    "\n",
    "\n",
    "\n",
    "def psiam_tied_loglike_fn(params):\n",
    "    base_V_A, new_V_A, theta_A, t_A_aff = params\n",
    "\n",
    "    all_loglike = Parallel(n_jobs=30)(delayed(compute_loglike)(row, base_V_A, new_V_A, theta_A, t_A_aff)\\\n",
    "                                      for _, row in df_to_fit.iterrows() \\\n",
    "                                        if (not np.isnan(row['timed_fix'] + row['intended_fix'] + row['LED_onset_time']))) \n",
    "                                   \n",
    "\n",
    "    loglike = np.sum(all_loglike)\n",
    "    return loglike"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# bounds"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "base_V_A_bounds = [0.1, 5]\n",
    "new_V_A_bounds = [0.1, 5]\n",
    "theta_A_bounds = [0.1, 5]\n",
    "t_A_aff_bounds = [-5, 0.1]\n",
    "\n",
    "base_V_A_plausible_bounds = [0.5, 3]\n",
    "new_V_A_plausible_bounds = [0.5, 3]\n",
    "theta_A_plausible_bounds = [0.5, 3]\n",
    "t_A_aff_plausible_bounds = [-2, 0.06]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# prior"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def trapezoidal_logpdf(x, a, b, c, d):\n",
    "    if x < a or x > d:\n",
    "        return -np.inf  # Logarithm of zero\n",
    "    area = ((b - a) + (d - c)) / 2 + (c - b)\n",
    "    h_max = 1.0 / area  # Height of the trapezoid to normalize the area to 1\n",
    "    \n",
    "    if a <= x <= b:\n",
    "        pdf_value = ((x - a) / (b - a)) * h_max\n",
    "    elif b < x < c:\n",
    "        pdf_value = h_max\n",
    "    elif c <= x <= d:\n",
    "        pdf_value = ((d - x) / (d - c)) * h_max\n",
    "    else:\n",
    "        pdf_value = 0.0  # This case is redundant due to the initial check\n",
    "\n",
    "    if pdf_value <= 0.0:\n",
    "        return -np.inf\n",
    "    else:\n",
    "        return np.log(pdf_value)\n",
    "    \n",
    "\n",
    "def vbmc_prior_abort_fn(params):\n",
    "    base_V_A, new_V_A, theta_A, t_A_aff = params\n",
    "\n",
    "    base_V_A_logpdf = trapezoidal_logpdf(base_V_A, base_V_A_bounds[0], base_V_A_plausible_bounds[0], base_V_A_plausible_bounds[1], base_V_A_bounds[1])\n",
    "    new_V_A_logpdf = trapezoidal_logpdf(new_V_A, new_V_A_bounds[0], new_V_A_plausible_bounds[0], new_V_A_plausible_bounds[1], new_V_A_bounds[1])\n",
    "    theta_A_logpdf = trapezoidal_logpdf(theta_A, theta_A_bounds[0], theta_A_plausible_bounds[0], theta_A_plausible_bounds[1], theta_A_bounds[1])\n",
    "    t_A_aff_logpdf = trapezoidal_logpdf(t_A_aff, t_A_aff_bounds[0], t_A_aff_plausible_bounds[0], t_A_aff_plausible_bounds[1], t_A_aff_bounds[1])\n",
    "    return base_V_A_logpdf + new_V_A_logpdf + theta_A_logpdf + t_A_aff_logpdf"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# joint"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def vbmc_joint(params):\n",
    "    return vbmc_prior_abort_fn(params) + psiam_tied_loglike_fn(params)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# run vbmc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "lb = [base_V_A_bounds[0], new_V_A_bounds[0], theta_A_bounds[0], t_A_aff_bounds[0]]\n",
    "ub = [base_V_A_bounds[1], new_V_A_bounds[1], theta_A_bounds[1], t_A_aff_bounds[1]]\n",
    "\n",
    "plb = [base_V_A_plausible_bounds[0], new_V_A_plausible_bounds[0], theta_A_plausible_bounds[0], t_A_aff_plausible_bounds[0]]\n",
    "pub = [base_V_A_plausible_bounds[1], new_V_A_plausible_bounds[1], theta_A_plausible_bounds[1], t_A_aff_plausible_bounds[1]]\n",
    "\n",
    "np.random.seed(42)\n",
    "base_V_A_0 = np.random.uniform(base_V_A_plausible_bounds[0], base_V_A_plausible_bounds[1])\n",
    "new_V_A_0 = np.random.uniform(new_V_A_plausible_bounds[0], new_V_A_plausible_bounds[1])\n",
    "theta_A_0 = np.random.uniform(theta_A_plausible_bounds[0], theta_A_plausible_bounds[1])\n",
    "t_A_aff_0 = np.random.uniform(t_A_aff_plausible_bounds[0], t_A_aff_plausible_bounds[1])\n",
    "\n",
    "x_0 = np.array([base_V_A_0, new_V_A_0, theta_A_0, t_A_aff_0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Reshaping x0 to row vector.\n",
      "Reshaping lower bounds to (1, 4).\n",
      "Reshaping upper bounds to (1, 4).\n",
      "Reshaping plausible lower bounds to (1, 4).\n",
      "Reshaping plausible upper bounds to (1, 4).\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[10], line 2\u001b[0m\n\u001b[1;32m      1\u001b[0m vbmc \u001b[38;5;241m=\u001b[39m VBMC(vbmc_joint, x_0, lb, ub, plb, pub, options\u001b[38;5;241m=\u001b[39m{\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mdisplay\u001b[39m\u001b[38;5;124m'\u001b[39m: \u001b[38;5;124m'\u001b[39m\u001b[38;5;124moff\u001b[39m\u001b[38;5;124m'\u001b[39m})\n\u001b[0;32m----> 2\u001b[0m vp, results \u001b[38;5;241m=\u001b[39m \u001b[43mvbmc\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43moptimize\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/raghavendra/ddm_data/.venv/lib/python3.12/site-packages/pyvbmc/vbmc/vbmc.py:1098\u001b[0m, in \u001b[0;36mVBMC.optimize\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m   1091\u001b[0m     \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m   1092\u001b[0m         \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39moptim_state[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mhyp_dict\u001b[39m\u001b[38;5;124m\"\u001b[39m] \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mhyp_dict\n\u001b[1;32m   1093\u001b[0m         (\n\u001b[1;32m   1094\u001b[0m             \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mfunction_logger,\n\u001b[1;32m   1095\u001b[0m             \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39moptim_state,\n\u001b[1;32m   1096\u001b[0m             \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mvp,\n\u001b[1;32m   1097\u001b[0m             \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mgp,\n\u001b[0;32m-> 1098\u001b[0m         ) \u001b[38;5;241m=\u001b[39m \u001b[43mactive_sample\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m   1099\u001b[0m \u001b[43m            \u001b[49m\u001b[43mgp_search\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1100\u001b[0m \u001b[43m            \u001b[49m\u001b[43mnew_funevals\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1101\u001b[0m \u001b[43m            \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43moptim_state\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1102\u001b[0m \u001b[43m            \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfunction_logger\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1103\u001b[0m \u001b[43m            \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43miteration_history\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1104\u001b[0m \u001b[43m            \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mvp\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1105\u001b[0m \u001b[43m            \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43moptions\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1106\u001b[0m \u001b[43m        \u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1107\u001b[0m         \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mhyp_dict \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39moptim_state[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mhyp_dict\u001b[39m\u001b[38;5;124m\"\u001b[39m]\n\u001b[1;32m   1109\u001b[0m \u001b[38;5;66;03m# Number of training inputs\u001b[39;00m\n",
      "File \u001b[0;32m~/raghavendra/ddm_data/.venv/lib/python3.12/site-packages/pyvbmc/vbmc/active_sample.py:484\u001b[0m, in \u001b[0;36mactive_sample\u001b[0;34m(gp, sample_count, optim_state, function_logger, iteration_history, vp, options)\u001b[0m\n\u001b[1;32m    481\u001b[0m timer\u001b[38;5;241m.\u001b[39mstart_timer(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mfun_time\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m    482\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m np\u001b[38;5;241m.\u001b[39misnan(y_orig):\n\u001b[1;32m    483\u001b[0m     \u001b[38;5;66;03m# Function value is not available, evaluate\u001b[39;00m\n\u001b[0;32m--> 484\u001b[0m     ynew, _, idx_new \u001b[38;5;241m=\u001b[39m \u001b[43mfunction_logger\u001b[49m\u001b[43m(\u001b[49m\u001b[43mxnew\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    485\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m    486\u001b[0m     ynew, _, idx_new \u001b[38;5;241m=\u001b[39m function_logger\u001b[38;5;241m.\u001b[39madd(xnew, y_orig)\n",
      "File \u001b[0;32m~/raghavendra/ddm_data/.venv/lib/python3.12/site-packages/pyvbmc/function_logger/function_logger.py:124\u001b[0m, in \u001b[0;36mFunctionLogger.__call__\u001b[0;34m(self, x)\u001b[0m\n\u001b[1;32m    122\u001b[0m     f_val_orig, f_sd \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mfun(x_orig)\n\u001b[1;32m    123\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m--> 124\u001b[0m     f_val_orig \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfun\u001b[49m\u001b[43m(\u001b[49m\u001b[43mx_orig\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    125\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mnoise_flag:\n\u001b[1;32m    126\u001b[0m         f_sd \u001b[38;5;241m=\u001b[39m \u001b[38;5;241m1\u001b[39m\n",
      "Cell \u001b[0;32mIn[8], line 2\u001b[0m, in \u001b[0;36mvbmc_joint\u001b[0;34m(params)\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mvbmc_joint\u001b[39m(params):\n\u001b[0;32m----> 2\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m vbmc_prior_abort_fn(params) \u001b[38;5;241m+\u001b[39m \u001b[43mpsiam_tied_loglike_fn\u001b[49m\u001b[43m(\u001b[49m\u001b[43mparams\u001b[49m\u001b[43m)\u001b[49m\n",
      "Cell \u001b[0;32mIn[5], line 40\u001b[0m, in \u001b[0;36mpsiam_tied_loglike_fn\u001b[0;34m(params)\u001b[0m\n\u001b[1;32m     37\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mpsiam_tied_loglike_fn\u001b[39m(params):\n\u001b[1;32m     38\u001b[0m     base_V_A, new_V_A, theta_A, t_A_aff \u001b[38;5;241m=\u001b[39m params\n\u001b[0;32m---> 40\u001b[0m     all_loglike \u001b[38;5;241m=\u001b[39m \u001b[43mParallel\u001b[49m\u001b[43m(\u001b[49m\u001b[43mn_jobs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m-\u001b[39;49m\u001b[38;5;241;43m1\u001b[39;49m\u001b[43m)\u001b[49m\u001b[43m(\u001b[49m\u001b[43mdelayed\u001b[49m\u001b[43m(\u001b[49m\u001b[43mcompute_loglike\u001b[49m\u001b[43m)\u001b[49m\u001b[43m(\u001b[49m\u001b[43mrow\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mbase_V_A\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mnew_V_A\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtheta_A\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mt_A_aff\u001b[49m\u001b[43m)\u001b[49m\u001b[43m\\\u001b[49m\n\u001b[1;32m     41\u001b[0m \u001b[43m                                      \u001b[49m\u001b[38;5;28;43;01mfor\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43m_\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mrow\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;129;43;01min\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mdf_to_fit\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43miterrows\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[43m \u001b[49m\u001b[43m\\\u001b[49m\n\u001b[1;32m     42\u001b[0m \u001b[43m                                        \u001b[49m\u001b[38;5;28;43;01mif\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;129;43;01mnot\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mnp\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43misnan\u001b[49m\u001b[43m(\u001b[49m\u001b[43mrow\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mtimed_fix\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m+\u001b[39;49m\u001b[43m \u001b[49m\u001b[43mrow\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mintended_fix\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m+\u001b[39;49m\u001b[43m \u001b[49m\u001b[43mrow\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mLED_onset_time\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m)\u001b[49m\u001b[43m)\u001b[49m\u001b[43m)\u001b[49m \n\u001b[1;32m     45\u001b[0m     loglike \u001b[38;5;241m=\u001b[39m np\u001b[38;5;241m.\u001b[39msum(all_loglike)\n\u001b[1;32m     46\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m loglike\n",
      "File \u001b[0;32m~/raghavendra/ddm_data/.venv/lib/python3.12/site-packages/joblib/parallel.py:2007\u001b[0m, in \u001b[0;36mParallel.__call__\u001b[0;34m(self, iterable)\u001b[0m\n\u001b[1;32m   2001\u001b[0m \u001b[38;5;66;03m# The first item from the output is blank, but it makes the interpreter\u001b[39;00m\n\u001b[1;32m   2002\u001b[0m \u001b[38;5;66;03m# progress until it enters the Try/Except block of the generator and\u001b[39;00m\n\u001b[1;32m   2003\u001b[0m \u001b[38;5;66;03m# reaches the first `yield` statement. This starts the asynchronous\u001b[39;00m\n\u001b[1;32m   2004\u001b[0m \u001b[38;5;66;03m# dispatch of the tasks to the workers.\u001b[39;00m\n\u001b[1;32m   2005\u001b[0m \u001b[38;5;28mnext\u001b[39m(output)\n\u001b[0;32m-> 2007\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m output \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mreturn_generator \u001b[38;5;28;01melse\u001b[39;00m \u001b[38;5;28;43mlist\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43moutput\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/raghavendra/ddm_data/.venv/lib/python3.12/site-packages/joblib/parallel.py:1650\u001b[0m, in \u001b[0;36mParallel._get_outputs\u001b[0;34m(self, iterator, pre_dispatch)\u001b[0m\n\u001b[1;32m   1647\u001b[0m     \u001b[38;5;28;01myield\u001b[39;00m\n\u001b[1;32m   1649\u001b[0m     \u001b[38;5;28;01mwith\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backend\u001b[38;5;241m.\u001b[39mretrieval_context():\n\u001b[0;32m-> 1650\u001b[0m         \u001b[38;5;28;01myield from\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_retrieve()\n\u001b[1;32m   1652\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mGeneratorExit\u001b[39;00m:\n\u001b[1;32m   1653\u001b[0m     \u001b[38;5;66;03m# The generator has been garbage collected before being fully\u001b[39;00m\n\u001b[1;32m   1654\u001b[0m     \u001b[38;5;66;03m# consumed. This aborts the remaining tasks if possible and warn\u001b[39;00m\n\u001b[1;32m   1655\u001b[0m     \u001b[38;5;66;03m# the user if necessary.\u001b[39;00m\n\u001b[1;32m   1656\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_exception \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mTrue\u001b[39;00m\n",
      "File \u001b[0;32m~/raghavendra/ddm_data/.venv/lib/python3.12/site-packages/joblib/parallel.py:1762\u001b[0m, in \u001b[0;36mParallel._retrieve\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m   1757\u001b[0m \u001b[38;5;66;03m# If the next job is not ready for retrieval yet, we just wait for\u001b[39;00m\n\u001b[1;32m   1758\u001b[0m \u001b[38;5;66;03m# async callbacks to progress.\u001b[39;00m\n\u001b[1;32m   1759\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m ((\u001b[38;5;28mlen\u001b[39m(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_jobs) \u001b[38;5;241m==\u001b[39m \u001b[38;5;241m0\u001b[39m) \u001b[38;5;129;01mor\u001b[39;00m\n\u001b[1;32m   1760\u001b[0m     (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_jobs[\u001b[38;5;241m0\u001b[39m]\u001b[38;5;241m.\u001b[39mget_status(\n\u001b[1;32m   1761\u001b[0m         timeout\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mtimeout) \u001b[38;5;241m==\u001b[39m TASK_PENDING)):\n\u001b[0;32m-> 1762\u001b[0m     \u001b[43mtime\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43msleep\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m0.01\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1763\u001b[0m     \u001b[38;5;28;01mcontinue\u001b[39;00m\n\u001b[1;32m   1765\u001b[0m \u001b[38;5;66;03m# We need to be careful: the job list can be filling up as\u001b[39;00m\n\u001b[1;32m   1766\u001b[0m \u001b[38;5;66;03m# we empty it and Python list are not thread-safe by\u001b[39;00m\n\u001b[1;32m   1767\u001b[0m \u001b[38;5;66;03m# default hence the use of the lock\u001b[39;00m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "vbmc = VBMC(vbmc_joint, x_0, lb, ub, plb, pub, options={'display': 'off'})\n",
    "vp, results = vbmc.optimize()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# save vbmc\n",
    "vp.save('V_A_step_jump_LED_on_vbmc.pkl', overwrite=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import pickle\n",
    "# with open('V_A_step_jump_LED_on_vbmc.pkl', 'rb') as f:\n",
    "#     vp = pickle.load(f)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# corner plot"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import corner\n",
    "vp_samples = vp.sample(int(1e6))[0]\n",
    "base_V_A_samp = vp_samples[:,0]\n",
    "new_V_A_samp = vp_samples[:,1]\n",
    "theta_A_samp = vp_samples[:,2]\n",
    "t_A_aff_samp = vp_samples[:,3]\n",
    "\n",
    "combined_samples = np.transpose(np.vstack((base_V_A_samp, new_V_A_samp, theta_A_samp, t_A_aff_samp)))\n",
    "param_labels = ['base_V_A', 'new_V_A', 'theta_A', 't_A_aff']\n",
    "corner.corner (combined_samples, labels=param_labels, show_titles=True, title_fmt=\".4f\");\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# fit and see - all"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "base_V_A_mean = np.mean(base_V_A_samp)\n",
    "new_V_A_mean = np.mean(new_V_A_samp)\n",
    "theta_A_mean = np.mean(theta_A_samp)\n",
    "t_A_aff_mean = np.mean(t_A_aff_samp)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# data\n",
    "data_abort_rt = df_to_fit[ (df_to_fit['timed_fix'] < df_to_fit['intended_fix']) & \\\n",
    "                            (df_to_fit['timed_fix'] > T_trunc) ]['timed_fix'].values\n",
    "\n",
    "bin_width = 0.03\n",
    "bins = np.arange(0, np.max(data_abort_rt), bin_width)\n",
    "t_pts = bins[:-1] + bin_width / 2\n",
    "\n",
    "frac_of_aborts_data = len(data_abort_rt) / len(df_to_fit)\n",
    "print(f'frac of aborts = {frac_of_aborts_data}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def calc_trunc_pdf(t, base_V_A, new_V_A, theta_A, t_A_aff, t_led, trunc_factor):   \n",
    "    # pdf\n",
    "    if t_led == 0:\n",
    "        if t <= T_trunc:\n",
    "            pdf = 0\n",
    "        else:\n",
    "            trunc_factor = 1 - cum_A_t_fn(T_trunc - t_A_aff, new_V_A, theta_A)\n",
    "            pdf = rho_A_t_fn(t - t_A_aff, new_V_A, theta_A) / trunc_factor\n",
    "    else:\n",
    "        if t <= T_trunc:\n",
    "            pdf = 0\n",
    "        else:\n",
    "            pdf = PDF_hit_V_A_change(t - t_A_aff, base_V_A, new_V_A, theta_A, t_led) / trunc_factor\n",
    "    return pdf\n",
    "\n",
    "def calc_trunc_cdf(base_V_A, new_V_A, theta_A, t_A_aff, t_led, t_stim, trunc_factor):\n",
    "    # cdf\n",
    "    if t_stim <= T_trunc:\n",
    "        return 0\n",
    "    if t_led == 0:\n",
    "        trunc_factor = 1 - cum_A_t_fn(T_trunc - t_A_aff, new_V_A, theta_A)\n",
    "        cdf = cum_A_t_fn(t_stim - t_A_aff, new_V_A, theta_A) / trunc_factor\n",
    "    else:\n",
    "        cdf = (CDF_hit_V_A_change(t_stim - t_A_aff, base_V_A, new_V_A, theta_A, t_led)) / trunc_factor\n",
    "    return cdf\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "N_theory = 5000\n",
    "unique_pairs = list(zip(df_to_fit['intended_fix'], df_to_fit['intended_fix'] - df_to_fit['LED_onset_time']))\n",
    "sampled_pairs = random.sample(unique_pairs, min(N_theory, len(unique_pairs)))\n",
    "\n",
    "pdf_ensemble = np.zeros((N_theory, len(t_pts)))\n",
    "cdf_ensemble = np.zeros((N_theory, ))\n",
    "all_areas_pdf_ensemble = np.zeros((N_theory, ))\n",
    "for i, (t_stim, t_led) in tqdm(enumerate (sampled_pairs), total=N_theory):\n",
    "    if t_stim <= t_led:\n",
    "        print('Issue')\n",
    "        break\n",
    "    \n",
    "    trunc_factor = 1 - CDF_hit_V_A_change(T_trunc - t_A_aff_mean, base_V_A_mean, new_V_A_mean, theta_A_mean, t_led)\n",
    "    pdf_ensemble[i,:] = [calc_trunc_pdf(t, base_V_A_mean, new_V_A_mean, theta_A_mean, t_A_aff_mean, t_led, trunc_factor) for t in t_pts]\n",
    "    all_areas_pdf_ensemble[i] = np.trapz(pdf_ensemble[i,:], t_pts)\n",
    "    # if all_areas_pdf_ensemble[i] < 0.8:\n",
    "    #     print(f'params = {t_stim, t_led}')\n",
    "    \n",
    "    cdf_ensemble[i] = calc_trunc_cdf(base_V_A_mean, new_V_A_mean, theta_A_mean, t_A_aff_mean, t_led, t_stim, trunc_factor)\n",
    "    # if cdf_ensemble[i] > 0.2:\n",
    "    #     print(f'params = {t_stim, t_led}')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(10,5))\n",
    "plt.subplot(1,2,1)\n",
    "plt.hist(all_areas_pdf_ensemble, bins=50, density=True, alpha=0.5, label='theory')\n",
    "plt.title(f'mean area = {np.mean(all_areas_pdf_ensemble):.2f}');\n",
    "\n",
    "plt.subplot(1,2,2)\n",
    "plt.hist(cdf_ensemble, bins=50, density=True, alpha=0.5, label='theory')\n",
    "plt.title(f'mean cdf = {np.mean(cdf_ensemble):.2f}');"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# sanity checks\n",
    "cdf_ensemble_mean = np.mean(cdf_ensemble)\n",
    "pdf_ensemble_mean = np.mean(pdf_ensemble, axis=0)\n",
    "print(f'pdf ensemble mean shape = {pdf_ensemble_mean.shape}')\n",
    "print(f'frac aborts theory = {cdf_ensemble_mean}, frac aborts data = {frac_of_aborts_data}')\n",
    "print(f'area under pdf ensemble mean = {np.trapz(pdf_ensemble_mean, t_pts)}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "abort_rt_hist, _ = np.histogram(data_abort_rt, bins=bins, density=True)\n",
    "abort_rt_hist *= frac_of_aborts_data # to make area frac of aborts\n",
    "\n",
    "\n",
    "pdf_ensemble_mean_norm = pdf_ensemble_mean* cdf_ensemble_mean # so that area is frac of aborts"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.plot(t_pts, pdf_ensemble_mean_norm, label='theory')\n",
    "plt.plot(t_pts, abort_rt_hist, label='data')\n",
    "\n",
    "plt.legend()\n",
    "\n",
    "plt.xlabel('truncated abort RT (s)')\n",
    "plt.ylabel('density')\n",
    "plt.title('Area = frac of aborts, V_A step jump,left-trunc,right-censor, LED on')\n",
    "print(f'area under theory = {np.trapz(pdf_ensemble_mean_norm, t_pts)}, area under data = {np.trapz(abort_rt_hist, t_pts)}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# area = 1\n",
    "\n",
    "plt.hist(data_abort_rt, bins=bins, density=True, label='data', histtype='step')\n",
    "plt.plot(t_pts, pdf_ensemble_mean, label='theory')\n",
    "plt.legend()\n",
    "plt.xlabel('truncated abort RT (s)')\n",
    "plt.ylabel('density')\n",
    "\n",
    "plt.title('Area = 1,V_A step jump,left-trunc,right-censor, LED on')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## how many t_stim < 0.3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(10,5))\n",
    "plt.subplot(1,2,1)\n",
    "plt.hist(df_to_fit['intended_fix'], alpha=0.5);\n",
    "plt.axvline(T_trunc);\n",
    "plt.title('tstim')\n",
    "\n",
    "plt.subplot(1,2,2)\n",
    "plt.hist(df_to_fit[df_to_fit['intended_fix'] < 0.3]['intended_fix'], alpha=0.5);\n",
    "plt.title('tstim < 0.3')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# remove t_led = 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "N_theory = 5000\n",
    "unique_pairs = list(zip(df_to_fit['intended_fix'], df_to_fit['intended_fix'] - df_to_fit['LED_onset_time']))\n",
    "# from unique_pairs remove rows where second column is zero\n",
    "unique_pairs = [pair for pair in unique_pairs if pair[1] != 0]\n",
    "\n",
    "sampled_pairs = random.sample(unique_pairs, min(N_theory, len(unique_pairs)))\n",
    "\n",
    "pdf_ensemble = np.zeros((N_theory, len(t_pts)))\n",
    "cdf_ensemble = np.zeros((N_theory, ))\n",
    "all_areas_pdf_ensemble = np.zeros((N_theory, ))\n",
    "for i, (t_stim, t_led) in tqdm(enumerate (sampled_pairs), total=N_theory):\n",
    "    if t_stim <= t_led:\n",
    "        print('Issue')\n",
    "        break\n",
    "    \n",
    "    trunc_factor = 1 - CDF_hit_V_A_change(T_trunc - t_A_aff_mean, base_V_A_mean, new_V_A_mean, theta_A_mean, t_led)\n",
    "    pdf_ensemble[i,:] = [calc_trunc_pdf(t, base_V_A_mean, new_V_A_mean, theta_A_mean, t_A_aff_mean, t_led, trunc_factor) for t in t_pts]\n",
    "    all_areas_pdf_ensemble[i] = np.trapz(pdf_ensemble[i,:], t_pts)\n",
    "    # if all_areas_pdf_ensemble[i] < 0.8:\n",
    "    #     print(f'params = {t_stim, t_led}')\n",
    "    \n",
    "    cdf_ensemble[i] = calc_trunc_cdf(base_V_A_mean, new_V_A_mean, theta_A_mean, t_A_aff_mean, t_led, t_stim, trunc_factor)\n",
    "    # if cdf_ensemble[i] > 0.2:\n",
    "    #     print(f'params = {t_stim, t_led}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(10,5))\n",
    "plt.subplot(1,2,1)\n",
    "plt.hist(all_areas_pdf_ensemble, bins=50, density=True, alpha=0.5, label='theory')\n",
    "plt.title(f'mean area = {np.mean(all_areas_pdf_ensemble):.2f}.LED = 0 removed');\n",
    "\n",
    "plt.subplot(1,2,2)\n",
    "plt.hist(cdf_ensemble, bins=50, density=True, alpha=0.5, label='theory')\n",
    "plt.title(f'mean cdf = {np.mean(cdf_ensemble):.2f}. LED = 0 removed');"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# led onset distr"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "led_onset = df_to_fit['intended_fix'] - df_to_fit['LED_onset_time']\n",
    "num_led_onset_zero = np.sum(led_onset == 0)\n",
    "print(f'num led onset zero = {num_led_onset_zero}/{len(df_to_fit)}')\n",
    "print(f'% led onset zero = {100*num_led_onset_zero / len(df_to_fit)}')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
