{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import pandas as pd\n",
    "from tqdm import tqdm\n",
    "from joblib import Parallel, delayed\n",
    "from pyvbmc import VBMC\n",
    "import corner\n",
    "from tqdm import tqdm\n",
    "import random\n",
    "from scipy.integrate import cumulative_trapezoid as cumtrapz\n",
    "\n",
    "from time_vary_norm_utils import (\n",
    "    up_or_down_RTs_fit_fn, cum_pro_and_reactive_time_vary_fn,\n",
    "    rho_A_t_VEC_fn, up_or_down_RTs_fit_wrt_stim_fn)\n",
    "from types import SimpleNamespace\n",
    "import pickle\n",
    "\n",
    "from time_vary_and_norm_simulators import psiam_tied_data_gen_wrapper_rate_norm_time_vary_fn\n",
    "from tqdm.notebook import tqdm\n",
    "from scipy.integrate import trapezoid as trapz\n",
    "from time_vary_and_norm_simulators import phi_t_fn\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ABL: [20 40 60]\n",
      "ILD: [-16.  -8.  -4.  -2.  -1.   1.   2.   4.   8.  16.]\n"
     ]
    }
   ],
   "source": [
    "# read out_LED.csv as dataframe\n",
    "og_df = pd.read_csv('../out_LED.csv')\n",
    "\n",
    "# chose non repeat trials - 0 or 2 or missing\n",
    "df = og_df[ og_df['repeat_trial'].isin([0,2]) | og_df['repeat_trial'].isna() ]\n",
    "\n",
    "# only session type 7\n",
    "session_type = 7    \n",
    "df = df[ df['session_type'].isin([session_type]) ]\n",
    "\n",
    "# training level 16\n",
    "training_level = 16\n",
    "df = df[ df['training_level'].isin([training_level]) ]\n",
    "\n",
    "df = df[  df['LED_trial'] == 0 ]\n",
    "\n",
    "# 1 is right , -1 is left\n",
    "df['choice'] = df['response_poke'].apply(lambda x: 1 if x == 3 else (-1 if x == 2 else random.choice([1, -1])))\n",
    "\n",
    "# 1 or 0 if the choice was correct or not\n",
    "df['correct'] = (df['ILD'] * df['choice']).apply(lambda x: 1 if x > 0 else 0)\n",
    "\n",
    "# find ABL and ILD\n",
    "ABL_arr = df['ABL'].unique()\n",
    "ILD_arr = df['ILD'].unique()\n",
    "\n",
    "\n",
    "# sort ILD arr in ascending order\n",
    "ILD_arr = np.sort(ILD_arr)\n",
    "ABL_arr = np.sort(ABL_arr)\n",
    "\n",
    "print('ABL:', ABL_arr)\n",
    "print('ILD:', ILD_arr)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "len df_led_off = 66226\n",
      "52799\n"
     ]
    }
   ],
   "source": [
    "# LED off rows\n",
    "df_led_off = df[ df['LED_trial'] == 0 ]\n",
    "print(f'len df_led_off = {len(df_led_off)}')\n",
    "\n",
    "# > 0 and < 1s valid rt \n",
    "df_led_off_valid = df_led_off[\n",
    "    (df_led_off['timed_fix'] - df_led_off['intended_fix'] > 0) &\n",
    "    (df_led_off['timed_fix'] - df_led_off['intended_fix'] < 1)\n",
    "]\n",
    "\n",
    "df_led_off_valid = df_led_off_valid[df_led_off_valid['response_poke'].isin([2,3])]\n",
    "\n",
    "print(len(df_led_off_valid))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## ******* REMOVE ILD 16 **************"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "len of df_led_off_valid = 42096\n"
     ]
    }
   ],
   "source": [
    "df_led_off_valid = df_led_off_valid[~df_led_off_valid['ILD'].isin([16, -16])].copy()\n",
    "print(f'len of df_led_off_valid = {len(df_led_off_valid)}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "V_A = 1.596\n",
    "theta_A = 2.531\n",
    "t_A_aff = -0.226\n",
    "# del_go = 0.13 # TO BE FIT\n",
    "\n",
    "\n",
    "# fix lambda and theta\n",
    "rate_lambda = 1.935\n",
    "theta_E = 3.03"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# phi params\n",
    "bump_offset = 0\n",
    "# bump_width = 0.240\n",
    "# dip_width = 0.038\n",
    "# dip_height = 0.327\n",
    "\n",
    "K_max = 10"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# vbmc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "is_norm = False\n",
    "is_time_vary = True"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "rate_norm_l = np.nan"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## loglike fn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "def compute_loglike(row, T_0, Z_E, t_E_aff, bump_height, bump_width, dip_height, dip_width, del_go):\n",
    "    \n",
    "    timed_fix = row['timed_fix']\n",
    "    intended_fix = row['intended_fix']\n",
    "    \n",
    "    \n",
    "    ILD = row['ILD']\n",
    "    ABL = row['ABL']\n",
    "    choice = 2*row['response_poke'] - 5\n",
    "\n",
    "    rt = timed_fix\n",
    "    t_stim = intended_fix\n",
    "\n",
    "    phi_params = {\n",
    "        'h1': bump_width,\n",
    "        'a1': bump_height,\n",
    "        'h2': dip_width,\n",
    "        'a2': dip_height,\n",
    "        'b1': bump_offset\n",
    "    }\n",
    "\n",
    "    phi_params_obj = SimpleNamespace(**phi_params)\n",
    "    \n",
    "    trunc_factor_p_joint = cum_pro_and_reactive_time_vary_fn(\n",
    "                            t_stim + 1,\n",
    "                            V_A, theta_A, t_A_aff,\n",
    "                            t_stim, ABL, ILD, rate_lambda, T_0, theta_E, Z_E, t_E_aff,\n",
    "                            phi_params_obj, rate_norm_l, \n",
    "                            is_norm, is_time_vary, K_max) \\\n",
    "                            - \\\n",
    "                            cum_pro_and_reactive_time_vary_fn(\n",
    "                            t_stim,\n",
    "                            V_A, theta_A, t_A_aff,\n",
    "                            t_stim, ABL, ILD, rate_lambda, T_0, theta_E, Z_E, t_E_aff,\n",
    "                            phi_params_obj, rate_norm_l, \n",
    "                            is_norm, is_time_vary, K_max) + 1e-10\n",
    "    P_joint_rt_choice = up_or_down_RTs_fit_fn(\n",
    "                    rt, choice,\n",
    "                    V_A, theta_A, t_A_aff,\n",
    "                    t_stim, ABL, ILD, rate_lambda, T_0, theta_E, Z_E, t_E_aff, del_go,\n",
    "                    phi_params_obj, rate_norm_l, \n",
    "                    is_norm, is_time_vary, K_max)\n",
    "\n",
    "    P_joint_rt_choice_trunc = max(P_joint_rt_choice / (trunc_factor_p_joint + 1e-10), 1e-10)\n",
    "    return np.log(P_joint_rt_choice_trunc)\n",
    "    \n",
    "    \n",
    "\n",
    "\n",
    "def vbmc_loglike_fn(params):\n",
    "    T_0, w, t_E_aff, bump_height, bump_width, dip_height, dip_width, del_go = params\n",
    "    Z_E = (w - 0.5) * 2 * theta_E\n",
    "\n",
    "    all_loglike = Parallel(n_jobs=30)(delayed(compute_loglike)(row, T_0, Z_E, t_E_aff, bump_height, bump_width, dip_height, dip_width, del_go)\\\n",
    "                                       for _, row in df_led_off_valid.iterrows() )\n",
    "    return np.sum(all_loglike)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## priors"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "T_0_bounds = [1e-3, 600e-3]\n",
    "w_bounds = [0.3, 0.7]\n",
    "t_E_aff_bounds = [0.001, 0.1]\n",
    "bump_height_bounds = [0.02, 1]\n",
    "bump_width_bounds = [0.1, 1]\n",
    "dip_width_bounds = [0.01, 1]\n",
    "dip_height_bounds = [0.001, 1]\n",
    "del_go_bounds = [0.01, 0.15]\n",
    "\n",
    "T_0_plausible_bounds = [80e-3, 200e-3]\n",
    "w_plausible_bounds = [0.45, 0.55]\n",
    "t_E_aff_plausible_bounds = [0.01, 0.05]\n",
    "bump_height_plausible_bounds = [0.1, 0.5]\n",
    "bump_width_plausible_bounds = [0.2, 0.3]\n",
    "dip_width_plausible_bounds = [0.025, 0.05]\n",
    "dip_height_plausible_bounds = [0.2, 0.5]\n",
    "del_go_plausible_bounds = [0.05, 0.14]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "def trapezoidal_logpdf(x, a, b, c, d):\n",
    "    if x < a or x > d:\n",
    "        return -np.inf  # Logarithm of zero\n",
    "    area = ((b - a) + (d - c)) / 2 + (c - b)\n",
    "    h_max = 1.0 / area  # Height of the trapezoid to normalize the area to 1\n",
    "    \n",
    "    if a <= x <= b:\n",
    "        pdf_value = ((x - a) / (b - a)) * h_max\n",
    "    elif b < x < c:\n",
    "        pdf_value = h_max\n",
    "    elif c <= x <= d:\n",
    "        pdf_value = ((d - x) / (d - c)) * h_max\n",
    "    else:\n",
    "        pdf_value = 0.0  # This case is redundant due to the initial check\n",
    "\n",
    "    if pdf_value <= 0.0:\n",
    "        return -np.inf\n",
    "    else:\n",
    "        return np.log(pdf_value)\n",
    "\n",
    "def vbmc_prior_fn(params):\n",
    "    T_0, w, t_E_aff, bump_height, bump_width, dip_height, dip_width, del_go = params\n",
    "\n",
    "    T_0_logpdf = trapezoidal_logpdf(\n",
    "        T_0,\n",
    "        T_0_bounds[0],\n",
    "        T_0_plausible_bounds[0],\n",
    "        T_0_plausible_bounds[1],\n",
    "        T_0_bounds[1]\n",
    "    )\n",
    "\n",
    "    \n",
    "    w_logpdf = trapezoidal_logpdf(\n",
    "        w,\n",
    "        w_bounds[0],\n",
    "        w_plausible_bounds[0],\n",
    "        w_plausible_bounds[1],\n",
    "        w_bounds[1]\n",
    "    )\n",
    "\n",
    "    t_E_aff_logpdf = trapezoidal_logpdf(\n",
    "        t_E_aff,\n",
    "        t_E_aff_bounds[0],\n",
    "        t_E_aff_plausible_bounds[0],\n",
    "        t_E_aff_plausible_bounds[1],\n",
    "        t_E_aff_bounds[1]\n",
    "    )\n",
    "\n",
    "    bump_height_logpdf = trapezoidal_logpdf(\n",
    "        bump_height,\n",
    "        bump_height_bounds[0],\n",
    "        bump_height_plausible_bounds[0],\n",
    "        bump_height_plausible_bounds[1],\n",
    "        bump_height_bounds[1]\n",
    "    )\n",
    "\n",
    "    bump_width_logpdf = trapezoidal_logpdf(\n",
    "        bump_width,\n",
    "        bump_width_bounds[0],\n",
    "        bump_width_plausible_bounds[0],\n",
    "        bump_width_plausible_bounds[1],\n",
    "        bump_width_bounds[1]\n",
    "    )\n",
    "\n",
    "    dip_height_logpdf = trapezoidal_logpdf(\n",
    "        dip_height,\n",
    "        dip_height_bounds[0],\n",
    "        dip_height_plausible_bounds[0],\n",
    "        dip_height_plausible_bounds[1],\n",
    "        dip_height_bounds[1]\n",
    "    )\n",
    "\n",
    "    dip_width_logpdf = trapezoidal_logpdf(\n",
    "        dip_width,\n",
    "        dip_width_bounds[0],\n",
    "        dip_width_plausible_bounds[0],\n",
    "        dip_width_plausible_bounds[1],\n",
    "        dip_width_bounds[1]\n",
    "    )\n",
    "\n",
    "    del_go_logpdf = trapezoidal_logpdf(\n",
    "        del_go,\n",
    "        del_go_bounds[0],\n",
    "        del_go_plausible_bounds[0],\n",
    "        del_go_plausible_bounds[1],\n",
    "        del_go_bounds[1]\n",
    "    )\n",
    "\n",
    "    return (\n",
    "        T_0_logpdf +\n",
    "        w_logpdf +\n",
    "        t_E_aff_logpdf +\n",
    "        bump_height_logpdf +\n",
    "        bump_width_logpdf +\n",
    "        dip_height_logpdf +\n",
    "        dip_width_logpdf + \n",
    "        del_go_logpdf\n",
    "    )\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## prior + loglike"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "def vbmc_joint_fn(params):\n",
    "    priors = vbmc_prior_fn(params)\n",
    "    loglike = vbmc_loglike_fn(params)\n",
    "\n",
    "    return priors + loglike"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# run vbmc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Reshaping x0 to row vector.\n",
      "Reshaping lower bounds to (1, 8).\n",
      "Reshaping upper bounds to (1, 8).\n",
      "Reshaping plausible lower bounds to (1, 8).\n",
      "Reshaping plausible upper bounds to (1, 8).\n",
      "vbmc:InitialPointsOutsidePB. The starting points X0 are not inside the provided plausible bounds PLB and PUB. Expanding the plausible bounds...\n",
      "Beginning variational optimization assuming EXACT observations of the log-joint.\n",
      " Iteration  f-count    Mean[ELBO]    Std[ELBO]    sKL-iter[q]   K[q]  Convergence  Action\n",
      "     0         10     -403539.73      1529.75    358170.88        2        inf     start warm-up\n",
      "     1         15     -381794.05      1869.71     28443.95        2        inf     \n",
      "     2         20     -367891.13      1627.12     19119.80        2   2.77e+05     \n",
      "     3         25     -360170.84      1601.68      9575.32        2   1.44e+05     \n",
      "     4         30     -359737.30       716.75       811.48        2   1.34e+04     \n",
      "     5         35     -317232.73      4912.76    270035.70        2   3.34e+06     \n",
      "     6         40     -285090.93      1913.59    113295.11        2   1.45e+06     \n",
      "     7         45     -277526.30      4368.47   1378305.45        2   1.63e+07     \n",
      "     8         50     -246208.14      2083.86  35685443.83        2   4.21e+08     \n",
      "     9         55     -239392.31      2177.61     36017.74        2   4.54e+05     \n",
      "    10         60     -236160.52      2234.86    347157.61        2   4.11e+06     \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/rlab/raghavendra/ddm_data/.venv/lib/python3.12/site-packages/cma/evolution_strategy.py:3379: RuntimeWarning: invalid value encountered in scalar subtract\n",
      "  current_fitness_range < opts['tolfunrel'] * (es.fit.median0 - es.fit.median_min),\n",
      "/home/rlab/raghavendra/ddm_data/.venv/lib/python3.12/site-packages/cma/evolution_strategy.py:3379: RuntimeWarning: invalid value encountered in scalar multiply\n",
      "  current_fitness_range < opts['tolfunrel'] * (es.fit.median0 - es.fit.median_min),\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    11         65     -182961.02      6241.27    269275.50        2   3.37e+06     \n",
      "    12         70     -170258.25      1849.69    253135.83        2   3.03e+06     \n",
      "    13         75     -168170.95      1178.73       436.39        2    1.6e+04     \n",
      "    14         80     -169341.40       942.28       137.23        2   8.66e+03     \n",
      "    15         85     -168326.41      1366.20      2113.13        2   3.28e+04     \n",
      "    16         90     -154073.67      9960.17    204732.65        2   2.49e+06     \n",
      "    17         95     -154443.82      3555.69      9195.80        2   1.21e+05     \n",
      "    18        100     -154418.83      2501.40      1751.55        2   2.91e+04     \n",
      "    19        105     -152918.08      4903.65      5637.55        2   8.78e+04     \n",
      "    20        110     -153658.60      2538.13      4397.25        2   6.28e+04     \n",
      "    21        115     -150599.52      6530.69    990760.87        2   1.17e+07     \n",
      "    22        120     -136212.83      2229.97 1315673109903.09        2   1.55e+13     \n",
      "    23        125     -136106.40      3327.22    166695.89        2   1.98e+06     \n",
      "    24        130     -135447.86       898.84      6065.61        2   7.67e+04     \n",
      "    25        135     -129255.55      4125.90  23814384.25        2   2.81e+08     \n",
      "    26        140     -130286.52      2757.68       345.99        2   1.67e+04     \n",
      "    27        145     -129671.03      3598.37      4170.42        2   6.32e+04     \n",
      "    28        150     -128499.19      4230.53      1217.23        2   3.24e+04     \n",
      "    29        155     -129082.96      3829.69    533006.61        2    6.3e+06     \n",
      "    30        160     -129071.16      2767.65     33739.48        2   4.07e+05     \n",
      "    31        165     -128070.58      3419.74    115779.85        2   1.38e+06     \n",
      "    32        170     -127394.50      4372.11       744.47        2   2.56e+04     \n",
      "    33        175     -127430.97      3739.03     44502.83        2   5.37e+05     \n",
      "    34        180     -127821.04      3582.46      1441.84        2   3.02e+04     \n",
      "    35        185     -128519.93      2475.63    129814.18        2   1.54e+06     \n",
      "    36        190     -128243.56      1466.39     27424.69        2   3.29e+05     \n",
      "    37        195     -126327.80      3299.78    120575.91        2   1.44e+06     \n",
      "    38        200     -128241.98      2438.38      1632.20        2   3.37e+04     \n",
      "    39        205     -127776.21      3209.33       728.92        2   2.08e+04     \n",
      "    40        210     -128290.16      2879.65       420.33        2   1.63e+04     \n",
      "    41        215     -127989.91      2737.95      4237.21        2   6.01e+04     \n",
      "    42        220     -128158.62      3067.69      4266.54        2   6.11e+04     \n",
      "    43        225     -128253.58      2605.10    329964.14        2    3.9e+06     \n",
      "    44        230     -128666.24      2214.35     99988.15        2   1.19e+06     \n",
      "    45        235     -128478.96      1205.02 554854789.57        2   6.54e+09     \n",
      "    46        240     -128192.66      1796.32    516079.13        2   6.09e+06     \n",
      "    47        245     -127937.36      1892.76   4771974.45        2   5.62e+07     \n",
      "    48        250     -128587.74      1058.45   2905148.95        2   3.42e+07     \n",
      "    49        255     -128759.90       645.89      2030.63        2   2.67e+04     \n",
      "    50        260     -126507.00      3999.04  10342746.66        2   1.22e+08     \n",
      "    51        265     -125231.31      4073.08 14973187844.92        2   1.76e+11     \n",
      "    52        270     -126192.09      2876.58   3550325.18        2   4.19e+07     \n",
      "    53        275     -127633.57      3778.11 143069035.46        2   1.69e+09     \n",
      "    54        280     -127752.82      2543.43  30297061.81        2   3.57e+08     switch to GP opt\n",
      "    55        285     -128030.91      1077.82 1562898309.89        2   1.84e+10     trim data\n",
      "    56        290     -128088.52       361.21 15668638498586.62        2   1.85e+14     \n",
      "    57        295     -127197.17       938.50 167446137.46        2   1.97e+09     \n",
      "    58        300     -127428.08       701.45  43568663.62        2   5.13e+08     \n",
      "    59        305     -127512.26      1496.45     10616.76        2    1.3e+05     end warm-up\n",
      "    60        310     -128672.32        42.61     15002.19        2   1.81e+05     \n",
      "    61        315     -128454.68       132.16       370.22        2   5.53e+03     \n",
      "    62        320     -128551.62        78.03     12894.24        3   1.53e+05     \n",
      "    63        325     -128213.84       225.52     53905.21        4   6.37e+05     \n",
      "    64        330     -111866.94      8237.53   1089609.66        4   1.29e+07     \n",
      "    65        335     -112644.36     20055.48    563219.40        4   6.71e+06     \n",
      "    66        340     -105519.72     22908.59    830340.36        4   9.89e+06     \n",
      "    67        345     -119737.78      8517.87  28574820.95        4   3.37e+08     \n",
      "    68        350     -120028.48      6614.88    444442.00        4   5.26e+06     \n",
      "    69        355     -114680.28     12966.46      8576.62        5   1.62e+05     \n",
      "    70        360     -118948.60      7978.13      4137.55        5   8.96e+04     \n",
      "    71        365     -122257.73      6246.11  12569957.71        5   1.48e+08     \n",
      "    72        370     -123670.77      3201.56 1031256213.68        5   1.22e+10     \n",
      "    73        375     -126179.93      1158.46      8806.62        6   1.16e+05     \n",
      "    74        380     -123262.18      5002.00     31976.18        7   4.03e+05     \n",
      "    75        385     -125519.20      2305.50  12093692.64        7   1.43e+08     \n",
      "    76        390     -127048.95      1052.38   2168874.95        7   2.56e+07     \n",
      "    77        395     -127470.89       797.49      6969.09        7   8.62e+04     \n",
      "    78        400     -125861.10      2820.71      4351.38        8    6.6e+04     \n",
      "    79        405     -126697.43      1014.78  15339960.48        8   1.81e+08     \n",
      "    80        410     -123062.20      3931.88      1255.61        9      4e+04     \n",
      "    81        415     -122508.56      4880.04      1146.54        9   3.16e+04     \n",
      "    82        420     -123964.10      2967.40    189252.01        9   2.25e+06     \n",
      "    83        425     -122331.70      3306.64       235.60        9   1.92e+04     \n",
      "    84        430     -125035.74      2838.78       809.42       10    2.8e+04     \n",
      "    85        435     -122887.26      4176.91       191.68       10   2.33e+04     \n",
      "    86        440     -123692.43      2140.14     64553.04       10   7.71e+05     \n",
      "    87        445     -122750.50      2679.48      3224.26       11   5.01e+04     \n",
      "    88        450     -124249.08      3003.38       477.89       11   2.06e+04     \n",
      "    89        455     -122727.60      3580.02    171369.31       11   2.04e+06     \n",
      "    90        460     -123073.38      7018.46      4270.46       11   7.49e+04     \n",
      "    91        465     -126477.26       780.88   1264849.26       11   1.49e+07     \n",
      "    92        470     -116342.61      9222.25    889459.02       12   1.05e+07     \n",
      "    93        475     -110276.46      8266.41      9509.65       12    1.6e+05     \n",
      "    94        480     -119352.00      3431.89      9551.29       12   1.54e+05     \n",
      "    95        485     -123436.70      1743.06     14296.11       12   1.88e+05     \n",
      "    96        490     -121403.02      6757.25    206183.56       13   2.46e+06     \n",
      "    97        495     -124332.14      1588.71      5697.38       13   8.22e+04     \n",
      "    98        500     -122237.53      4690.67      1634.24       13   4.19e+04     \n"
     ]
    }
   ],
   "source": [
    "# Add bounds for all parameters\n",
    "lb = np.array([\n",
    "    T_0_bounds[0],\n",
    "    w_bounds[0],\n",
    "    t_E_aff_bounds[0],\n",
    "    bump_height_bounds[0],\n",
    "    bump_width_bounds[0],\n",
    "    dip_height_bounds[0],\n",
    "    dip_width_bounds[0],\n",
    "    del_go_bounds[0]\n",
    "])\n",
    "\n",
    "ub = np.array([\n",
    "    T_0_bounds[1],\n",
    "    w_bounds[1],\n",
    "    t_E_aff_bounds[1],\n",
    "    bump_height_bounds[1],\n",
    "    bump_width_bounds[1],\n",
    "    dip_height_bounds[1],\n",
    "    dip_width_bounds[1],\n",
    "    del_go_bounds[1]\n",
    "])\n",
    "\n",
    "plb = np.array([\n",
    "    T_0_plausible_bounds[0],\n",
    "    w_plausible_bounds[0],\n",
    "    t_E_aff_plausible_bounds[0],\n",
    "    bump_height_plausible_bounds[0],\n",
    "    bump_width_plausible_bounds[0],\n",
    "    dip_height_plausible_bounds[0],\n",
    "    dip_width_plausible_bounds[0],\n",
    "    del_go_plausible_bounds[0]\n",
    "])\n",
    "\n",
    "pub = np.array([\n",
    "    T_0_plausible_bounds[1],\n",
    "    w_plausible_bounds[1],\n",
    "    t_E_aff_plausible_bounds[1],\n",
    "    bump_height_plausible_bounds[1],\n",
    "    bump_width_plausible_bounds[1],\n",
    "    dip_height_plausible_bounds[1],\n",
    "    dip_width_plausible_bounds[1],\n",
    "    del_go_plausible_bounds[1]\n",
    "])\n",
    "\n",
    "# Initialize with random values within plausible bounds\n",
    "np.random.seed(42)\n",
    "# rate_lambda_0 = np.random.uniform(*rate_lambda_plausible_bounds) \n",
    "# rate_lambda_0 = 0.13 # hardcoded init\n",
    "# T_0_0 = np.random.uniform(*T_0_plausible_bounds)\n",
    "T_0_0 = 100e-3\n",
    "# theta_E_0 = np.random.uniform(*theta_E_plausible_bounds)\n",
    "# theta_E_0 = 45\n",
    "# w_0 = np.random.uniform(*w_plausible_bounds)\n",
    "w_0 = 0.5\n",
    "# t_E_aff_0 = np.random.uniform(*t_E_aff_plausible_bounds)\n",
    "t_E_aff_0 = 0.068\n",
    "bump_height_0 = np.random.uniform(*bump_height_plausible_bounds)\n",
    "bump_width_0 = np.random.uniform(*bump_width_plausible_bounds)\n",
    "dip_height_0 = np.random.uniform(*dip_height_plausible_bounds)\n",
    "dip_width_0 = np.random.uniform(*dip_width_plausible_bounds)\n",
    "del_go_0 = 0.13\n",
    "\n",
    "x_0 = np.array([\n",
    "    T_0_0,\n",
    "    w_0,\n",
    "    t_E_aff_0,\n",
    "    bump_height_0,\n",
    "    bump_width_0,\n",
    "    dip_height_0,\n",
    "    dip_width_0,\n",
    "    del_go_0\n",
    "])\n",
    "\n",
    "# Run VBMC\n",
    "vbmc = VBMC(vbmc_joint_fn, x_0, lb, ub, plb, pub, options={'display': 'on'})\n",
    "vp, results = vbmc.optimize()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# vbmc.save('lamda_theta_fixed_NO_16_no_norm_del_go_vbmc_time_vary_all_phi.pkl', overwrite=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# with open('lamda_theta_fixed_NO_16_no_norm_del_go_vbmc_time_vary_all_phi.pkl', 'rb') as f:\n",
    "#     vp = pickle.load(f).vp"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# continue vbmc run"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# load_filename = \"NO_16_NO_NORM_TEMP_run.pkl\"\n",
    "# vbmc.save(load_filename, overwrite=True)\n",
    "# new_options = {\n",
    "#     'display': 'on', # Keep display on if you like\n",
    "#     'max_fun_evals': 50\n",
    "# }\n",
    "\n",
    "# # Specify the filename where you saved the state\n",
    "\n",
    "\n",
    "# # Load the VBMC instance from the file, applying the new options\n",
    "# print(f\"Loading VBMC state from {load_filename}...\")\n",
    "# vbmc = VBMC.load(load_filename, new_options=new_options)\n",
    "# print(\"State loaded. Resuming optimization...\")\n",
    "\n",
    "# # Resume optimization - this will continue from where it left off\n",
    "# vp, results = vbmc.optimize()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## TEMP SAVE \n",
    "# vbmc.save('fit_all_phi_norm_and_time_vary.pkl')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### ********* READING VP from OLD PICKLE FILE ******************"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# with open('fit_all_phi_norm_and_time_vary.pkl', 'rb') as f:\n",
    "#     vp = pickle.load(f).vp"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# corner"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Sample from the VBMC posterior (returns tuple: samples, log weights)\n",
    "vp_samples = vp.sample(int(1e5))[0]\n",
    "\n",
    "# Convert T_0 to ms\n",
    "vp_samples[:, 0] *= 1e3  # T_0 is at index 1\n",
    "\n",
    "# Parameter labels (order matters!)\n",
    "# param_labels = [r'$T_0$ (ms)', r'$\\theta_E$', r'$w$', r'$t_{E}^{aff}$', 'bump_height', 'bump_width', 'dip_height', 'dip_width', 'del_go']\n",
    "param_labels = ['T0', 'w', 't_E', 'bump_height', 'bump_width', 'dip_height', 'dip_width', 'del_go']\n",
    "\n",
    "# Compute 1st and 99th percentiles for each param to restrict range\n",
    "percentiles = np.percentile(vp_samples, [1, 99], axis=0)\n",
    "_ranges = [(percentiles[0, i], percentiles[1, i]) for i in range(vp_samples.shape[1])]\n",
    "\n",
    "# Create the corner plot\n",
    "fig = corner.corner(\n",
    "    vp_samples,\n",
    "    labels=param_labels,\n",
    "    show_titles=True,\n",
    "    quantiles=[0.025, 0.5, 0.975],\n",
    "    range=_ranges,\n",
    "    title_fmt=\".3f\"\n",
    ")\n",
    "\n",
    "vp_samples[:, 0] /= 1e3  # T_0 is at index 1\n",
    "\n",
    "\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# diagnostics"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## params"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "T_0 = vp_samples[:, 0].mean()\n",
    "\n",
    "w = vp_samples[:, 1].mean()\n",
    "Z_E = (w - 0.5) * 2 * theta_E\n",
    "\n",
    "t_E_aff = vp_samples[:, 2].mean()\n",
    "bump_height = vp_samples[:, 3].mean()\n",
    "bump_width = vp_samples[:, 4].mean()\n",
    "dip_height = vp_samples[:, 5].mean()\n",
    "dip_width = vp_samples[:, 6].mean()\n",
    "del_go = vp_samples[:, 7].mean()\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "# Print them out\n",
    "print(\"Posterior Means:\")\n",
    "print(f\"rate_lambda  = {rate_lambda:.5f}\")\n",
    "print(f\"T_0 (ms)      = {1e3*T_0:.5f}\")\n",
    "print(f\"theta_E       = {theta_E:.5f}\")\n",
    "print(f\"Z_E           = {Z_E:.5f}\")\n",
    "print(f\"t_E_aff       = {1e3*t_E_aff:.5f} ms\")\n",
    "print(f\"rate_norm_l   = {rate_norm_l:.5f}\")\n",
    "print(f'bump height = {bump_height :.5f}')\n",
    "print(f'bump_width = {bump_width :.5f}')\n",
    "print(f'dip_height = {dip_height :.5f}')\n",
    "print(f'dip_width = {dip_width :.5f}')\n",
    "print(f'del go = {del_go :.5f}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "phi_params = {\n",
    "    'h1': bump_width,\n",
    "    'a1': bump_height,\n",
    "    'h2': dip_width,\n",
    "    'a2': dip_height,\n",
    "    'b1': bump_offset\n",
    "}\n",
    "phi_params_obj = SimpleNamespace(**phi_params)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## simualte"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# sample t-stim\n",
    "N_sim = int(1e6)\n",
    "\n",
    "t_stim_samples = df['intended_fix'].sample(N_sim, replace=True).values\n",
    "ABL_samples = df['ABL'].sample(N_sim, replace=True).values\n",
    "ILD_samples = df['ILD'].sample(N_sim, replace=True).values\n",
    "\n",
    "N_print = int(N_sim / 5)\n",
    "dt  = 1e-4\n",
    "\n",
    "rate_norm_l = 0 # NO NORM\n",
    "\n",
    "sim_results = Parallel(n_jobs=30)(\n",
    "    delayed(psiam_tied_data_gen_wrapper_rate_norm_time_vary_fn)(\n",
    "        V_A, theta_A, ABL_samples[iter_num], ILD_samples[iter_num], rate_lambda, T_0, theta_E, Z_E, t_A_aff, t_E_aff, del_go, \n",
    "        t_stim_samples[iter_num], rate_norm_l, iter_num, N_print, phi_params_obj, dt\n",
    "    ) for iter_num in tqdm(range(N_sim))\n",
    ")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# temp - *** ADD 16 back *****"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# LED off rows\n",
    "df_led_off = df[ df['LED_trial'] == 0 ]\n",
    "print(f'len df_led_off = {len(df_led_off)}')\n",
    "\n",
    "# > 0 and < 1s valid rt \n",
    "df_led_off_valid = df_led_off[\n",
    "    (df_led_off['timed_fix'] - df_led_off['intended_fix'] > 0) &\n",
    "    (df_led_off['timed_fix'] - df_led_off['intended_fix'] < 1)\n",
    "]\n",
    "\n",
    "df_led_off_valid = df_led_off_valid[df_led_off_valid['response_poke'].isin([2,3])]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## prepare valid sim df, data df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sim_results_df = pd.DataFrame(sim_results)\n",
    "sim_results_df_valid = sim_results_df[\n",
    "    (sim_results_df['rt'] > sim_results_df['t_stim']) &\n",
    "    (sim_results_df['rt'] - sim_results_df['t_stim'] < 1)\n",
    "].copy()\n",
    "sim_results_df_valid.loc[:, 'correct'] = (sim_results_df_valid['ILD'] * sim_results_df_valid['choice']).apply(lambda x: 1 if x > 0 else 0)\n",
    "\n",
    "\n",
    "df_led_off_valid_renamed = df_led_off_valid.rename(columns = {\n",
    "    'timed_fix': 'rt',\n",
    "    'intended_fix': 't_stim'\n",
    "}).copy()\n",
    "\n",
    "sim_df_1 = sim_results_df_valid.copy()\n",
    "data_df_1 = df_led_off_valid_renamed.copy()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## plots"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "bw = 0.02\n",
    "bins = np.arange(0, 1, bw)\n",
    "bin_centers = bins[:-1] + (0.5 * bw)\n",
    "\n",
    "n_rows = len(ILD_arr)\n",
    "n_cols = len(ABL_arr)\n",
    "\n",
    "fig, axs = plt.subplots(n_rows, n_cols, figsize=(4 * n_cols, 3 * n_rows), sharey='row')\n",
    "\n",
    "for i_idx, ILD in enumerate(ILD_arr):\n",
    "    for a_idx, ABL in enumerate(ABL_arr):\n",
    "        ax = axs[i_idx, a_idx] if n_rows > 1 else axs[a_idx]\n",
    "\n",
    "        sim_df_1_ABL_ILD = sim_df_1[(sim_df_1['ABL'] == ABL) & (sim_df_1['ILD'] == ILD)]\n",
    "        data_df_1_ABL_ILD = data_df_1[(data_df_1['ABL'] == ABL) & (data_df_1['ILD'] == ILD)]\n",
    "\n",
    "        sim_up = sim_df_1_ABL_ILD[sim_df_1_ABL_ILD['choice'] == 1]\n",
    "        sim_down = sim_df_1_ABL_ILD[sim_df_1_ABL_ILD['choice'] == -1]\n",
    "        data_up = data_df_1_ABL_ILD[data_df_1_ABL_ILD['choice'] == 1]\n",
    "        data_down = data_df_1_ABL_ILD[data_df_1_ABL_ILD['choice'] == -1]\n",
    "\n",
    "        sim_up_rt = sim_up['rt'] - sim_up['t_stim']\n",
    "        sim_down_rt = sim_down['rt'] - sim_down['t_stim']\n",
    "        data_up_rt = data_up['rt'] - data_up['t_stim']\n",
    "        data_down_rt = data_down['rt'] - data_down['t_stim']\n",
    "\n",
    "        sim_up_hist, _ = np.histogram(sim_up_rt, bins=bins, density=True)\n",
    "        sim_down_hist, _ = np.histogram(sim_down_rt, bins=bins, density=True)\n",
    "        data_up_hist, _ = np.histogram(data_up_rt, bins=bins, density=True)\n",
    "        data_down_hist, _ = np.histogram(data_down_rt, bins=bins, density=True)\n",
    "\n",
    "        # Normalize histograms by proportion of trials\n",
    "        sim_up_hist *= len(sim_up) / len(sim_df_1_ABL_ILD)\n",
    "        sim_down_hist *= len(sim_down) / len(sim_df_1_ABL_ILD)\n",
    "        data_up_hist *= len(data_up) / len(data_df_1_ABL_ILD)\n",
    "        data_down_hist *= len(data_down) / len(data_df_1_ABL_ILD)\n",
    "\n",
    "        # Plot\n",
    "        ax.plot(bin_centers, data_up_hist, color='b', label='Data' if (i_idx == 0 and a_idx == 0) else \"\")\n",
    "        ax.plot(bin_centers, -data_down_hist, color='b')\n",
    "        ax.plot(bin_centers, sim_up_hist, color='r', label='Sim' if (i_idx == 0 and a_idx == 0) else \"\")\n",
    "        ax.plot(bin_centers, -sim_down_hist, color='r')\n",
    "\n",
    "        # Compute fractions\n",
    "        data_total = len(data_df_1_ABL_ILD)\n",
    "        sim_total = len(sim_df_1_ABL_ILD)\n",
    "        data_up_frac = len(data_up) / data_total if data_total else 0\n",
    "        data_down_frac = len(data_down) / data_total if data_total else 0\n",
    "        sim_up_frac = len(sim_up) / sim_total if sim_total else 0\n",
    "        sim_down_frac = len(sim_down) / sim_total if sim_total else 0\n",
    "\n",
    "        ax.set_title(\n",
    "            f\"ABL: {ABL}, ILD: {ILD}\\n\"\n",
    "            f\"Data,Sim: (+{data_up_frac:.2f},+{sim_up_frac:.2f}), \"\n",
    "            f\"(-{data_down_frac:.2f},-{sim_down_frac:.2f})\"\n",
    "        )\n",
    "        \n",
    "        ax.axhline(0, color='k', linewidth=0.5)\n",
    "        ax.set_xlim([0, 0.7])\n",
    "        if a_idx == 0:\n",
    "            ax.set_ylabel(\"Density (Up / Down flipped)\")\n",
    "        if i_idx == n_rows - 1:\n",
    "            ax.set_xlabel(\"RT (s)\")\n",
    "\n",
    "fig.tight_layout()\n",
    "fig.legend(loc='upper right')\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## tacho"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "bw = 0.02\n",
    "bins = np.arange(0, 1, bw)\n",
    "bin_centers = bins[:-1] + (0.5 * bw)\n",
    "\n",
    "def plot_tacho(df_1):\n",
    "    df_1 = df_1.copy()\n",
    "    df_1['RT_bin'] = pd.cut(df_1['rt'] - df_1['t_stim'], bins=bins, include_lowest=True)\n",
    "    grouped = df_1.groupby('RT_bin', observed=False)['correct'].agg(['mean', 'count'])\n",
    "    grouped['bin_mid'] = grouped.index.map(lambda x: x.mid)\n",
    "    return grouped['bin_mid'], grouped['mean']\n",
    "\n",
    "n_rows = len(ILD_arr)\n",
    "n_cols = len(ABL_arr)\n",
    "\n",
    "# === Define fig2 ===\n",
    "fig2, axs = plt.subplots(n_rows, n_cols, figsize=(4 * n_cols, 3 * n_rows), sharey='row')\n",
    "\n",
    "for i_idx, ILD in enumerate(ILD_arr):\n",
    "    for a_idx, ABL in enumerate(ABL_arr):\n",
    "        ax = axs[i_idx, a_idx] if n_rows > 1 else axs[a_idx]\n",
    "\n",
    "        sim_df_1_ABL_ILD = sim_df_1[(sim_df_1['ABL'] == ABL) & (sim_df_1['ILD'] == ILD)]\n",
    "        data_df_1_ABL_ILD = data_df_1[(data_df_1['ABL'] == ABL) & (data_df_1['ILD'] == ILD)]\n",
    "\n",
    "        sim_tacho_x, sim_tacho_y = plot_tacho(sim_df_1_ABL_ILD)\n",
    "        data_tacho_x, data_tacho_y = plot_tacho(data_df_1_ABL_ILD)\n",
    "\n",
    "        # Plotting\n",
    "        ax.plot(data_tacho_x, data_tacho_y, color='b', label='Data' if (i_idx == 0 and a_idx == 0) else \"\")\n",
    "        ax.plot(sim_tacho_x, sim_tacho_y, color='r', label='Sim' if (i_idx == 0 and a_idx == 0) else \"\")\n",
    "\n",
    "        ax.set_ylim([0.5, 1.05])\n",
    "        ax.set_xlim([0, 0.7])\n",
    "        ax.set_title(f\"ABL: {ABL}, ILD: {ILD}\")\n",
    "        if a_idx == 0:\n",
    "            ax.set_ylabel(\"P(correct)\")\n",
    "        if i_idx == n_rows - 1:\n",
    "            ax.set_xlabel(\"RT (s)\")\n",
    "\n",
    "fig2.tight_layout()\n",
    "fig2.legend(loc='upper right')\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## grand rtd, psycho, tacho"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def grand_rtd(df_1):\n",
    "    df_1_rt = df_1['rt'] - df_1['t_stim']\n",
    "    rt_hist, _ = np.histogram(df_1_rt, bins=bins, density=True)\n",
    "    return rt_hist\n",
    "\n",
    "def plot_psycho(df_1):\n",
    "    prob_choice_dict = {}\n",
    "\n",
    "    all_ABL = np.sort(df_1['ABL'].unique())\n",
    "    all_ILD = np.sort(df_1['ILD'].unique())\n",
    "\n",
    "    for abl in all_ABL:\n",
    "        filtered_df = df_1[df_1['ABL'] == abl]\n",
    "        prob_choice_dict[abl] = [\n",
    "            sum(filtered_df[filtered_df['ILD'] == ild]['choice'] == 1) / len(filtered_df[filtered_df['ILD'] == ild])\n",
    "            for ild in all_ILD\n",
    "        ]\n",
    "\n",
    "    return prob_choice_dict\n",
    "\n",
    "# === Define fig3 ===\n",
    "fig3, axes = plt.subplots(1, 3, figsize=(15, 4))\n",
    "\n",
    "# === Grand RTD ===\n",
    "axes[0].plot(bin_centers, grand_rtd(data_df_1), color='b', label='data')\n",
    "axes[0].plot(bin_centers, grand_rtd(sim_df_1), color='r', label='sim')\n",
    "axes[0].legend()\n",
    "axes[0].set_xlabel('rt wrt stim')\n",
    "axes[0].set_ylabel('density')\n",
    "axes[0].set_title('Grand RTD')\n",
    "\n",
    "# === Grand Psychometric ===\n",
    "data_psycho = plot_psycho(data_df_1)\n",
    "sim_psycho = plot_psycho(sim_df_1)\n",
    "\n",
    "colors = ['r', 'b', 'g']  # Adjust colors for your ABLs\n",
    "for i, ABL in enumerate(ABL_arr):\n",
    "    axes[1].plot(ILD_arr, data_psycho[ABL], color=colors[i], label=f'data ABL={ABL}', marker='o', linestyle='None')\n",
    "    axes[1].plot(ILD_arr, sim_psycho[ABL], color=colors[i], linestyle='-')\n",
    "\n",
    "axes[1].legend()\n",
    "axes[1].set_xlabel('ILD')\n",
    "axes[1].set_ylabel('P(right)')\n",
    "axes[1].set_title('Grand Psychometric')\n",
    "\n",
    "# === Grand Tacho ===\n",
    "data_tacho_x, data_tacho_y = plot_tacho(data_df_1)\n",
    "sim_tacho_x, sim_tacho_y = plot_tacho(sim_df_1)\n",
    "\n",
    "axes[2].plot(data_tacho_x, data_tacho_y, color='b', label='data')\n",
    "axes[2].plot(sim_tacho_x, sim_tacho_y, color='r', label='sim')\n",
    "# axes[2].axvline(del_go - t_E_aff, color='k', alpha=0.3)\n",
    "axes[2].legend()\n",
    "axes[2].set_xlabel('rt wrt stim')\n",
    "axes[2].set_ylabel('acc')\n",
    "axes[2].set_title('Grand Tacho')\n",
    "axes[2].set_ylim(0.5, 1)\n",
    "\n",
    "fig3.tight_layout()\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## save diagnostics in pdf, docx"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "from matplotlib.backends.backend_pdf import PdfPages\n",
    "from docx import Document\n",
    "from docx.shared import Inches\n",
    "\n",
    "# Set your filename prefix\n",
    "output_filename = 'DEL_GO_150ms_NO_16_NO_NORM_only_time_vary'\n",
    "\n",
    "# Ensure output directory\n",
    "os.makedirs('outputs', exist_ok=True)\n",
    "\n",
    "# === Save individual figures as PNGs ===\n",
    "fig1_path = f'outputs/{output_filename}_updown_hist.png'\n",
    "fig2_path = f'outputs/{output_filename}_tacho.png'\n",
    "fig3_path = f'outputs/{output_filename}_grand_summary.png'\n",
    "\n",
    "fig.savefig(fig1_path)\n",
    "fig2.savefig(fig2_path)\n",
    "fig3.savefig(fig3_path)\n",
    "\n",
    "# === Create PDF with all three figures ===\n",
    "pdf_path = f'outputs/{output_filename}.pdf'\n",
    "with PdfPages(pdf_path) as pdf:\n",
    "    for fig_item in [fig, fig2, fig3]:\n",
    "        pdf.savefig(fig_item)\n",
    "\n",
    "# === Create DOCX with all three figures ===\n",
    "doc = Document()\n",
    "doc.add_heading('RTD and Tacho Analysis Results', 0)\n",
    "\n",
    "for img_path in [fig1_path, fig2_path, fig3_path]:\n",
    "    doc.add_page_break()\n",
    "    doc.add_picture(img_path, width=Inches(6.5))\n",
    "\n",
    "docx_path = f'outputs/{output_filename}.docx'\n",
    "doc.save(docx_path)\n",
    "\n",
    "print(f\"✅ Saved PDF to: {pdf_path}\")\n",
    "print(f\"✅ Saved DOCX to: {docx_path}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## mu * phi(t), sigma^2 * phi(t) for each stim"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def mu_phi(t_pts, ABL, ILD):\n",
    "    chi = 17.37\n",
    "\n",
    "    lambda_ABL_term = (10 ** (rate_lambda * (1 - rate_norm_l) * ABL / 20))\n",
    "    lambda_ILD_arg = rate_lambda * ILD / chi\n",
    "    lambda_ILD_L_arg = rate_lambda * rate_norm_l * ILD / chi\n",
    "\n",
    "    # Vectorized phi_t over t_pts\n",
    "    phi_t = phi_t_fn(t_pts, phi_params_obj.h1, phi_params_obj.a1, phi_params_obj.b1, phi_params_obj.h2, phi_params_obj.a2)\n",
    "    \n",
    "    mu = (1 / T_0) * lambda_ABL_term * (np.sinh(lambda_ILD_arg) / np.cosh(lambda_ILD_L_arg)) * phi_t\n",
    "    \n",
    "    return mu * phi_t  # element-wise product for each t in t_pts\n",
    "\n",
    "\n",
    "def sigma_sq_phi(t_pts, ABL, ILD):\n",
    "    chi = 17.37\n",
    "\n",
    "    lambda_ABL_term = (10 ** (rate_lambda * (1 - rate_norm_l) * ABL / 20))\n",
    "    lambda_ILD_arg = rate_lambda * ILD / chi\n",
    "    lambda_ILD_L_arg = rate_lambda * rate_norm_l * ILD / chi\n",
    "\n",
    "    # Vectorized phi_t over t_pts\n",
    "    phi_t = phi_t_fn(t_pts, phi_params_obj.h1, phi_params_obj.a1, phi_params_obj.b1, phi_params_obj.h2, phi_params_obj.a2)\n",
    "    \n",
    "    sigma_sq = (1/T_0) * lambda_ABL_term * ( np.cosh(lambda_ILD_arg) / np.cosh(lambda_ILD_L_arg) ) * phi_t\n",
    "    \n",
    "    return sigma_sq * phi_t  # element-wise product for each t in t_pts\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## mu * phi(t)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "t_pts = np.arange(0, 1, 0.02)\n",
    "ILD_arr_pos = ILD_arr[ILD_arr > 0]\n",
    "\n",
    "colors = ['r', 'b', 'g']  # Assuming len(ABL_arr) == 3\n",
    "\n",
    "# First, precompute y-limits across all ILDs and ABLs\n",
    "all_mu_vals = []\n",
    "for ILD in ILD_arr_pos:\n",
    "    for ABL in ABL_arr:\n",
    "        all_mu_vals.append(mu_phi(t_pts, ABL, ILD))\n",
    "\n",
    "y_min = min(np.min(mu) for mu in all_mu_vals)\n",
    "y_max = max(np.max(mu) for mu in all_mu_vals)\n",
    "\n",
    "# Now, create subplots\n",
    "plt.figure(figsize=(4 * len(ILD_arr_pos), 4))\n",
    "for i_idx, ILD in enumerate(ILD_arr_pos):\n",
    "    ax = plt.subplot(1, len(ILD_arr_pos), i_idx + 1)\n",
    "    \n",
    "    for a_idx, ABL in enumerate(ABL_arr):\n",
    "        ax.plot(t_pts, mu_phi(t_pts, ABL, ILD), label=f'ABL={ABL}', color=colors[a_idx])\n",
    "    \n",
    "    ax.set_title(f'ILD = {ILD}')\n",
    "    ax.set_ylim([y_min, y_max])\n",
    "    \n",
    "    if i_idx == 0:\n",
    "        ax.legend()\n",
    "    else:\n",
    "        ax.legend().set_visible(False)\n",
    "\n",
    "    ax.set_xlabel('Time (s)')\n",
    "    if i_idx == 0:\n",
    "        ax.set_ylabel('μ·φ(t)')\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## sigma^2 x phi(t)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "t_pts = np.arange(0, 1, 0.02)\n",
    "ILD_arr_pos = ILD_arr[ILD_arr > 0]\n",
    "\n",
    "colors = ['r', 'b', 'g']  # Assuming len(ABL_arr) == 3\n",
    "\n",
    "# Compute y-limits for consistent scale\n",
    "all_sigma_vals = []\n",
    "for ILD in ILD_arr_pos:\n",
    "    for ABL in ABL_arr:\n",
    "        all_sigma_vals.append(sigma_sq_phi(t_pts, ABL, ILD))\n",
    "\n",
    "y_min = min(np.min(sig) for sig in all_sigma_vals)\n",
    "y_max = max(np.max(sig) for sig in all_sigma_vals)\n",
    "\n",
    "# Create subplots\n",
    "plt.figure(figsize=(4 * len(ILD_arr_pos), 4))\n",
    "for i_idx, ILD in enumerate(ILD_arr_pos):\n",
    "    ax = plt.subplot(1, len(ILD_arr_pos), i_idx + 1)\n",
    "    \n",
    "    for a_idx, ABL in enumerate(ABL_arr):\n",
    "        ax.plot(t_pts, sigma_sq_phi(t_pts, ABL, ILD), label=f'ABL={ABL}', color=colors[a_idx])\n",
    "    \n",
    "    ax.set_title(f'ILD = {ILD}')\n",
    "    ax.set_ylim([y_min, y_max])\n",
    "    \n",
    "    if i_idx == 0:\n",
    "        ax.legend()\n",
    "    else:\n",
    "        ax.legend().set_visible(False)\n",
    "\n",
    "    ax.set_xlabel('Time (s)')\n",
    "    if i_idx == 0:\n",
    "        ax.set_ylabel('σ²·φ(t)')\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# up and down RTD"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "N_theory = int(1e3)\n",
    "t_stim_and_led_tuple = [(row['intended_fix'], row['intended_fix'] - row['LED_onset_time']) for _, row in df.iterrows()]\n",
    "random_indices = np.random.randint(0, len(t_stim_and_led_tuple), N_theory)\n",
    "t_pts = np.arange(-1, 2, 0.001)\n",
    "\n",
    "P_A_samples = np.zeros((N_theory, len(t_pts)))\n",
    "for idx in range(N_theory):\n",
    "    t_stim, t_LED = t_stim_and_led_tuple[random_indices[idx]]\n",
    "    pdf = rho_A_t_VEC_fn(t_pts - t_A_aff + t_stim, V_A, theta_A)\n",
    "    P_A_samples[idx, :] = pdf\n",
    "\n",
    "P_A_samples_mean = np.mean(P_A_samples, axis=0)\n",
    "C_A_mean = cumtrapz(P_A_samples_mean, t_pts, initial=0)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# per stim, up and down RTD"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create figure and axes row by row to enable row-wise shared Y axes\n",
    "fig = plt.figure(figsize=(18, 24))\n",
    "axes = []\n",
    "\n",
    "for i in range(10):  # 10 rows\n",
    "    row_axes = []\n",
    "    for j in range(3):  # 3 columns\n",
    "        ax = fig.add_subplot(10, 3, i * 3 + j + 1, sharey=row_axes[0] if row_axes else None)\n",
    "        row_axes.append(ax)\n",
    "    axes.append(row_axes)\n",
    "\n",
    "fig.subplots_adjust(hspace=0.8, wspace=0.4)\n",
    "\n",
    "bin_size = 0.02\n",
    "bins = np.arange(-1, 2, bin_size)\n",
    "bin_centers = bins[:-1] + (bin_size / 2)\n",
    "t_pts = np.arange(-1, 2, 0.001)\n",
    "\n",
    "phi_params = {\n",
    "    'h1': bump_width,\n",
    "    'a1': bump_height,\n",
    "    'h2': dip_width,\n",
    "    'a2': dip_height,\n",
    "    'b1': bump_offset\n",
    "}\n",
    "phi_params_obj = SimpleNamespace(**phi_params)\n",
    "\n",
    "# Plotting\n",
    "for a_idx, ABL in enumerate(ABL_arr):\n",
    "    for i_idx, ILD in enumerate(ILD_arr):\n",
    "        ax = axes[i_idx][a_idx]  # axes[row][col] = (ILD, ABL)\n",
    "\n",
    "        # data\n",
    "        # ONLY valid\n",
    "        # df_ABL_ILD = df_led_off_valid[\n",
    "        #     (df_led_off_valid['ABL'] == ABL) & (df_led_off_valid['ILD'] == ILD)]\n",
    "        # valid + aborts\n",
    "        df_led_off_abort_and_valid = df_led_off[(df_led_off['abort_event'] == 3) | (df_led_off['response_poke'].isin([2,3]))]\n",
    "        mask_invalid = ~df_led_off_abort_and_valid['response_poke'].isin([2, 3])\n",
    "        # Step 2: Assign random values (2 or 3 with 50% chance) to those rows\n",
    "        df_led_off_abort_and_valid.loc[mask_invalid, 'response_poke'] = np.random.choice([2, 3], size=mask_invalid.sum())\n",
    "\n",
    "        df_ABL_ILD = df_led_off_abort_and_valid[\n",
    "            (df_led_off_abort_and_valid['ABL'] == ABL) & (df_led_off_abort_and_valid['ILD'] == ILD)]\n",
    "        df_ABL_ILD_up = df_ABL_ILD[df_ABL_ILD['response_poke'] == 3]\n",
    "        df_ABL_ILD_down = df_ABL_ILD[df_ABL_ILD['response_poke'] == 2]\n",
    "\n",
    "        df_ABL_ILD_up_rt = df_ABL_ILD_up['timed_fix'] - df_ABL_ILD_up['intended_fix']\n",
    "        df_ABL_ILD_down_rt = df_ABL_ILD_down['timed_fix'] - df_ABL_ILD_down['intended_fix']\n",
    "\n",
    "        data_up_rt_hist, _ = np.histogram(df_ABL_ILD_up_rt, bins=bins, density=True)\n",
    "        data_down_rt_hist, _ = np.histogram(df_ABL_ILD_down_rt, bins=bins, density=True)\n",
    "\n",
    "        data_frac_up = len(df_ABL_ILD_up) / len(df_ABL_ILD)\n",
    "        data_frac_down = len(df_ABL_ILD_down) / len(df_ABL_ILD)\n",
    "\n",
    "        # theory\n",
    "        theory_ABL_ILD_up = np.zeros_like(t_pts)\n",
    "        theory_ABL_ILD_down = np.zeros_like(t_pts)\n",
    "\n",
    "        for idx, t in enumerate(t_pts):\n",
    "            P_A = P_A_samples_mean[idx]\n",
    "            C_A = C_A_mean[idx]\n",
    "            theory_ABL_ILD_up[idx] = up_or_down_RTs_fit_wrt_stim_fn(\n",
    "                t, 1, P_A, C_A,\n",
    "                t_stim, ABL, ILD, rate_lambda, T_0, theta_E, Z_E, t_E_aff, del_go,\n",
    "                phi_params_obj, rate_norm_l, is_norm, is_time_vary, K_max)\n",
    "\n",
    "            theory_ABL_ILD_down[idx] = up_or_down_RTs_fit_wrt_stim_fn(\n",
    "                t, -1, P_A, C_A,\n",
    "                t_stim, ABL, ILD, rate_lambda, T_0, theta_E, Z_E, t_E_aff, del_go,\n",
    "                phi_params_obj, rate_norm_l, is_norm, is_time_vary, K_max)\n",
    "\n",
    "        ax.plot(bin_centers, data_up_rt_hist * data_frac_up, 'b--', label='Data Up' if i_idx == 0 and a_idx == 0 else \"\")\n",
    "        ax.plot(bin_centers, -data_down_rt_hist * data_frac_down, 'b--', label='Data Down' if i_idx == 0 and a_idx == 0 else \"\")\n",
    "        ax.plot(t_pts, theory_ABL_ILD_up, 'r-', label='Theory Up' if i_idx == 0 and a_idx == 0 else \"\")\n",
    "        ax.plot(t_pts, -theory_ABL_ILD_down, 'r-', label='Theory Down' if i_idx == 0 and a_idx == 0 else \"\")\n",
    "        print(f'### ABL = {ABL}, ILD = {ILD} ###')\n",
    "        print(f'theory areas:')\n",
    "        theory_area_up = trapz(theory_ABL_ILD_up, t_pts); theory_area_down = trapz(theory_ABL_ILD_down, t_pts)\n",
    "        print(f'Up: {theory_area_up :.3f}, down={theory_area_down :.3f}, up + down = {(theory_area_up  + theory_area_down) :.3f}')\n",
    "        print(f'data areas:')\n",
    "        print(f'up = {data_frac_up :.3f}, down = {data_frac_down :.3f}, up + down = {(data_frac_up + data_frac_down) :.3f}')\n",
    "        ax.set_title(f'ABL={ABL}, ILD={ILD}', fontsize=9)\n",
    "        ax.axhline(0, color='black', linewidth=0.5)\n",
    "        ax.set_xlim(-0.2, 0.7)\n",
    "\n",
    "# Add a single legend outside the plot\n",
    "handles, labels = axes[0][0].get_legend_handles_labels()\n",
    "fig.legend(handles, labels, loc='upper right', fontsize=10)\n",
    "\n",
    "plt.tight_layout(rect=[0, 0, 0.98, 1])\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# tacho"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# Prepare the figure and axes\n",
    "fig, axes = plt.subplots(nrows=10, ncols=3, figsize=(18, 24), sharex=True, sharey=True)\n",
    "fig.subplots_adjust(hspace=0.5, wspace=0.3)\n",
    "bin_size = 0.02\n",
    "bins = np.arange(-1, 2, bin_size)\n",
    "bin_centers = bins[:-1] + (bin_size / 2)\n",
    "t_pts = np.arange(-1, 2, 0.001)\n",
    "\n",
    "\n",
    "for a_idx, ABL in enumerate(ABL_arr):\n",
    "    for i_idx, ILD in enumerate(ILD_arr):\n",
    "        ax = axes[i_idx, a_idx]  # (row=ILD, col=ABL)\n",
    "\n",
    "        # data\n",
    "        df_led_off_abort_and_valid = df_led_off[(df_led_off['abort_event'] == 3) | (df_led_off['response_poke'].isin([2,3]))]\n",
    "        mask_invalid = ~df_led_off_abort_and_valid['response_poke'].isin([2, 3])\n",
    "        # Step 2: Assign random values (2 or 3 with 50% chance) to those rows\n",
    "        df_led_off_abort_and_valid.loc[mask_invalid, 'response_poke'] = np.random.choice([2, 3], size=mask_invalid.sum())\n",
    "\n",
    "        df_ABL_ILD = df_led_off_abort_and_valid[\n",
    "            (df_led_off_abort_and_valid['ABL'] == ABL) & (df_led_off_abort_and_valid['ILD'] == ILD)].copy()\n",
    "        \n",
    "        # df_ABL_ILD = df_led_off_valid[\n",
    "        #     (df_led_off_valid['ABL'] == ABL) & (df_led_off_valid['ILD'] == ILD)].copy()\n",
    "        \n",
    "        df_ABL_ILD.loc[:, 'RT'] = df_ABL_ILD['timed_fix'] - df_ABL_ILD['intended_fix']\n",
    "        df_ABL_ILD.loc[:, 'is_correct'] = (\n",
    "                    df_ABL_ILD['ILD'] * (2 * df_ABL_ILD['response_poke'] - 5)\n",
    "                ) > 0\n",
    "        df_ABL_ILD.loc[:, 'rt_bin'] = pd.cut(\n",
    "                df_ABL_ILD['RT'], bins=bins, include_lowest=True\n",
    "            )\n",
    "        tachometric_curve = df_ABL_ILD.groupby('rt_bin', observed=False)['is_correct'].mean()\n",
    "\n",
    "\n",
    "        # theory\n",
    "        theory_ABL_ILD_up = np.zeros_like(t_pts)\n",
    "        theory_ABL_ILD_down = np.zeros_like(t_pts)\n",
    "        theory_tacho = np.zeros_like(t_pts)\n",
    "        for idx, t in enumerate(t_pts):\n",
    "            P_A = P_A_samples_mean[idx]\n",
    "            C_A = C_A_mean[idx]\n",
    "            theory_ABL_ILD_up[idx] = up_or_down_RTs_fit_wrt_stim_fn(\n",
    "                t, 1,\n",
    "                P_A, C_A,\n",
    "                t_stim, ABL, ILD, rate_lambda, T_0, theta_E, Z_E, t_E_aff, del_go,\n",
    "                phi_params_obj, rate_norm_l,\n",
    "                is_norm, is_time_vary, K_max)\n",
    "\n",
    "            theory_ABL_ILD_down[idx] = up_or_down_RTs_fit_wrt_stim_fn(\n",
    "                t, -1,\n",
    "                P_A, C_A,\n",
    "                t_stim, ABL, ILD, rate_lambda, T_0, theta_E, Z_E, t_E_aff, del_go,\n",
    "                phi_params_obj, rate_norm_l,\n",
    "                is_norm, is_time_vary, K_max)\n",
    "\n",
    "            if ILD > 0:\n",
    "                theory_tacho[idx] = theory_ABL_ILD_up[idx] / (theory_ABL_ILD_up[idx] + theory_ABL_ILD_down[idx] + 1e-10)\n",
    "            else:\n",
    "                theory_tacho[idx] = theory_ABL_ILD_down[idx] / (theory_ABL_ILD_up[idx] + theory_ABL_ILD_down[idx] + 1e-10)\n",
    "        \n",
    "\n",
    "        ax.plot(bin_centers, tachometric_curve, 'b--')\n",
    "        ax.plot(t_pts, theory_tacho, 'r-')\n",
    "        ax.set_title(f'ABL={ABL}, ILD={ILD}', fontsize=9)\n",
    "        ax.axhline(0, color='black', linewidth=0.5)\n",
    "        ax.set_xlim(0, 0.7)\n",
    "        ax.set_ylim(0.5, 1.05)\n",
    "\n",
    "# Add shared axis labels\n",
    "\n",
    "# Add a single legend outside the plot\n",
    "handles, labels = ax.get_legend_handles_labels()\n",
    "fig.legend(handles, labels, loc='upper right', fontsize=10)\n",
    "\n",
    "plt.tight_layout(rect=[0, 0, 0.98, 1])  # leave space for legend\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# check with simulations "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# sample t-stim\n",
    "N_sim = int(1e6)\n",
    "\n",
    "t_stim_samples = df['intended_fix'].sample(N_sim, replace=True).values\n",
    "ABL_samples = df['ABL'].sample(N_sim, replace=True).values\n",
    "ILD_samples = df['ILD'].sample(N_sim, replace=True).values\n",
    "\n",
    "N_print = int(N_sim / 5)\n",
    "dt  = 1e-4\n",
    "\n",
    "sim_results = Parallel(n_jobs=30)(\n",
    "    delayed(psiam_tied_data_gen_wrapper_rate_norm_time_vary_fn)(\n",
    "        V_A, theta_A, ABL_samples[iter_num], ILD_samples[iter_num], rate_lambda, T_0, theta_E, Z_E, t_A_aff, t_E_aff, del_go, \n",
    "        t_stim_samples[iter_num], rate_norm_l, iter_num, N_print, phi_params_obj, dt\n",
    "    ) for iter_num in tqdm(range(N_sim))\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Grand RT, Grand Tacho, Psycho"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sim_results_df = pd.DataFrame(sim_results)\n",
    "sim_results_df_valid = sim_results_df[sim_results_df['rt'] > sim_results_df['t_stim']]\n",
    "sim_results_df_valid_less_than_1 = sim_results_df_valid[sim_results_df_valid['rt'] - sim_results_df_valid['t_stim'] < 1].copy()\n",
    "\n",
    "df_led_off_valid.loc[:,'choice'] = 2*df_led_off_valid['response_poke'] - 5\n",
    "df_led_off_valid_renamed = df_led_off_valid.rename(columns={\n",
    "    'timed_fix': 'rt',\n",
    "    'intended_fix': 't_stim'\n",
    "}).copy()\n",
    "\n",
    "df_led_off_valid_renamed.loc[:,'correct'] = (df_led_off_valid_renamed['choice'] * df_led_off_valid_renamed['ILD'] > 0).astype(int)\n",
    "sim_results_df_valid_less_than_1.loc[:,'correct'] = (sim_results_df_valid_less_than_1['choice'] * sim_results_df_valid_less_than_1['ILD'] > 0).astype(int)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "bw = 0.02\n",
    "bins = np.arange(0, 1, bw)\n",
    "bin_centers = bins[:-1] + 0.5*bw\n",
    "def grand_rtd(df_1):\n",
    "    df_1_rt = df_1['rt'] - df_1['t_stim']\n",
    "    rt_hist, _ = np.histogram(df_1_rt, bins=bins, density=True)\n",
    "    return rt_hist\n",
    "\n",
    "def plot_psycho(df_1):\n",
    "    prob_choice_dict = {}\n",
    "\n",
    "    all_ABL = np.sort(df_1['ABL'].unique())\n",
    "    all_ILD = np.sort(df_1['ILD'].unique())\n",
    "\n",
    "    for abl in all_ABL:\n",
    "        filtered_df = df_1[df_1['ABL'] == abl]\n",
    "        prob_choice_dict[abl] = [sum(filtered_df[filtered_df['ILD'] == ild]['choice'] == 1) / len(filtered_df[filtered_df['ILD'] == ild]) for ild in all_ILD]\n",
    "\n",
    "    return prob_choice_dict\n",
    "\n",
    "def plot_tacho(df_1):\n",
    "    # prob of correct vs RT\n",
    "    df_1.loc[:, 'RT_bin'] = pd.cut(df_1['rt'] - df_1['t_stim'], bins=bins, include_lowest=True)\n",
    "    grouped_by_rt_bin = df_1.groupby('RT_bin', observed=False)['correct'].agg(['mean', 'count'])\n",
    "    grouped_by_rt_bin['bin_mid'] = grouped_by_rt_bin.index.map(lambda x: x.mid)\n",
    "    return grouped_by_rt_bin['bin_mid'], grouped_by_rt_bin['mean']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# Create a figure with 3 subplots in a single row\n",
    "fig, axes = plt.subplots(1, 3, figsize=(15, 4))\n",
    "\n",
    "# === grand RTD ===\n",
    "axes[0].plot(bin_centers, grand_rtd(df_led_off_valid_renamed), color='b', label='data')\n",
    "axes[0].plot(bin_centers, grand_rtd(sim_results_df_valid_less_than_1), color='r', label='sim')\n",
    "axes[0].legend()\n",
    "axes[0].set_xlabel('rt wrt stim')\n",
    "axes[0].set_ylabel('density')\n",
    "axes[0].set_title('Grand RTD')\n",
    "\n",
    "# === grand psycho ===\n",
    "data_psycho = plot_psycho(df_led_off_valid_renamed)\n",
    "sim_psycho = plot_psycho(sim_results_df_valid_less_than_1)\n",
    "\n",
    "colors = ['r', 'b', 'g']  # Define colors for each ABL\n",
    "for i, ABL in enumerate(ABL_arr):\n",
    "    axes[1].plot(ILD_arr, data_psycho[ABL], color=colors[i], label=f'data ABL={ABL}', marker='o', linestyle='None')\n",
    "    axes[1].plot(ILD_arr, sim_psycho[ABL], color=colors[i], label=f'sim ABL={ABL}', linestyle='-')\n",
    "\n",
    "axes[1].legend()\n",
    "axes[1].set_xlabel('ILD')\n",
    "axes[1].set_ylabel('P(right)')\n",
    "axes[1].set_title('Grand Psychometric')\n",
    "\n",
    "# === grand tacho ===\n",
    "data_tacho_x, data_tacho_y = plot_tacho(df_led_off_valid_renamed)\n",
    "sim_tacho_x, sim_tacho_y = plot_tacho(sim_results_df_valid_less_than_1)\n",
    "\n",
    "axes[2].plot(data_tacho_x, data_tacho_y, color='b', label='data')\n",
    "axes[2].plot(sim_tacho_x, sim_tacho_y, color='r', label='sim')\n",
    "axes[2].legend()\n",
    "axes[2].set_xlabel('rt wrt stim')\n",
    "axes[2].set_ylabel('acc')\n",
    "axes[2].set_title('Grand Tacho')\n",
    "axes[2].set_ylim(0.5, 1);\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ABL = 20; ILD = 1\n",
    "sim_results_df_ABL_ILD = sim_results_df[(sim_results_df['ABL'] == ABL) & (sim_results_df['ILD'] == ILD)]\n",
    "bins = np.arange(-1, 2, 0.02)\n",
    "rt_ABL_ILD = sim_results_df_ABL_ILD['rt'] - sim_results_df_ABL_ILD['t_stim']\n",
    "\n",
    "\n",
    "theory_total = np.zeros_like(t_pts)\n",
    "theory_up = np.zeros_like(t_pts)\n",
    "theory_down = np.zeros_like(t_pts)\n",
    "\n",
    "for idx, t in enumerate(t_pts):\n",
    "    P_A = P_A_samples_mean[idx]\n",
    "    C_A = C_A_mean[idx]\n",
    "    up = up_or_down_RTs_fit_wrt_stim_fn(\n",
    "        t, 1, P_A, C_A,\n",
    "        np.nan, ABL, ILD, rate_lambda, T_0, theta_E, Z_E, t_E_aff, del_go,\n",
    "        phi_params_obj, rate_norm_l, is_norm, is_time_vary, K_max)\n",
    "\n",
    "    down = up_or_down_RTs_fit_wrt_stim_fn(\n",
    "        t, -1, P_A, C_A,\n",
    "        np.nan, ABL, ILD, rate_lambda, T_0, theta_E, Z_E, t_E_aff, del_go,\n",
    "        phi_params_obj, rate_norm_l, is_norm, is_time_vary, K_max)\n",
    "\n",
    "    theory_up[idx]  = up\n",
    "    theory_down[idx] = down  \n",
    "    theory_total[idx] = up + down\n",
    "\n",
    "\n",
    "plt.figure(figsize=(10,5))\n",
    "plt.subplot(1,2,1)\n",
    "plt.plot(t_pts, theory_total, ls='--')\n",
    "plt.hist(rt_ABL_ILD, bins=bins, density=True, histtype='step');\n",
    "\n",
    "plt.subplot(1,2,2)\n",
    "sim_results_df_ABL_ILD_up = sim_results_df_ABL_ILD[sim_results_df_ABL_ILD['choice'] == 1]\n",
    "sim_results_df_ABL_ILD_down = sim_results_df_ABL_ILD[sim_results_df_ABL_ILD['choice'] == -1]\n",
    "\n",
    "up_rt_hist, _ = np.histogram(sim_results_df_ABL_ILD_up['rt'] - sim_results_df_ABL_ILD_up['t_stim'], bins=bins, density=True)\n",
    "down_rt_hist, _ = np.histogram(sim_results_df_ABL_ILD_down['rt'] - sim_results_df_ABL_ILD_down['t_stim'], bins=bins, density=True)\n",
    "\n",
    "\n",
    "bin_centers = bins[:-1] + 0.5 * 0.02\n",
    "plt.plot(bin_centers, up_rt_hist * len(sim_results_df_ABL_ILD_up)/len(sim_results_df_ABL_ILD))\n",
    "plt.plot(bin_centers, -1 *  down_rt_hist * len(sim_results_df_ABL_ILD_down)/len(sim_results_df_ABL_ILD))\n",
    "\n",
    "\n",
    "plt.plot(t_pts, theory_up, ls='--')\n",
    "plt.plot(t_pts, -theory_down, ls='--')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Convert t_pts to numpy array if it's not already\n",
    "t_pts = np.array(t_pts)\n",
    "\n",
    "# Define masks for the integration ranges\n",
    "mask_full = (t_pts >= -1) & (t_pts <= 2)\n",
    "mask_pos = (t_pts >= 0) & (t_pts <= 2)\n",
    "\n",
    "# Compute areas under the curve for full range [-1, 2]\n",
    "area_up_full = np.trapz(theory_up[mask_full], t_pts[mask_full])\n",
    "area_down_full = np.trapz(theory_down[mask_full], t_pts[mask_full])\n",
    "area_total_full = area_up_full + area_down_full\n",
    "\n",
    "# Compute areas under the curve for positive range [0, 2]\n",
    "area_up_pos = np.trapz(theory_up[mask_pos], t_pts[mask_pos])\n",
    "area_down_pos = np.trapz(theory_down[mask_pos], t_pts[mask_pos])\n",
    "area_total_pos = area_up_pos + area_down_pos\n",
    "\n",
    "# Print results\n",
    "print(\"Area in range [-1, 2]:\")\n",
    "print(f\"  Up: {area_up_full:.4f}, Down: {area_down_full:.4f}, Total: {area_total_full:.4f}\")\n",
    "\n",
    "print(\"Area in range [0, 2]:\")\n",
    "print(f\"  Up: {area_up_pos:.4f}, Down: {area_down_pos:.4f}, Total: {area_total_pos:.4f}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from scipy.integrate import trapezoid as trapz\n",
    "\n",
    "# Ensure t_pts is a numpy array\n",
    "t_pts = np.array(t_pts)\n",
    "\n",
    "# Define masks for the integration ranges\n",
    "mask_full = (t_pts >= -1) & (t_pts <= 2)\n",
    "mask_pos = (t_pts >= 0) & (t_pts <= 2)\n",
    "\n",
    "# Compute areas under the curve for full range [-1, 2]\n",
    "area_up_full = trapz(theory_up[mask_full], t_pts[mask_full])\n",
    "area_down_full = trapz(theory_down[mask_full], t_pts[mask_full])\n",
    "area_total_full = area_up_full + area_down_full\n",
    "\n",
    "# Compute areas under the curve for positive range [0, 2]\n",
    "area_up_pos = trapz(theory_up[mask_pos], t_pts[mask_pos])\n",
    "area_down_pos = trapz(theory_down[mask_pos], t_pts[mask_pos])\n",
    "area_total_pos = area_up_pos + area_down_pos\n",
    "\n",
    "# Print results\n",
    "print(\"Area in range [-1, 2]:\")\n",
    "print(f\"  Up: {area_up_full:.4f}, Down: {area_down_full:.4f}, Total: {area_total_full:.4f}\")\n",
    "\n",
    "print(\"Area in range [0, 2]:\")\n",
    "print(f\"  Up: {area_up_pos:.4f}, Down: {area_down_pos:.4f}, Total: {area_total_pos:.4f}\")\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
